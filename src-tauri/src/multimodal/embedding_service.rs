//! å¤šæ¨¡æ€åµŒå…¥æœåŠ¡
//!
//! å°è£…å¤šæ¨¡æ€å†…å®¹å‘é‡åŒ–çš„å®Œæ•´é€»è¾‘ï¼ŒåŒ…æ‹¬æ‰¹é‡å¤„ç†ã€é”™è¯¯é‡è¯•å’Œæ—¥å¿—è®°å½•ã€‚
//!
//! ## è®¾è®¡è¦ç‚¹
//!
//! - **ä¸å­˜å‚¨æ¨¡å‹é…ç½®**: æœåŠ¡åªæŒæœ‰ LLMManager å¼•ç”¨ï¼Œæ¯æ¬¡è°ƒç”¨æ—¶åŠ¨æ€è·å–é…ç½®ã€‚
//!   è¿™æ ·å½“ç”¨æˆ·åœ¨è®¾ç½®ä¸­æ›´æ¢æ¨¡å‹æ—¶ï¼Œæ— éœ€é‡å¯æœåŠ¡ã€‚
//! - **æ‰¹é‡å¤„ç†**: VL æ¨¡å‹é€šå¸¸å¤„ç†é€Ÿåº¦è¾ƒæ…¢ï¼Œæ‰¹é‡å¤§å°å»ºè®®é™åˆ¶åœ¨ 8 ä»¥å†…ã€‚
//!   æœåŠ¡è´Ÿè´£å°†å¤§æ‰¹é‡è¾“å…¥æ‹†åˆ†å¤„ç†ã€‚
//! - **é”™è¯¯å¤„ç†**: å›¾ç‰‡åŠ è½½å¤±è´¥æ—¶é™çº§ä¸ºçº¯æ–‡æœ¬åµŒå…¥ï¼Œç¡®ä¿ç´¢å¼•æµç¨‹ä¸ä¸­æ–­ã€‚
//! - **åŒæ¨¡å¼æ”¯æŒ**: æ”¯æŒ VL-Embedding ç›´æ¥å‘é‡åŒ–å’Œ VLæ‘˜è¦+æ–‡æœ¬åµŒå…¥ä¸¤ç§æ–¹æ¡ˆã€‚
//!
//! è®¾è®¡æ–‡æ¡£å‚è€ƒ: docs/multimodal-knowledge-base-design.md (Section 7.3)

use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::Arc;

use futures::stream::{self, StreamExt};
use tokio::sync::mpsc;

use crate::llm_manager::{ImagePayload, LLMManager};
use crate::models::AppError;
use crate::multimodal::types::{MultimodalImage, MultimodalIndexingMode, MultimodalInput};

/// åµŒå…¥è¿›åº¦ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct EmbeddingProgress {
    /// å½“å‰é˜¶æ®µï¼šsummarizing / embedding
    pub phase: String,
    /// å½“å‰å®Œæˆçš„é¡µæ•°
    pub completed: usize,
    /// æ€»é¡µæ•°
    pub total: usize,
    /// å½“å‰æ­£åœ¨å¤„ç†çš„é¡µç ï¼ˆå¯é€‰ï¼‰
    pub current_page: Option<usize>,
    /// æ¶ˆæ¯
    pub message: String,
}

type Result<T> = std::result::Result<T, AppError>;

/// é»˜è®¤æ‰¹é‡å¤§å°ï¼ˆVL æ¨¡å‹å¤„ç†é€Ÿåº¦è¾ƒæ…¢ï¼Œé™åˆ¶åœ¨ 8 ä»¥å†…ï¼‰
const DEFAULT_BATCH_SIZE: usize = 8;
/// é»˜è®¤æ‘˜è¦ç”Ÿæˆå¹¶å‘æ•°
const DEFAULT_SUMMARY_CONCURRENCY: usize = 10;

/// åµŒå…¥æœåŠ¡é…ç½®
#[derive(Debug, Clone)]
pub struct EmbeddingServiceConfig {
    /// å•æ¬¡ API è°ƒç”¨çš„æœ€å¤§è¾“å…¥æ•°é‡
    pub batch_size: usize,
    /// VL æ‘˜è¦ç”Ÿæˆçš„å¹¶å‘æ•°
    pub summary_concurrency: usize,
    /// æ˜¯å¦å¯ç”¨é™çº§æ¨¡å¼ï¼ˆå›¾ç‰‡åŠ è½½å¤±è´¥æ—¶é™çº§ä¸ºçº¯æ–‡æœ¬ï¼‰
    pub enable_fallback: bool,
}

impl Default for EmbeddingServiceConfig {
    fn default() -> Self {
        Self {
            batch_size: DEFAULT_BATCH_SIZE,
            summary_concurrency: DEFAULT_SUMMARY_CONCURRENCY,
            enable_fallback: true,
        }
    }
}

/// å¤šæ¨¡æ€åµŒå…¥æœåŠ¡
///
/// å°è£…å¤šæ¨¡æ€å†…å®¹å‘é‡åŒ–çš„å®Œæ•´é€»è¾‘ï¼Œé€šè¿‡ LLMManager åŠ¨æ€è·å–æ¨¡å‹é…ç½®ã€‚
pub struct MultimodalEmbeddingService {
    llm_manager: Arc<LLMManager>,
    config: EmbeddingServiceConfig,
}

impl MultimodalEmbeddingService {
    /// åˆ›å»ºæ–°çš„åµŒå…¥æœåŠ¡å®ä¾‹
    pub fn new(llm_manager: Arc<LLMManager>) -> Self {
        Self {
            llm_manager,
            config: EmbeddingServiceConfig::default(),
        }
    }

    /// ä½¿ç”¨è‡ªå®šä¹‰é…ç½®åˆ›å»ºåµŒå…¥æœåŠ¡
    pub fn with_config(llm_manager: Arc<LLMManager>, config: EmbeddingServiceConfig) -> Self {
        Self {
            llm_manager,
            config,
        }
    }

    /// æ£€æŸ¥å¤šæ¨¡æ€åµŒå…¥æ¨¡å‹æ˜¯å¦å·²é…ç½®ï¼ˆä»»ä¸€æ¨¡å¼å¯ç”¨å³è¿”å› trueï¼‰
    pub async fn is_configured(&self) -> bool {
        self.llm_manager.is_multimodal_rag_configured().await
    }

    /// æ£€æŸ¥ VL-Embedding æ¨¡å‹æ˜¯å¦çœŸæ­£å¯ç”¨ï¼ˆæ–¹æ¡ˆä¸€ï¼‰
    ///
    /// ä¸ `is_configured()` ä¸åŒï¼Œæ­¤æ–¹æ³•ä»…æ£€æŸ¥ VL-Embedding æ¨¡å‹ï¼Œ
    /// ç”¨äºå¬å›æ—¶åˆ¤æ–­æ˜¯å¦èƒ½ç”Ÿæˆå¤šæ¨¡æ€æŸ¥è¯¢å‘é‡
    ///
    /// æ³¨æ„ï¼šVL-Embedding æ¨¡å‹é€šè¿‡ç»´åº¦ç®¡ç†çš„é»˜è®¤å¤šæ¨¡æ€ç»´åº¦è®¾ç½®
    pub async fn is_vl_embedding_available(&self) -> bool {
        self.llm_manager
            .get_vl_embedding_model_config()
            .await
            .is_ok()
    }

    /// æ£€æŸ¥æ–‡æœ¬åµŒå…¥æ¨¡å‹æ˜¯å¦å¯ç”¨ï¼ˆæ–¹æ¡ˆäºŒçš„ä¸€éƒ¨åˆ†ï¼‰
    ///
    /// æ³¨æ„ï¼šæ–‡æœ¬åµŒå…¥æ¨¡å‹é€šè¿‡ç»´åº¦ç®¡ç†çš„é»˜è®¤æ–‡æœ¬ç»´åº¦è®¾ç½®
    pub async fn is_text_embedding_available(&self) -> bool {
        self.llm_manager.get_embedding_model_config().await.is_ok()
    }

    /// è·å–å½“å‰åµŒå…¥æ¨¡å‹çš„è¾“å‡ºç»´åº¦
    ///
    /// é€šè¿‡è°ƒç”¨ä¸€ä¸ªç®€å•çš„æ–‡æœ¬è¾“å…¥æ¥æ£€æµ‹æ¨¡å‹è¾“å‡ºç»´åº¦
    pub async fn detect_embedding_dimension(&self) -> Result<usize> {
        // ä½¿ç”¨ç®€å•çš„æµ‹è¯•æ–‡æœ¬è·å–ç»´åº¦
        let test_input = MultimodalInput::text("test");
        let embeddings = self
            .llm_manager
            .call_multimodal_embedding_api(&[test_input])
            .await?;

        embeddings
            .first()
            .map(|v| v.len())
            .ok_or_else(|| AppError::configuration("æ— æ³•æ£€æµ‹åµŒå…¥æ¨¡å‹è¾“å‡ºç»´åº¦"))
    }

    /// è·å–åµŒå…¥æ¨¡å‹ç‰ˆæœ¬æ ‡è¯†
    ///
    /// è¿”å›æ ¼å¼: "{model_name}@{config_id}"
    pub async fn get_model_version(&self) -> Result<String> {
        let config = self.llm_manager.get_vl_embedding_model_config().await?;
        Ok(format!("{}@{}", config.model, config.id))
    }

    /// ä¸ºå•ä¸ªå¤šæ¨¡æ€è¾“å…¥ç”ŸæˆåµŒå…¥å‘é‡
    pub async fn embed_single(&self, input: &MultimodalInput) -> Result<Vec<f32>> {
        let embeddings = self.embed_batch(&[input.clone()]).await?;
        embeddings
            .into_iter()
            .next()
            .ok_or_else(|| AppError::internal("åµŒå…¥ API è¿”å›ç©ºç»“æœ"))
    }

    /// ä¸ºå¤šä¸ªå¤šæ¨¡æ€è¾“å…¥æ‰¹é‡ç”ŸæˆåµŒå…¥å‘é‡
    ///
    /// å¦‚æœè¾“å…¥æ•°é‡è¶…è¿‡æ‰¹é‡å¤§å°ï¼Œä¼šè‡ªåŠ¨æ‹†åˆ†ä¸ºå¤šä¸ª API è°ƒç”¨
    pub async fn embed_batch(&self, inputs: &[MultimodalInput]) -> Result<Vec<Vec<f32>>> {
        self.embed_batch_with_progress(inputs, None).await
    }

    /// ä¸ºå¤šä¸ªå¤šæ¨¡æ€è¾“å…¥æ‰¹é‡ç”ŸæˆåµŒå…¥å‘é‡ï¼ˆå¸¦è¿›åº¦å›è°ƒï¼‰
    pub async fn embed_batch_with_progress(
        &self,
        inputs: &[MultimodalInput],
        progress_tx: Option<mpsc::UnboundedSender<EmbeddingProgress>>,
    ) -> Result<Vec<Vec<f32>>> {
        if inputs.is_empty() {
            return Ok(Vec::new());
        }

        // æ£€æŸ¥æ˜¯å¦é…ç½®äº†å¤šæ¨¡æ€æ¨¡å‹
        if !self.is_configured().await {
            return Err(AppError::configuration("æœªé…ç½®å¤šæ¨¡æ€åµŒå…¥æ¨¡å‹"));
        }

        let batch_size = self.config.batch_size;
        let total = inputs.len();
        let mut all_embeddings = Vec::with_capacity(total);
        let mut completed = 0usize;

        if let Some(ref tx) = progress_tx {
            let _ = tx.send(EmbeddingProgress {
                phase: "embedding".to_string(),
                completed,
                total,
                current_page: None,
                message: format!("å¼€å§‹å¤šæ¨¡æ€åµŒå…¥: 0/{}", total),
            });
        }

        log::info!(
            "ğŸ–¼ï¸ å¤šæ¨¡æ€åµŒå…¥æœåŠ¡ï¼šå¼€å§‹å¤„ç† {} ä¸ªè¾“å…¥ï¼Œæ‰¹é‡å¤§å° {}",
            total,
            batch_size
        );

        // åˆ†æ‰¹å¤„ç†
        for (batch_idx, chunk) in inputs.chunks(batch_size).enumerate() {
            let batch_start = batch_idx * batch_size;
            log::debug!(
                "  å¤„ç†æ‰¹æ¬¡ {}: è¾“å…¥ {}-{} / {}",
                batch_idx + 1,
                batch_start + 1,
                (batch_start + chunk.len()).min(total),
                total
            );

            // å¦‚æœå¯ç”¨é™çº§æ¨¡å¼ï¼Œå¤„ç†å¯èƒ½çš„å›¾ç‰‡åŠ è½½å¤±è´¥
            let processed_inputs = if self.config.enable_fallback {
                self.prepare_inputs_with_fallback(chunk)
            } else {
                chunk.to_vec()
            };

            // è°ƒç”¨ API
            match self
                .llm_manager
                .call_multimodal_embedding_api(&processed_inputs)
                .await
            {
                Ok(embeddings) => {
                    if embeddings.len() != processed_inputs.len() {
                        return Err(AppError::internal(format!(
                            "åµŒå…¥ API è¿”å›æ•°é‡ä¸åŒ¹é…: æœŸæœ› {}, å®é™… {}",
                            processed_inputs.len(),
                            embeddings.len()
                        )));
                    }
                    all_embeddings.extend(embeddings);
                    completed = all_embeddings.len().min(total);

                    if let Some(ref tx) = progress_tx {
                        let _ = tx.send(EmbeddingProgress {
                            phase: "embedding".to_string(),
                            completed,
                            total,
                            current_page: Some(completed),
                            message: format!("å¤šæ¨¡æ€åµŒå…¥è¿›åº¦: {}/{}", completed, total),
                        });
                    }
                }
                Err(e) => {
                    log::error!("  æ‰¹æ¬¡ {} åµŒå…¥å¤±è´¥: {}", batch_idx + 1, e);
                    return Err(e);
                }
            }
        }

        if let Some(ref tx) = progress_tx {
            let _ = tx.send(EmbeddingProgress {
                phase: "embedding".to_string(),
                completed: total,
                total,
                current_page: Some(total),
                message: format!("å¤šæ¨¡æ€åµŒå…¥å®Œæˆ: {}/{}", total, total),
            });
        }

        log::info!(
            "âœ… å¤šæ¨¡æ€åµŒå…¥æœåŠ¡ï¼šå®Œæˆ {} ä¸ªè¾“å…¥çš„å‘é‡åŒ–",
            all_embeddings.len()
        );

        Ok(all_embeddings)
    }

    /// ä¸ºé¡µé¢å†…å®¹ç”ŸæˆåµŒå…¥å‘é‡
    ///
    /// ## å‚æ•°
    /// - `image_base64`: é¡µé¢å›¾ç‰‡çš„ Base64 ç¼–ç 
    /// - `media_type`: å›¾ç‰‡ MIME ç±»å‹ï¼ˆå¦‚ "image/png"ï¼‰
    /// - `text_summary`: é¡µé¢çš„æ–‡æœ¬æ‘˜è¦ï¼ˆOCR æ–‡æœ¬æˆ– VLM ç”Ÿæˆçš„æ‘˜è¦ï¼‰
    /// - `instruction`: å¯é€‰çš„ä»»åŠ¡æŒ‡ä»¤
    ///
    /// ## è¿”å›
    /// åµŒå…¥å‘é‡
    pub async fn embed_page(
        &self,
        image_base64: &str,
        media_type: &str,
        text_summary: Option<&str>,
        instruction: Option<&str>,
    ) -> Result<Vec<f32>> {
        let mut input = if let Some(text) = text_summary {
            // å›¾æ–‡æ··åˆè¾“å…¥
            MultimodalInput::text_and_image(text, image_base64, media_type)
        } else {
            // çº¯å›¾ç‰‡è¾“å…¥
            MultimodalInput::image_base64(image_base64, media_type)
        };

        // æ·»åŠ ä»»åŠ¡æŒ‡ä»¤
        if let Some(instr) = instruction {
            input = input.with_instruction(instr);
        }

        self.embed_single(&input).await
    }

    /// ä¸ºé¡µé¢å†…å®¹æ‰¹é‡ç”ŸæˆåµŒå…¥å‘é‡
    ///
    /// ## å‚æ•°
    /// - `pages`: é¡µé¢æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (image_base64, media_type, text_summary)
    /// - `instruction`: å¯é€‰çš„ä»»åŠ¡æŒ‡ä»¤ï¼ˆåº”ç”¨äºæ‰€æœ‰é¡µé¢ï¼‰
    ///
    /// ## è¿”å›
    /// æ¯ä¸ªé¡µé¢å¯¹åº”çš„åµŒå…¥å‘é‡
    pub async fn embed_pages(
        &self,
        pages: &[(String, String, Option<String>)],
        instruction: Option<&str>,
    ) -> Result<Vec<Vec<f32>>> {
        let inputs: Vec<MultimodalInput> = pages
            .iter()
            .map(|(base64, media_type, text)| {
                let mut input = if let Some(t) = text {
                    MultimodalInput::text_and_image(t, base64, media_type)
                } else {
                    MultimodalInput::image_base64(base64, media_type)
                };
                if let Some(instr) = instruction {
                    input = input.with_instruction(instr);
                }
                input
            })
            .collect();

        self.embed_batch(&inputs).await
    }

    /// å‡†å¤‡è¾“å…¥æ•°æ®ï¼Œå¤„ç†å¯èƒ½çš„å›¾ç‰‡åŠ è½½å¤±è´¥
    ///
    /// å¦‚æœè¾“å…¥åŒ…å«æ— æ•ˆçš„å›¾ç‰‡æ•°æ®ï¼Œé™çº§ä¸ºçº¯æ–‡æœ¬è¾“å…¥ï¼ˆå¦‚æœæœ‰æ–‡æœ¬çš„è¯ï¼‰
    fn prepare_inputs_with_fallback(&self, inputs: &[MultimodalInput]) -> Vec<MultimodalInput> {
        inputs
            .iter()
            .map(|input| {
                // æ£€æŸ¥å›¾ç‰‡æ•°æ®æ˜¯å¦æœ‰æ•ˆ
                if let Some(ref image) = input.image {
                    match image {
                        MultimodalImage::Base64 { data, .. } => {
                            // Base64 æ•°æ®ä¸ºç©ºæˆ–å¤ªçŸ­å¯èƒ½æ˜¯æ— æ•ˆçš„
                            if data.len() < 100 {
                                log::warn!("å›¾ç‰‡ Base64 æ•°æ®è¿‡çŸ­ï¼Œå¯èƒ½æ— æ•ˆï¼Œé™çº§ä¸ºçº¯æ–‡æœ¬");
                                if let Some(ref text) = input.text {
                                    return MultimodalInput::text(text);
                                }
                            }
                        }
                        MultimodalImage::Url { url } => {
                            // URL ä¸ºç©ºæ˜¯æ— æ•ˆçš„
                            if url.is_empty() {
                                log::warn!("å›¾ç‰‡ URL ä¸ºç©ºï¼Œé™çº§ä¸ºçº¯æ–‡æœ¬");
                                if let Some(ref text) = input.text {
                                    return MultimodalInput::text(text);
                                }
                            }
                        }
                    }
                }
                input.clone()
            })
            .collect()
    }

    // ============================================================================
    // æ–¹æ¡ˆäºŒï¼šDeepSeek-OCR æ‘˜è¦ + æ–‡æœ¬åµŒå…¥
    // ============================================================================

    /// ä½¿ç”¨ DeepSeek-OCR æ¨¡å‹ä¸ºå›¾ç‰‡ç”Ÿæˆæ–‡æœ¬æ‘˜è¦
    ///
    /// âš ï¸ ä½¿ç”¨ DeepSeek-OCR å®˜æ–¹ prompt "Free OCR."ï¼Œé€Ÿåº¦æ›´å¿«ã€ç²¾åº¦æ›´é«˜
    ///
    /// ## å‚æ•°
    /// - `image_base64`: å›¾ç‰‡çš„ Base64 ç¼–ç 
    /// - `media_type`: å›¾ç‰‡ MIME ç±»å‹
    /// - `_existing_text`: å·²æœ‰çš„æ–‡æœ¬å†…å®¹ï¼ˆä¿ç•™å‚æ•°å…¼å®¹æ€§ï¼ŒDeepSeek-OCR ä¸ä½¿ç”¨ï¼‰
    ///
    /// ## è¿”å›
    /// ç”Ÿæˆçš„æ–‡æœ¬æ‘˜è¦ï¼ˆMarkdown æ ¼å¼ï¼‰
    pub async fn generate_image_summary(
        &self,
        image_base64: &str,
        media_type: &str,
        _existing_text: Option<&str>,
    ) -> Result<String> {
        // âš ï¸ DeepSeek-OCR å®˜æ–¹ prompt - æ–‡æ¡£è½¬ Markdown æ ¼å¼ï¼ˆä¸å¸¦ groundingï¼Œæ— åæ ‡æ ‡è®°ï¼‰
        let prompt = "Convert the document to markdown.";

        let image_payload = ImagePayload {
            mime: media_type.to_string(),
            base64: image_base64.to_string(),
        };

        let result = self
            .llm_manager
            .call_ocr_model_raw_prompt(prompt, Some(vec![image_payload]))
            .await?;

        Ok(result.assistant_message)
    }

    /// æ‰¹é‡ä¸ºå›¾ç‰‡ç”Ÿæˆæ–‡æœ¬æ‘˜è¦ï¼ˆå¹¶è¡Œå¤„ç†ï¼Œå¸¦è¿›åº¦å›è°ƒï¼‰
    ///
    /// ä½¿ç”¨ DeepSeek-OCR å®˜æ–¹ prompt è¿›è¡Œ OCR è¯†åˆ«ï¼Œé€Ÿåº¦æ›´å¿«ã€ç²¾åº¦æ›´é«˜ã€‚
    ///
    /// ## DeepSeek-OCR å®˜æ–¹æ”¯æŒçš„ promptï¼ˆå¿…é¡»ä¸¥æ ¼ä½¿ç”¨ï¼‰ï¼š
    /// - æ–‡æ¡£è½¬Markdownï¼š`<|grounding|>Convert the document to markdown.`
    /// - é€šç”¨OCRï¼š`<|grounding|>OCR this image.`
    /// - æ— å¸ƒå±€æå–ï¼š`Free OCR.`
    /// - å›¾è¡¨è§£æï¼š`Parse the figure.`
    /// - å›¾åƒæè¿°ï¼š`Describe this image in detail.`
    ///
    /// ## å‚æ•°
    /// - `pages`: é¡µé¢æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (image_base64, media_type, existing_text)
    /// - `progress_tx`: å¯é€‰çš„è¿›åº¦å›è°ƒé€šé“
    ///
    /// ## è¿”å›
    /// æ¯ä¸ªé¡µé¢å¯¹åº”çš„æ–‡æœ¬æ‘˜è¦ï¼ˆMarkdown æ ¼å¼ï¼‰
    ///
    /// ## å¹¶è¡Œç­–ç•¥
    /// ä½¿ç”¨ `buffer_unordered` å¹¶è¡Œå¤„ç†ï¼Œå¹¶å‘æ•°é€šè¿‡é…ç½®æŒ‡å®šï¼ˆé»˜è®¤ 10ï¼‰
    pub async fn generate_summaries_batch_with_progress(
        &self,
        pages: &[(String, String, Option<String>)],
        progress_tx: Option<mpsc::UnboundedSender<EmbeddingProgress>>,
    ) -> Result<Vec<String>> {
        let concurrency = self.config.summary_concurrency;
        let total = pages.len();

        log::info!(
            "ğŸ“ DeepSeek-OCR æ‘˜è¦æœåŠ¡ï¼šå¼€å§‹ä¸º {} ä¸ªé¡µé¢å¹¶è¡Œç”Ÿæˆæ‘˜è¦ï¼ˆå¹¶å‘æ•°: {}ï¼‰",
            total,
            concurrency
        );

        // ä½¿ç”¨åŸå­è®¡æ•°å™¨è·Ÿè¸ªå®Œæˆçš„é¡µé¢æ•°
        let completed_count = Arc::new(AtomicUsize::new(0));

        // åˆ›å»ºå¸¦ç´¢å¼•çš„ä»»åŠ¡åˆ—è¡¨ï¼Œä»¥ä¿æŒç»“æœé¡ºåº
        let tasks: Vec<(usize, String, String, Option<String>)> = pages
            .iter()
            .enumerate()
            .map(|(idx, (base64, media_type, existing_text))| {
                (
                    idx,
                    base64.clone(),
                    media_type.clone(),
                    existing_text.clone(),
                )
            })
            .collect();

        // å¹¶è¡Œæ‰§è¡Œæ‘˜è¦ç”Ÿæˆ
        let results: Vec<(usize, String)> = stream::iter(tasks)
            .map(|(idx, base64, media_type, existing_text)| {
                let llm_manager = self.llm_manager.clone();
                let progress_tx = progress_tx.clone();
                let completed_count = completed_count.clone();
                async move {
                    // â˜… å¦‚æœå·²æœ‰ OCR æ–‡æœ¬ï¼Œç›´æ¥å¤ç”¨ï¼Œè·³è¿‡ OCR è°ƒç”¨
                    if let Some(ref text) = existing_text {
                        if !text.is_empty() {
                            log::info!("  ğŸ“– é¡µé¢ {} å¤ç”¨å·²æœ‰ OCRï¼ˆ{} å­—ç¬¦ï¼‰ï¼Œè·³è¿‡ DeepSeek-OCR è°ƒç”¨", idx + 1, text.len());

                            // æ›´æ–°å®Œæˆè®¡æ•°å¹¶å‘é€è¿›åº¦
                            let completed = completed_count.fetch_add(1, Ordering::SeqCst) + 1;
                            if let Some(ref tx) = progress_tx {
                                let _ = tx.send(EmbeddingProgress {
                                    phase: "summarizing".to_string(),
                                    completed,
                                    total,
                                    current_page: Some(idx + 1),
                                    message: format!("å¤ç”¨å·²æœ‰ OCR: {}/{} é¡µå®Œæˆ", completed, total),
                                });
                            }

                            return (idx, text.clone());
                        }
                    }

                    // è°ƒè¯•ï¼šè¾“å‡º base64 æ•°æ®çš„å‰ 100 å­—ç¬¦ï¼Œç¡®è®¤å›¾ç‰‡æ•°æ®æ˜¯å¦æ­£ç¡®
                    let base64_preview: String = base64.chars().take(100).collect();
                    log::info!("  ğŸ“„ å¼€å§‹ç”Ÿæˆé¡µé¢ {} æ‘˜è¦ (DeepSeek-OCR)... base64å‰100å­—ç¬¦: {}", idx + 1, base64_preview);
                    log::info!("  ğŸ“„ é¡µé¢ {} media_type: {}, base64é•¿åº¦: {} å­—èŠ‚", idx + 1, media_type, base64.len());

                    // âš ï¸ DeepSeek-OCR å®˜æ–¹ prompt - æ–‡æ¡£è½¬ Markdown æ ¼å¼ï¼ˆä¸å¸¦ groundingï¼Œæ— åæ ‡æ ‡è®°ï¼‰
                    let prompt = "Convert the document to markdown.";

                    let image_payload = ImagePayload {
                        mime: media_type,
                        base64,
                    };

                    let result = match llm_manager
                        .call_ocr_model_raw_prompt(prompt, Some(vec![image_payload]))
                        .await
                    {
                        Ok(result) => {
                            let content = &result.assistant_message;
                            // è¾“å‡ºæ‘˜è¦å†…å®¹ï¼ˆæˆªå–å‰ 500 å­—ç¬¦é¿å…æ—¥å¿—è¿‡é•¿ï¼Œä½¿ç”¨å­—ç¬¦è¾¹ç•Œå®‰å…¨åˆ‡ç‰‡ï¼‰
                            let preview: String = content.chars().take(500).collect();
                            let truncated = content.chars().count() > 500;
                            let display = if truncated {
                                format!("{}...(å…± {} å­—ç¬¦)", preview, content.len())
                            } else {
                                content.clone()
                            };
                            log::info!("  âœ… é¡µé¢ {} OCR æˆåŠŸï¼Œé•¿åº¦ {} å­—ç¬¦\n--- æ‘˜è¦å†…å®¹ ---\n{}\n--- æ‘˜è¦ç»“æŸ ---", idx + 1, content.len(), display);
                            (idx, result.assistant_message)
                        }
                        Err(e) => {
                            log::warn!("  âš ï¸ é¡µé¢ {} OCR å¤±è´¥: {}ï¼Œä½¿ç”¨ç©ºå†…å®¹", idx + 1, e);
                            (idx, String::new())
                        }
                    };

                    // æ›´æ–°å®Œæˆè®¡æ•°å¹¶å‘é€è¿›åº¦
                    let completed = completed_count.fetch_add(1, Ordering::SeqCst) + 1;
                    if let Some(ref tx) = progress_tx {
                        let _ = tx.send(EmbeddingProgress {
                            phase: "summarizing".to_string(),
                            completed,
                            total,
                            current_page: Some(idx + 1),
                            message: format!("DeepSeek-OCR: {}/{} é¡µå®Œæˆ", completed, total),
                        });
                    }

                    result
                }
            })
            .buffer_unordered(concurrency)
            .collect()
            .await;

        // æŒ‰åŸå§‹ç´¢å¼•æ’åºå¹¶æå–æ‘˜è¦
        let mut sorted_results = results;
        sorted_results.sort_by_key(|(idx, _)| *idx);
        let summaries: Vec<String> = sorted_results
            .into_iter()
            .map(|(_, summary)| summary)
            .collect();

        log::info!(
            "âœ… DeepSeek-OCR æ‘˜è¦æœåŠ¡ï¼šå®Œæˆ {} ä¸ªé¡µé¢çš„æ‘˜è¦ç”Ÿæˆ",
            summaries.len()
        );
        Ok(summaries)
    }

    /// æ‰¹é‡ä¸ºå›¾ç‰‡ç”Ÿæˆæ–‡æœ¬æ‘˜è¦ï¼ˆå¹¶è¡Œå¤„ç†ï¼Œæ— è¿›åº¦å›è°ƒï¼‰
    pub async fn generate_summaries_batch(
        &self,
        pages: &[(String, String, Option<String>)],
    ) -> Result<Vec<String>> {
        self.generate_summaries_batch_with_progress(pages, None)
            .await
    }

    /// ä½¿ç”¨æ–‡æœ¬åµŒå…¥æ¨¡å‹ä¸ºæ–‡æœ¬ç”Ÿæˆå‘é‡ï¼ˆå¸¦è¿›åº¦å›è°ƒï¼‰
    ///
    /// è¶…è¿‡æ¨¡å‹ token é™åˆ¶çš„é•¿æ–‡æœ¬ä¼šè‡ªåŠ¨åˆ†å—å¤„ç†ï¼Œç„¶åä½¿ç”¨å¹³å‡æ± åŒ–èšåˆ
    pub async fn embed_texts_with_progress(
        &self,
        texts: &[String],
        progress_tx: Option<mpsc::UnboundedSender<EmbeddingProgress>>,
    ) -> Result<Vec<Vec<f32>>> {
        if texts.is_empty() {
            return Ok(Vec::new());
        }

        let total = texts.len();
        log::info!("ğŸ“Š æ–‡æœ¬åµŒå…¥æœåŠ¡ï¼šå¼€å§‹ä¸º {} ä¸ªæ–‡æœ¬ç”Ÿæˆå‘é‡", total);

        // å‘é€å¼€å§‹è¿›åº¦
        if let Some(ref tx) = progress_tx {
            let _ = tx.send(EmbeddingProgress {
                phase: "embedding".to_string(),
                completed: 0,
                total,
                current_page: None,
                message: format!("å¼€å§‹æ–‡æœ¬åµŒå…¥: 0/{} ä¸ª", total),
            });
        }

        let config = self.llm_manager.get_embedding_model_config().await?;

        // è·å–æ¨¡å‹çš„ token é™åˆ¶
        let token_limits = crate::multimodal::embedding_chunker::EmbeddingTokenLimits::default();
        let max_tokens = token_limits.get_limit(&config.model);
        let chunker = crate::multimodal::embedding_chunker::EmbeddingChunker::new(max_tokens);

        // æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†å—
        let needs_chunking = texts.iter().any(|t| chunker.needs_chunking(t));

        let embeddings = if !needs_chunking {
            // ä¸éœ€è¦åˆ†å—ï¼Œç›´æ¥è°ƒç”¨ API
            self.llm_manager
                .call_embedding_api(texts.to_vec(), &config.id)
                .await
                .map_err(|e| AppError::internal(format!("æ–‡æœ¬åµŒå…¥å¤±è´¥: {}", e)))?
        } else {
            // éœ€è¦åˆ†å—å¤„ç†
            log::info!("ğŸ“Š æ–‡æœ¬åµŒå…¥æœåŠ¡ï¼šæ£€æµ‹åˆ°é•¿æ–‡æœ¬ï¼Œå¯ç”¨åˆ†å—å¤„ç†");

            let chunk_results =
                crate::multimodal::embedding_chunker::batch_chunk_texts(texts, &chunker);
            let all_chunks: Vec<String> = chunk_results
                .iter()
                .flat_map(|r| r.chunks.clone())
                .collect();

            log::info!(
                "ğŸ“Š æ–‡æœ¬åµŒå…¥æœåŠ¡ï¼š{} ä¸ªæ–‡æœ¬åˆ†ä¸º {} ä¸ªå—",
                texts.len(),
                all_chunks.len()
            );

            let all_embeddings = self
                .llm_manager
                .call_embedding_api(all_chunks, &config.id)
                .await
                .map_err(|e| AppError::internal(format!("æ–‡æœ¬åµŒå…¥å¤±è´¥: {}", e)))?;

            // èšåˆ
            let mut result = Vec::with_capacity(texts.len());
            let mut emb_idx = 0;

            for chunk_result in &chunk_results {
                let chunk_count = chunk_result.chunks.len();

                if chunk_count == 0 {
                    let dim = all_embeddings.first().map(|v| v.len()).unwrap_or(1024);
                    result.push(vec![0.0; dim]);
                } else if chunk_count == 1 {
                    result.push(all_embeddings[emb_idx].clone());
                } else {
                    let chunk_embeddings: Vec<_> =
                        all_embeddings[emb_idx..emb_idx + chunk_count].to_vec();
                    let aggregated = crate::multimodal::embedding_chunker::EmbeddingChunker::aggregate_embeddings(
                        &chunk_embeddings,
                        crate::multimodal::embedding_chunker::ChunkAggregation::MeanPooling,
                    );
                    result.push(aggregated);
                }

                emb_idx += chunk_count;
            }

            result
        };

        // å‘é€å®Œæˆè¿›åº¦
        if let Some(ref tx) = progress_tx {
            let _ = tx.send(EmbeddingProgress {
                phase: "embedding".to_string(),
                completed: total,
                total,
                current_page: None,
                message: format!("æ–‡æœ¬åµŒå…¥å®Œæˆ: {}/{} ä¸ª", total, total),
            });
        }

        log::info!(
            "âœ… æ–‡æœ¬åµŒå…¥æœåŠ¡ï¼šå®Œæˆ {} ä¸ªæ–‡æœ¬çš„å‘é‡ç”Ÿæˆ",
            embeddings.len()
        );
        Ok(embeddings)
    }

    /// ä½¿ç”¨æ–‡æœ¬åµŒå…¥æ¨¡å‹ä¸ºæ–‡æœ¬ç”Ÿæˆå‘é‡
    ///
    /// ## å‚æ•°
    /// - `texts`: æ–‡æœ¬åˆ—è¡¨
    ///
    /// ## è¿”å›
    /// æ¯ä¸ªæ–‡æœ¬å¯¹åº”çš„åµŒå…¥å‘é‡
    ///
    /// ## æ³¨æ„
    /// - è¶…è¿‡æ¨¡å‹ token é™åˆ¶çš„é•¿æ–‡æœ¬ä¼šè‡ªåŠ¨åˆ†å—å¤„ç†ï¼Œç„¶åä½¿ç”¨å¹³å‡æ± åŒ–èšåˆ
    /// - â˜… 2026-01 ä¿®å¤ï¼šå¦‚æœåˆ†å—ååµŒå…¥ä»å›  token è¶…é™å¤±è´¥ï¼Œä¼šè‡ªåŠ¨ç”¨ 2 å€åˆ†å—é‡è¯•ï¼Œæœ€å¤š 5 è½®
    pub async fn embed_texts(&self, texts: &[String]) -> Result<Vec<Vec<f32>>> {
        if texts.is_empty() {
            return Ok(Vec::new());
        }

        log::info!("ğŸ“Š æ–‡æœ¬åµŒå…¥æœåŠ¡ï¼šå¼€å§‹å¤„ç† {} ä¸ªæ–‡æœ¬", texts.len());

        let config = self.llm_manager.get_embedding_model_config().await?;

        // è·å–æ¨¡å‹çš„ token é™åˆ¶
        let token_limits = crate::multimodal::embedding_chunker::EmbeddingTokenLimits::default();
        let base_max_tokens = token_limits.get_limit(&config.model);

        // â˜… 2026-01 ä¿®å¤ï¼šæ·»åŠ è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼Œæœ€å¤š 5 è½®ï¼Œæ¯è½®åˆ†å—é™åˆ¶å‡åŠ
        const MAX_RETRY_ROUNDS: usize = 5;
        let mut current_max_tokens = base_max_tokens;
        let mut last_error_msg: String = String::new();

        for round in 0..MAX_RETRY_ROUNDS {
            let chunker =
                crate::multimodal::embedding_chunker::EmbeddingChunker::new(current_max_tokens);

            // æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†å—
            let needs_chunking = texts.iter().any(|t| chunker.needs_chunking(t));

            let api_result = if !needs_chunking && round == 0 {
                // ç¬¬ä¸€è½®ä¸”ä¸éœ€è¦åˆ†å—ï¼Œç›´æ¥è°ƒç”¨ API
                self.llm_manager
                    .call_embedding_api(texts.to_vec(), &config.id)
                    .await
                    .map(|embeddings| (embeddings, None))
            } else {
                // éœ€è¦åˆ†å—å¤„ç†
                if round > 0 {
                    log::warn!(
                        "ğŸ“Š æ–‡æœ¬åµŒå…¥æœåŠ¡ï¼šç¬¬ {} è½®é‡è¯•ï¼Œä½¿ç”¨æ›´æ¿€è¿›çš„åˆ†å—ï¼ˆmax_tokens={}ï¼‰",
                        round + 1,
                        current_max_tokens
                    );
                } else {
                    log::info!("ğŸ“Š æ–‡æœ¬åµŒå…¥æœåŠ¡ï¼šæ£€æµ‹åˆ°é•¿æ–‡æœ¬ï¼Œå¯ç”¨åˆ†å—å¤„ç†");
                }

                // åˆ†å—å¹¶è®°å½•æ˜ å°„å…³ç³»
                let chunk_results =
                    crate::multimodal::embedding_chunker::batch_chunk_texts(texts, &chunker);

                // æ”¶é›†æ‰€æœ‰å—
                let all_chunks: Vec<String> = chunk_results
                    .iter()
                    .flat_map(|r| r.chunks.clone())
                    .collect();

                let total_chunks = all_chunks.len();
                log::info!(
                    "ğŸ“Š æ–‡æœ¬åµŒå…¥æœåŠ¡ï¼š{} ä¸ªæ–‡æœ¬åˆ†ä¸º {} ä¸ªå—ï¼ˆmax_tokens={}ï¼‰",
                    texts.len(),
                    total_chunks,
                    current_max_tokens
                );

                // æ‰¹é‡åµŒå…¥æ‰€æœ‰å—
                match self
                    .llm_manager
                    .call_embedding_api(all_chunks, &config.id)
                    .await
                {
                    Ok(all_embeddings) => {
                        // æŒ‰åŸå§‹æ–‡æœ¬ç´¢å¼•èšåˆåµŒå…¥å‘é‡
                        let mut result = Vec::with_capacity(texts.len());
                        let mut emb_idx = 0;

                        for chunk_result in &chunk_results {
                            let chunk_count = chunk_result.chunks.len();

                            if chunk_count == 0 {
                                // ç©ºæ–‡æœ¬ï¼Œè¿”å›é›¶å‘é‡
                                let dim = all_embeddings.first().map(|v| v.len()).unwrap_or(1024);
                                result.push(vec![0.0; dim]);
                            } else if chunk_count == 1 {
                                // å•å—ï¼Œç›´æ¥ä½¿ç”¨
                                result.push(all_embeddings[emb_idx].clone());
                            } else {
                                // å¤šå—ï¼Œèšåˆ
                                let chunk_embeddings: Vec<_> =
                                    all_embeddings[emb_idx..emb_idx + chunk_count].to_vec();
                                let aggregated = crate::multimodal::embedding_chunker::EmbeddingChunker::aggregate_embeddings(
                                    &chunk_embeddings,
                                    crate::multimodal::embedding_chunker::ChunkAggregation::MeanPooling,
                                );
                                log::debug!(
                                    "  æ–‡æœ¬ {} èšåˆ {} ä¸ªå—çš„åµŒå…¥å‘é‡",
                                    chunk_result.original_index,
                                    chunk_count
                                );
                                result.push(aggregated);
                            }

                            emb_idx += chunk_count;
                        }

                        Ok((result, Some(chunk_results)))
                    }
                    Err(e) => Err(e),
                }
            };

            match api_result {
                Ok((embeddings, _)) => {
                    log::info!(
                        "âœ… æ–‡æœ¬åµŒå…¥æœåŠ¡ï¼šå®Œæˆ {} ä¸ªæ–‡æœ¬çš„å‘é‡åŒ–{}ï¼Œç»´åº¦ {}",
                        embeddings.len(),
                        if round > 0 {
                            format!("ï¼ˆç¬¬ {} è½®é‡è¯•æˆåŠŸï¼‰", round + 1)
                        } else {
                            String::new()
                        },
                        embeddings.first().map(|v| v.len()).unwrap_or(0)
                    );
                    return Ok(embeddings);
                }
                Err(e) => {
                    let error_str = e.to_string();
                    // æ£€æŸ¥æ˜¯å¦æ˜¯ token è¶…é™é”™è¯¯
                    let is_token_limit_error = error_str.contains("413")
                        || error_str.contains("Payload Too Large")
                        || error_str.contains("too many tokens")
                        || error_str.contains("8192 tokens")
                        || error_str.contains("token limit");

                    if is_token_limit_error && round < MAX_RETRY_ROUNDS - 1 {
                        log::warn!(
                            "âš ï¸ æ–‡æœ¬åµŒå…¥æœåŠ¡ï¼štoken è¶…é™é”™è¯¯ï¼Œå‡†å¤‡ç¬¬ {} è½®é‡è¯•ï¼ˆå½“å‰ max_tokens={}ï¼‰: {}",
                            round + 2, current_max_tokens, error_str
                        );
                        // å‡åŠ token é™åˆ¶ï¼Œè¿›è¡Œæ›´æ¿€è¿›çš„åˆ†å—
                        current_max_tokens = current_max_tokens / 2;
                        // ç¡®ä¿ä¸ä¼šå¤ªå°
                        if current_max_tokens < 256 {
                            current_max_tokens = 256;
                        }
                        last_error_msg = error_str;
                        continue;
                    } else {
                        // ä¸æ˜¯ token è¶…é™é”™è¯¯ï¼Œæˆ–å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°
                        if round >= MAX_RETRY_ROUNDS - 1 {
                            log::error!(
                                "âŒ æ–‡æœ¬åµŒå…¥æœåŠ¡ï¼šå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•° {}ï¼Œæ”¾å¼ƒ: {}",
                                MAX_RETRY_ROUNDS,
                                error_str
                            );
                        }
                        return Err(e);
                    }
                }
            }
        }

        // ä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œï¼Œä½†ä¸ºäº†ç¼–è¯‘å™¨æ»¡æ„
        Err(AppError::internal(if last_error_msg.is_empty() {
            "åµŒå…¥å¤±è´¥ï¼šæœªçŸ¥é”™è¯¯".to_string()
        } else {
            last_error_msg
        }))
    }

    // ============================================================================
    // ç»Ÿä¸€æ¥å£ï¼šæ”¯æŒä¸¤ç§ç´¢å¼•æ¨¡å¼
    // ============================================================================

    /// æ ¹æ®ç´¢å¼•æ¨¡å¼ä¸ºé¡µé¢ç”ŸæˆåµŒå…¥å‘é‡ï¼ˆå¸¦è¿›åº¦å›è°ƒï¼‰
    ///
    /// ## å‚æ•°
    /// - `pages`: é¡µé¢æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (image_base64, media_type, text_summary)
    /// - `mode`: ç´¢å¼•æ¨¡å¼
    /// - `instruction`: å¯é€‰çš„ä»»åŠ¡æŒ‡ä»¤ï¼ˆä»…ç”¨äº VLEmbedding æ¨¡å¼ï¼‰
    /// - `progress_tx`: å¯é€‰çš„è¿›åº¦å›è°ƒé€šé“
    ///
    /// ## è¿”å›
    /// (åµŒå…¥å‘é‡åˆ—è¡¨, ç”Ÿæˆçš„æ‘˜è¦åˆ—è¡¨)
    pub async fn embed_pages_with_mode_and_progress(
        &self,
        pages: &[(String, String, Option<String>)],
        mode: MultimodalIndexingMode,
        instruction: Option<&str>,
        progress_tx: Option<mpsc::UnboundedSender<EmbeddingProgress>>,
    ) -> Result<(Vec<Vec<f32>>, Vec<Option<String>>)> {
        if pages.is_empty() {
            return Ok((Vec::new(), Vec::new()));
        }

        // ç¡®å®šå®é™…ä½¿ç”¨çš„æ¨¡å¼ï¼ˆå¦‚æœè¯·æ±‚çš„æ¨¡å¼ä¸å¯ç”¨ï¼Œè‡ªåŠ¨å›é€€ï¼‰
        let actual_mode = if self.is_mode_available(mode).await {
            mode
        } else {
            // å°è¯•å›é€€åˆ°å¦ä¸€ä¸ªæ¨¡å¼
            let fallback = match mode {
                MultimodalIndexingMode::VLEmbedding => {
                    MultimodalIndexingMode::VLSummaryThenTextEmbed
                }
                MultimodalIndexingMode::VLSummaryThenTextEmbed => {
                    MultimodalIndexingMode::VLEmbedding
                }
            };
            if self.is_mode_available(fallback).await {
                log::warn!("âš ï¸ è¯·æ±‚çš„æ¨¡å¼ {:?} ä¸å¯ç”¨ï¼Œå›é€€åˆ° {:?}", mode, fallback);
                fallback
            } else {
                return Err(AppError::configuration(
                    "æœªé…ç½®ä»»ä½•å¤šæ¨¡æ€åµŒå…¥æ¨¡å‹ã€‚è¯·åœ¨è®¾ç½®ä¸­é…ç½® VL-Embedding æ¨¡å‹æˆ– VL èŠå¤©æ¨¡å‹ + æ–‡æœ¬åµŒå…¥æ¨¡å‹ã€‚"
                ));
            }
        };

        log::info!(
            "ğŸ”„ å¤šæ¨¡æ€åµŒå…¥æœåŠ¡ï¼šä½¿ç”¨ {:?} æ¨¡å¼å¤„ç† {} ä¸ªé¡µé¢",
            actual_mode,
            pages.len()
        );

        match actual_mode {
            MultimodalIndexingMode::VLEmbedding => {
                // æ–¹æ¡ˆä¸€ï¼šç›´æ¥ä½¿ç”¨ VL-Embedding æ¨¡å‹
                let embeddings = self.embed_pages(pages, instruction).await?;
                let summaries: Vec<Option<String>> =
                    pages.iter().map(|(_, _, s)| s.clone()).collect();
                Ok((embeddings, summaries))
            }
            MultimodalIndexingMode::VLSummaryThenTextEmbed => {
                // æ–¹æ¡ˆäºŒï¼šVL æ‘˜è¦ + æ–‡æœ¬åµŒå…¥
                // æ­¥éª¤ 1: ç”Ÿæˆæ‘˜è¦ï¼ˆå¸¦è¿›åº¦å›è°ƒï¼‰
                let summaries = self
                    .generate_summaries_batch_with_progress(pages, progress_tx.clone())
                    .await?;

                // æ­¥éª¤ 2: å¯¹æ‘˜è¦è¿›è¡Œæ–‡æœ¬åµŒå…¥ï¼ˆå¸¦è¿›åº¦å›è°ƒï¼‰
                let embeddings = self
                    .embed_texts_with_progress(&summaries, progress_tx)
                    .await?;

                // è½¬æ¢æ‘˜è¦ä¸º Option<String>
                let summaries_opt: Vec<Option<String>> = summaries
                    .into_iter()
                    .map(|s| if s.is_empty() { None } else { Some(s) })
                    .collect();

                Ok((embeddings, summaries_opt))
            }
        }
    }

    /// æ ¹æ®ç´¢å¼•æ¨¡å¼ä¸ºé¡µé¢ç”ŸæˆåµŒå…¥å‘é‡ï¼ˆæ— è¿›åº¦å›è°ƒï¼‰
    pub async fn embed_pages_with_mode(
        &self,
        pages: &[(String, String, Option<String>)],
        mode: MultimodalIndexingMode,
        instruction: Option<&str>,
    ) -> Result<(Vec<Vec<f32>>, Vec<Option<String>>)> {
        self.embed_pages_with_mode_and_progress(pages, mode, instruction, None)
            .await
    }

    /// æ£€æŸ¥æŒ‡å®šæ¨¡å¼æ˜¯å¦å¯ç”¨
    pub async fn is_mode_available(&self, mode: MultimodalIndexingMode) -> bool {
        match mode {
            MultimodalIndexingMode::VLEmbedding => {
                // æ–¹æ¡ˆä¸€éœ€è¦ä¸“é—¨çš„ VL-Embedding æ¨¡å‹ï¼ˆé€šè¿‡ç»´åº¦ç®¡ç†è®¾ç½®ï¼‰
                self.is_vl_embedding_available().await
            }
            MultimodalIndexingMode::VLSummaryThenTextEmbed => {
                // å·²åºŸå¼ƒï¼šç¬¬ä¸€æ¨¡å‹ç§»é™¤ï¼ŒVL æ‘˜è¦æ–¹æ¡ˆä¸å¯ç”¨
                false
            }
        }
    }

    /// è·å–æŒ‡å®šæ¨¡å¼çš„åµŒå…¥ç»´åº¦
    ///
    /// é€šè¿‡å®é™…è°ƒç”¨ API æ£€æµ‹ç»´åº¦
    pub async fn detect_embedding_dimension_for_mode(
        &self,
        mode: MultimodalIndexingMode,
    ) -> Result<usize> {
        match mode {
            MultimodalIndexingMode::VLEmbedding => self.detect_embedding_dimension().await,
            MultimodalIndexingMode::VLSummaryThenTextEmbed => {
                // ä½¿ç”¨æ–‡æœ¬åµŒå…¥æ¨¡å‹æ£€æµ‹ç»´åº¦
                let config = self.llm_manager.get_embedding_model_config().await?;
                let embeddings = self
                    .llm_manager
                    .call_embedding_api(vec!["test".to_string()], &config.id)
                    .await?;
                embeddings
                    .first()
                    .map(|v| v.len())
                    .ok_or_else(|| AppError::configuration("æ— æ³•æ£€æµ‹æ–‡æœ¬åµŒå…¥æ¨¡å‹è¾“å‡ºç»´åº¦"))
            }
        }
    }

    /// è·å–æŒ‡å®šæ¨¡å¼çš„æ¨¡å‹ç‰ˆæœ¬æ ‡è¯†
    pub async fn get_model_version_for_mode(&self, mode: MultimodalIndexingMode) -> Result<String> {
        match mode {
            MultimodalIndexingMode::VLEmbedding => self.get_model_version().await,
            MultimodalIndexingMode::VLSummaryThenTextEmbed => {
                let config = self.llm_manager.get_embedding_model_config().await?;
                Ok(format!("text_embed:{}@{}", config.model, config.id))
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_embedding_service_config_default() {
        let config = EmbeddingServiceConfig::default();
        assert_eq!(config.batch_size, DEFAULT_BATCH_SIZE);
        assert!(config.enable_fallback);
    }

    #[test]
    fn test_prepare_inputs_with_fallback_valid_image() {
        // åˆ›å»ºä¸€ä¸ªæœ‰æ•ˆçš„ Base64 å›¾ç‰‡æ•°æ®ï¼ˆè¶³å¤Ÿé•¿ï¼‰
        let valid_base64 = "a".repeat(200);
        let input = MultimodalInput::text_and_image("test text", &valid_base64, "image/png");

        let inputs = vec![input];
        let llm_manager = create_mock_llm_manager();
        let service = MultimodalEmbeddingService::new(Arc::new(llm_manager));

        // ç”±äº LLMManager éœ€è¦çœŸå®ç¯å¢ƒï¼Œè¿™é‡Œåªæµ‹è¯•è¾“å…¥å‡†å¤‡é€»è¾‘
        // å®é™…çš„ API è°ƒç”¨æµ‹è¯•éœ€è¦é›†æˆæµ‹è¯•ç¯å¢ƒ
    }

    // è¾…åŠ©å‡½æ•°ï¼šåˆ›å»ºæ¨¡æ‹Ÿçš„ LLMManagerï¼ˆä»…ç”¨äºæµ‹è¯•ç¼–è¯‘ï¼‰
    fn create_mock_llm_manager() -> LLMManager {
        // æ³¨æ„ï¼šè¿™éœ€è¦çœŸå®çš„ Database å’Œ FileManager
        // åœ¨å•å…ƒæµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬åªéªŒè¯é€»è¾‘ï¼Œä¸è°ƒç”¨å®é™… API
        panic!("æ­¤å‡½æ•°ä»…ç”¨äºç±»å‹æ£€æŸ¥ï¼Œä¸åº”åœ¨æµ‹è¯•ä¸­å®é™…è°ƒç”¨")
    }
}
