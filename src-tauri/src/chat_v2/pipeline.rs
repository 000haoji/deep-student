//! Chat V2 ç¼–æ’å¼•æ“ (Pipeline)
//!
//! å®ç°å®Œæ•´çš„æ¶ˆæ¯å‘é€æµæ°´çº¿ï¼Œåè°ƒæ£€ç´¢ã€LLM è°ƒç”¨ã€å·¥å…·æ‰§è¡Œå’Œæ•°æ®æŒä¹…åŒ–ã€‚
//!
//! ## æµæ°´çº¿é˜¶æ®µ
//! 1. åˆ›å»ºç”¨æˆ·æ¶ˆæ¯å’ŒåŠ©æ‰‹æ¶ˆæ¯
//! 2. æ‰§è¡Œæ£€ç´¢ï¼ˆRAG/å›¾è°±/è®°å¿†/ç½‘ç»œæœç´¢ï¼‰- å¹¶è¡Œæ‰§è¡Œ
//! 3. æ„å»º system prompt
//! 4. è°ƒç”¨ LLMï¼ˆæµå¼ï¼‰
//! 5. å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆæ”¯æŒé€’å½’ï¼‰
//! 6. ä¿å­˜ç»“æœ
//!
//! ## çº¦æŸ
//! - å¹¶è¡Œæ£€ç´¢ï¼šä½¿ç”¨ `tokio::join!`
//! - å–æ¶ˆæ”¯æŒï¼šä½¿ç”¨ `tokio_util::sync::CancellationToken`
//! - å·¥å…·å¹¶è¡Œï¼šä½¿ç”¨ `futures::future::join_all`
//! - å·¥å…·é€’å½’ï¼šæœ€å¤šé€’å½’ 5 æ¬¡
//! - æ•°æ®æŒä¹…åŒ–ï¼šæ¯ä¸ªé˜¶æ®µå®Œæˆåç«‹å³ä¿å­˜

use std::collections::HashMap;
use std::sync::Arc;
use std::time::Instant;

use serde_json::{json, Value};
use sha2::{Digest, Sha256};
use tauri::{Emitter, Window};
use tokio::time::{timeout, Duration};
use tokio_util::sync::CancellationToken;
use uuid::Uuid;

use crate::llm_manager::{LLMManager, LLMStreamHooks};

use super::approval_manager::{ApprovalManager, ApprovalRequest};
use super::database::ChatV2Database;
use super::tools::builtin_retrieval_executor::BUILTIN_NAMESPACE;
use super::tools::{
    AcademicSearchExecutor, AttemptCompletionExecutor, BuiltinResourceExecutor,
    BuiltinRetrievalExecutor, CanvasToolExecutor, ChatAnkiToolExecutor, ExecutionContext,
    FetchExecutor, GeneralToolExecutor, KnowledgeExecutor, MemoryToolExecutor,
    SkillsExecutor, TemplateDesignerExecutor, ToolExecutor, ToolExecutorRegistry,
    ToolSensitivity, WorkspaceToolExecutor,
};
use crate::database::Database as MainDatabase;
use crate::models::{ChatMessage as LegacyChatMessage, MultimodalContentPart, RagSourceInfo};
use crate::tools::web_search::{do_search, SearchInput, ToolConfig as WebSearchConfig};
use crate::tools::ToolRegistry;

use super::error::{ChatV2Error, ChatV2Result};
use super::events::{event_types, ChatV2EventEmitter};
use super::prompt_builder;
use super::repo::ChatV2Repo;
// ğŸ†• VFS ç»Ÿä¸€å­˜å‚¨ï¼ˆ2025-12-07ï¼‰ï¼šä½¿ç”¨ vfs.db çš„ VfsResourceRepo
use crate::vfs::database::VfsDatabase;
use crate::vfs::repos::VfsResourceRepo;
// ğŸ†• VFS RAG ç»Ÿä¸€çŸ¥è¯†ç®¡ç†ï¼ˆ2025-01ï¼‰ï¼šä½¿ç”¨ VFS å‘é‡æ£€ç´¢
use crate::vfs::indexing::{VfsFullSearchService, VfsSearchParams};
use crate::vfs::lance_store::VfsLanceStore;
use crate::vfs::repos::MODALITY_TEXT;
use crate::vfs::multimodal_service::VfsMultimodalService;
// ğŸ†• MCP å·¥å…·æ³¨å…¥æ”¯æŒï¼šç°åœ¨ä½¿ç”¨å‰ç«¯ä¼ é€’çš„ mcp_tool_schemasï¼Œæ— éœ€åç«¯ MCP Client
use super::context::PipelineContext;
use super::resource_types::{ContentBlock, ContextRef, ContextSnapshot};
use super::types::{
    block_status, block_types, feature_flags, variant_status, AttachmentInput, ChatMessage,
    MessageBlock, MessageMeta, MessageRole, MessageSources, SendMessageRequest, SendOptions,
    SharedContext, SourceInfo, TokenUsage, ToolCall, ToolResultInfo, Variant,
};
use super::user_message_builder::{build_user_message, UserMessageParams};
use super::workspace::WorkspaceCoordinator;
use std::sync::Mutex;

// ============================================================
// å¸¸é‡å®šä¹‰
// ============================================================

/// å·¥å…·é€’å½’æœ€å¤§æ·±åº¦
pub(crate) const MAX_TOOL_RECURSION: u32 = 30;

/// é»˜è®¤å·¥å…·è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰
pub(crate) const DEFAULT_TOOL_TIMEOUT_MS: u64 = 30_000;

/// é»˜è®¤æ£€ç´¢ TopK
pub(crate) const DEFAULT_RAG_TOP_K: u32 = 5;

/// é»˜è®¤å›¾è°±æ£€ç´¢ TopK
pub(crate) const DEFAULT_GRAPH_TOP_K: u32 = 10;

/// é»˜è®¤å¤šæ¨¡æ€æ£€ç´¢ TopK
pub(crate) const DEFAULT_MULTIMODAL_TOP_K: u32 = 10;

/// ğŸ”§ P1ä¿®å¤ï¼šé»˜è®¤å†å²æ¶ˆæ¯æ•°é‡é™åˆ¶ï¼ˆæ¡æ•°ï¼Œé tokenï¼‰
/// context_limit åº”è¯¥ç”¨äº LLM çš„ token é™åˆ¶ï¼Œä¸åº”è¯¯ç”¨äºæ¶ˆæ¯æ¡æ•°
pub(crate) const DEFAULT_MAX_HISTORY_MESSAGES: usize = 50;

/// ğŸ”§ P1ä¿®å¤ï¼šLLM æµå¼è°ƒç”¨è¶…æ—¶ï¼ˆç§’ï¼‰
/// æµå¼å“åº”éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè®¾ç½®ä¸º 10 åˆ†é’Ÿ
pub(crate) const LLM_STREAM_TIMEOUT_SECS: u64 = 600;

/// ğŸ”§ P1ä¿®å¤ï¼šLLM éæµå¼è°ƒç”¨è¶…æ—¶ï¼ˆç§’ï¼‰
/// ç”¨äºæ‘˜è¦ç”Ÿæˆç­‰ç®€å•è°ƒç”¨ï¼Œè®¾ç½®ä¸º 2 åˆ†é’Ÿ
pub(crate) const LLM_NON_STREAM_TIMEOUT_SECS: u64 = 120;

/// åˆ¤æ–­ä¸€ä¸ªå­—ç¬¦ä¸²æ˜¯å¦æ˜¯ API é…ç½® ID æ ¼å¼ï¼ˆè€Œéæ¨¡å‹æ˜¾ç¤ºåç§°ï¼‰
///
/// é…ç½® ID æœ‰ä¸¤ç§å·²çŸ¥æ ¼å¼ï¼š
/// 1. `builtin-*` â€” å†…ç½®æ¨¡å‹é…ç½®ï¼ˆå¦‚ "builtin-deepseek-chat"ï¼‰
/// 2. UUID v4 â€” ç”¨æˆ·è‡ªå»ºæ¨¡å‹é…ç½®ï¼ˆå¦‚ "a1b2c3d4-e5f6-7890-abcd-ef1234567890"ï¼Œ36å­—ç¬¦ 8-4-4-4-12ï¼‰
///
/// ä¸å±äºä»¥ä¸Šæ ¼å¼çš„å­—ç¬¦ä¸²è¢«è®¤ä¸ºæ˜¯æ¨¡å‹æ˜¾ç¤ºåç§°ï¼ˆå¦‚ "Qwen/Qwen3-8B"ã€"deepseek-chat"ï¼‰ã€‚
fn is_config_id_format(id: &str) -> bool {
    if id.is_empty() {
        return false;
    }
    // 1. å†…ç½®é…ç½® ID
    if id.starts_with("builtin-") {
        return true;
    }
    // 2. UUID v4 æ ¼å¼: 8-4-4-4-12 hex digits (total 36 chars with 4 hyphens)
    id.len() == 36
        && id.chars().filter(|c| *c == '-').count() == 4
        && id.chars().all(|c| c.is_ascii_hexdigit() || c == '-')
}

/// æˆªæ–­é¢„è§ˆæ–‡æœ¬åˆ°æŒ‡å®šå­—ç¬¦æ•°ï¼ˆç”¨äºç¬”è®°å·¥å…· diff é¢„è§ˆï¼‰
fn truncate_preview(text: &str, max_chars: usize) -> String {
    let chars: Vec<char> = text.chars().collect();
    if chars.len() <= max_chars {
        text.to_string()
    } else {
        let truncated: String = chars[..max_chars].iter().collect();
        format!("{}...", truncated)
    }
}

// ============================================================
// æ£€ç´¢ç»“æœè¿‡æ»¤é…ç½®ï¼ˆæ”¹è¿› 3ï¼‰
// ============================================================

/// æ£€ç´¢ç»“æœç»å¯¹æœ€ä½åˆ†é˜ˆå€¼
/// ä½äºæ­¤åˆ†æ•°çš„ç»“æœç›´æ¥å‰”é™¤
pub(crate) const RETRIEVAL_MIN_SCORE: f32 = 0.3;

/// æ£€ç´¢ç»“æœç›¸å¯¹é˜ˆå€¼
/// ä¿ç•™ >= æœ€é«˜åˆ† * æ­¤æ¯”ä¾‹çš„ç»“æœ
pub(crate) const RETRIEVAL_RELATIVE_THRESHOLD: f32 = 0.5;

/// æ‰¹é‡é‡è¯•å˜ä½“å‚æ•°
#[derive(Debug, Clone)]
pub(crate) struct VariantRetrySpec {
    pub variant_id: String,
    pub model_id: String,
    pub config_id: String,
}

// ============================================================
// ç±»å‹è½¬æ¢å®ç°
// ============================================================

/// ä» RagSourceInfo è½¬æ¢ä¸º SourceInfo
impl From<RagSourceInfo> for SourceInfo {
    fn from(rag: RagSourceInfo) -> Self {
        Self {
            title: Some(rag.file_name.clone()),
            url: None,
            snippet: Some(rag.chunk_text.clone()),
            score: Some(rag.score),
            metadata: Some(json!({
                "documentId": rag.document_id,
                "chunkIndex": rag.chunk_index,
            })),
        }
    }
}

// ============================================================
// è¾…åŠ©å‡½æ•°ï¼ˆæ”¹è¿› 3 & 5ï¼‰
// ============================================================

/// è¿‡æ»¤ä½ç›¸å…³æ€§çš„æ£€ç´¢ç»“æœï¼ˆæ”¹è¿› 3ï¼‰
///
/// ä½¿ç”¨é˜ˆå€¼è¿‡æ»¤å’ŒåŠ¨æ€æˆªæ–­ç­–ç•¥ï¼š
/// 1. ç»å¯¹é˜ˆå€¼ï¼šscore < min_score çš„ç»“æœç›´æ¥å‰”é™¤
/// 2. ç›¸å¯¹é˜ˆå€¼ï¼šscore < max_score * relative_threshold çš„ç»“æœå‰”é™¤
/// 3. æœ€å¤§ä¿ç•™ï¼šä¿ç•™æœ€å¤š max_results æ¡ç»“æœ
///
/// # å‚æ•°
/// - `sources`: åŸå§‹æ£€ç´¢ç»“æœ
/// - `min_score`: ç»å¯¹æœ€ä½åˆ†é˜ˆå€¼
/// - `relative_threshold`: ç›¸å¯¹é˜ˆå€¼ï¼ˆç›¸å¯¹äºæœ€é«˜åˆ†çš„æ¯”ä¾‹ï¼‰
/// - `max_results`: æœ€å¤§ä¿ç•™æ•°é‡
///
/// # è¿”å›
/// è¿‡æ»¤åçš„æ£€ç´¢ç»“æœï¼ˆå·²æŒ‰åˆ†æ•°æ’åºï¼‰
fn filter_retrieval_results(
    sources: Vec<SourceInfo>,
    min_score: f32,
    relative_threshold: f32,
    max_results: usize,
) -> Vec<SourceInfo> {
    if sources.is_empty() {
        return sources;
    }

    // è·å–æœ€é«˜åˆ†
    let max_score = sources
        .iter()
        .filter_map(|s| s.score)
        .fold(0.0f32, |a, b| a.max(b));

    // è®¡ç®—åŠ¨æ€é˜ˆå€¼ï¼šå–ç»å¯¹é˜ˆå€¼å’Œç›¸å¯¹é˜ˆå€¼ä¸­çš„è¾ƒå¤§è€…
    let dynamic_threshold = min_score.max(max_score * relative_threshold);

    // è¿‡æ»¤åæŒ‰åˆ†æ•°é™åºå†æˆªæ–­ï¼Œé¿å…è¾“å…¥æ— åºæ—¶ä¸¢å¤±é«˜åˆ†ç»“æœ
    let before_count = sources.len();
    let mut filtered: Vec<SourceInfo> = sources
        .into_iter()
        .filter(|s| s.score.unwrap_or(0.0) >= dynamic_threshold)
        .collect();

    filtered.sort_by(|a, b| {
        b.score
            .unwrap_or(0.0)
            .partial_cmp(&a.score.unwrap_or(0.0))
            .unwrap_or(std::cmp::Ordering::Equal)
    });
    filtered.truncate(max_results);

    let after_count = filtered.len();
    if before_count != after_count {
        log::debug!(
            "[ChatV2::pipeline] Filtered retrieval results: {} -> {} (threshold={:.3}, max_score={:.3})",
            before_count,
            after_count,
            dynamic_threshold,
            max_score
        );
    }

    filtered
}

fn approval_scope_setting_key(tool_name: &str, arguments: &Value) -> String {
    let serialized = serde_json::to_string(arguments).unwrap_or_else(|_| "null".to_string());
    let mut hasher = Sha256::new();
    hasher.update(serialized.as_bytes());
    let fingerprint = hex::encode(hasher.finalize());
    format!("tool_approval.scope.{}.{}", tool_name, fingerprint)
}

/// å·¥å…·å®¡æ‰¹ç»“æœæšä¸¾
///
/// åŒºåˆ†ç”¨æˆ·ä¸»åŠ¨æ“ä½œä¸ç³»ç»Ÿå¼‚å¸¸ï¼Œä½¿è°ƒç”¨æ–¹èƒ½ç»™å‡ºç²¾ç¡®çš„é”™è¯¯æ¶ˆæ¯ã€‚
/// - `Approved`ï¼šç”¨æˆ·åŒæ„æ‰§è¡Œ
/// - `Rejected`ï¼šç”¨æˆ·æ˜ç¡®æ‹’ç»
/// - `Timeout`ï¼šç­‰å¾…å®¡æ‰¹è¶…æ—¶
/// - `ChannelClosed`ï¼šå®¡æ‰¹é€šé“å¼‚å¸¸å…³é—­
enum ApprovalOutcome {
    /// ç”¨æˆ·åŒæ„æ‰§è¡Œ
    Approved,
    /// ç”¨æˆ·æ˜ç¡®æ‹’ç»
    Rejected,
    /// ç­‰å¾…å®¡æ‰¹è¶…æ—¶
    Timeout,
    /// å®¡æ‰¹é€šé“å¼‚å¸¸å…³é—­
    ChannelClosed,
}

/// éªŒè¯å·¥å…·è°ƒç”¨é“¾å®Œæ•´æ€§ï¼ˆæ”¹è¿› 5ï¼‰
///
/// æ£€æŸ¥èŠå¤©å†å²ä¸­çš„å·¥å…·è°ƒç”¨é“¾æ˜¯å¦å®Œæ•´ï¼š
/// - æ¯ä¸ª tool_call å¿…é¡»æœ‰å¯¹åº”çš„ tool_result
/// - è®°å½•æœªå®Œæˆçš„è°ƒç”¨æ•°é‡
///
/// # è¿”å›
/// - true: å·¥å…·é“¾å®Œæ•´
/// - false: å­˜åœ¨æœªå®Œæˆçš„å·¥å…·è°ƒç”¨
fn validate_tool_chain(chat_history: &[LegacyChatMessage]) -> bool {
    use std::collections::HashSet;

    let mut pending_calls: HashSet<String> = HashSet::new();

    for msg in chat_history {
        // è®°å½•æ–°çš„å·¥å…·è°ƒç”¨
        if let Some(ref tc) = msg.tool_call {
            pending_calls.insert(tc.id.clone());
        }
        // ç§»é™¤å·²å®Œæˆçš„å·¥å…·è°ƒç”¨
        if let Some(ref tr) = msg.tool_result {
            pending_calls.remove(&tr.call_id);
        }
    }

    if !pending_calls.is_empty() {
        log::warn!(
            "[ChatV2::pipeline] Incomplete tool chain detected: {} pending call(s): {:?}",
            pending_calls.len(),
            pending_calls
        );
    }

    pending_calls.is_empty()
}

/// æ„å»ºä¸€ä¸ªä»…å« role/content çš„ç©º ChatMessageï¼Œå…¶ä½™å­—æ®µå‡ä¸º None/é»˜è®¤å€¼ã€‚
/// ç”¨äºåˆæˆæ¶ˆæ¯æ„é€ ï¼Œé¿å…é‡å¤ç½—åˆ— 15+ ä¸ª None å­—æ®µã€‚
fn make_empty_message(role: &str, content: String) -> LegacyChatMessage {
    LegacyChatMessage {
        role: role.to_string(),
        content,
        timestamp: chrono::Utc::now(),
        thinking_content: None,
        thought_signature: None,
        rag_sources: None,
        memory_sources: None,
        graph_sources: None,
        web_search_sources: None,
        image_paths: None,
        image_base64: None,
        doc_attachments: None,
        multimodal_content: None,
        tool_call: None,
        tool_result: None,
        overrides: None,
        relations: None,
        persistent_stable_id: None,
        metadata: None,
    }
}

/// ğŸ†• 2026-02-22: ä¸ºå·²æ¿€æ´»çš„é»˜è®¤æŠ€èƒ½è‡ªåŠ¨æ³¨å…¥åˆæˆ load_skills å·¥å…·äº¤äº’
///
/// æ¨¡å‹å¯¹ `role: tool` ç»“æœä¸­çš„æŒ‡ä»¤éµå¾ªåº¦è¿œé«˜äº user message ä¸­çš„ XML å—ã€‚
/// æ­¤å‡½æ•°åœ¨æ¶ˆæ¯å†å²å¼€å¤´ prepend ä¸€å¯¹åˆæˆçš„ assistant(tool_call) + tool(result) æ¶ˆæ¯ï¼Œ
/// ä¸çœŸå® `load_skills` è¿”å›æ ¼å¼å®Œå…¨ä¸€è‡´ã€‚
///
/// è·³è¿‡æ¡ä»¶ï¼š
/// - æ²¡æœ‰ active_skill_ids æˆ– skill_contents
/// - å†å²ä¸­å·²å­˜åœ¨çœŸå®çš„ load_skills è°ƒç”¨ï¼ˆé¿å… regenerate/retry æ—¶é‡å¤æ³¨å…¥ï¼‰
fn inject_synthetic_load_skills(
    chat_history: &mut Vec<LegacyChatMessage>,
    options: &SendOptions,
) {
    let active_ids = match options.active_skill_ids.as_ref() {
        Some(ids) if !ids.is_empty() => ids,
        _ => return,
    };
    let skill_contents = match options.skill_contents.as_ref() {
        Some(sc) if !sc.is_empty() => sc,
        _ => return,
    };

    // æ”¶é›†æœ‰å†…å®¹çš„å·²æ¿€æ´»æŠ€èƒ½
    let skills_to_inject: Vec<(&String, &String)> = active_ids
        .iter()
        .filter_map(|id| skill_contents.get(id).map(|content| (id, content)))
        .collect();

    if skills_to_inject.is_empty() {
        return;
    }

    // æ£€æŸ¥å†å²ä¸­æ˜¯å¦å·²æœ‰çœŸå®çš„ load_skills è°ƒç”¨ï¼ˆregenerate/retry åœºæ™¯ï¼‰
    let has_existing_load_skills = chat_history.iter().any(|m| {
        m.tool_call
            .as_ref()
            .map_or(false, |tc| SkillsExecutor::is_load_skills_tool(&tc.tool_name))
    });

    if has_existing_load_skills {
        log::debug!(
            "[ChatV2::pipeline] Skipping synthetic load_skills: history already contains real load_skills call"
        );
        return;
    }

    // æ„å»ºåˆæˆçš„ load_skills å·¥å…·äº¤äº’ï¼ˆä¸ SkillsExecutor è¾“å‡ºæ ¼å¼ä¸€è‡´ï¼‰
    let skill_ids: Vec<&str> = skills_to_inject.iter().map(|(id, _)| id.as_str()).collect();
    let tool_call_id = format!("tc_auto_skills_{}", uuid::Uuid::new_v4().simple());

    // 1. åˆæˆ assistant æ¶ˆæ¯ï¼ˆtool_call: load_skillsï¼‰
    let tool_call_args = json!({ "skills": skill_ids });
    let mut assistant_msg = make_empty_message("assistant", String::new());
    assistant_msg.tool_call = Some(crate::models::ToolCall {
        id: tool_call_id.clone(),
        tool_name: "load_skills".to_string(),
        args_json: tool_call_args,
    });

    // 2. æ„å»ºå·¥å…·ç»“æœå†…å®¹ï¼ˆä¸ SkillsExecutor æ ¼å¼ä¸€è‡´ï¼‰
    let mut content_parts: Vec<String> = Vec::with_capacity(skills_to_inject.len() + 1);
    for (skill_id, content) in &skills_to_inject {
        content_parts.push(format!(
            "<skill_loaded id=\"{}\">\n<instructions>\n{}\n</instructions>\n</skill_loaded>",
            skill_id, content
        ));
    }
    content_parts.push(format!(
        "\nå…±åŠ è½½ {} ä¸ªæŠ€èƒ½ã€‚è¿™äº›å·¥å…·ç°åœ¨å¯ä»¥ä½¿ç”¨äº†ã€‚",
        skills_to_inject.len()
    ));
    let full_content = content_parts.join("\n");
    let content_len = full_content.len();

    let mut tool_msg = make_empty_message("tool", full_content);
    tool_msg.tool_result = Some(crate::models::ToolResult {
        call_id: tool_call_id,
        ok: true,
        error: None,
        error_details: None,
        data_json: None,
        usage: None,
        citations: None,
    });

    // 3. Prepend åˆ°æ¶ˆæ¯å†å²å¼€å¤´ï¼ˆè¿™ä¸¤æ¡æ¶ˆæ¯ä¼šå‡ºç°åœ¨ [LLM_REVIEW_DEBUG] è¯·æ±‚ä½“æ—¥å¿—ä¸­ï¼‰
    log::info!(
        "[ChatV2::pipeline] ğŸ†• Synthetic load_skills injected: {} skill(s) {:?}, content_len={}, history {} -> {} messages",
        skills_to_inject.len(),
        skill_ids,
        content_len,
        chat_history.len(),
        chat_history.len() + 2
    );
    chat_history.insert(0, assistant_msg);
    chat_history.insert(1, tool_msg);
}

// ============================================================
// LLM æµå¼é€‚é…å™¨
// ============================================================

/// è§£æ API è¿”å›çš„ usage ä¿¡æ¯
///
/// æ”¯æŒå¤šç§ LLM API å“åº”æ ¼å¼ï¼š
/// - **OpenAI æ ¼å¼**: `prompt_tokens`, `completion_tokens`, `total_tokens`
/// - **Anthropic æ ¼å¼**: `input_tokens`, `output_tokens`, `cache_creation_input_tokens`
/// - **DeepSeek æ ¼å¼**: `prompt_tokens`, `completion_tokens`, `reasoning_tokens`
///
/// # å‚æ•°
/// - `usage`: API è¿”å›çš„ usage JSON å¯¹è±¡
///
/// # è¿”å›
/// - `Some(TokenUsage)`: è§£ææˆåŠŸ
/// - `None`: è§£æå¤±è´¥ï¼ˆæ ¼å¼ä¸æ”¯æŒæˆ–å­—æ®µç¼ºå¤±ï¼‰
pub fn parse_api_usage(usage: &Value) -> Option<TokenUsage> {
    // å°è¯• OpenAI æ ¼å¼: prompt_tokens, completion_tokens
    let prompt_tokens = usage
        .get("prompt_tokens")
        .and_then(|v| v.as_u64())
        .map(|v| v as u32);

    let completion_tokens = usage
        .get("completion_tokens")
        .and_then(|v| v.as_u64())
        .map(|v| v as u32);

    // å°è¯• Anthropic æ ¼å¼: input_tokens, output_tokens
    let input_tokens = usage
        .get("input_tokens")
        .and_then(|v| v.as_u64())
        .map(|v| v as u32);

    let output_tokens = usage
        .get("output_tokens")
        .and_then(|v| v.as_u64())
        .map(|v| v as u32);

    // ç¡®å®š prompt å’Œ completion tokens
    let (prompt, completion) = match (
        prompt_tokens,
        completion_tokens,
        input_tokens,
        output_tokens,
    ) {
        // OpenAI æ ¼å¼ä¼˜å…ˆ
        (Some(p), Some(c), _, _) => (p, c),
        // Anthropic æ ¼å¼å…œåº•
        (_, _, Some(i), Some(o)) => (i, o),
        // éƒ¨åˆ†å­—æ®µå­˜åœ¨
        (Some(p), None, _, _) => (p, 0),
        (None, Some(c), _, _) => (0, c),
        (_, _, Some(i), None) => (i, 0),
        (_, _, None, Some(o)) => (0, o),
        // æ— æ³•è§£æ
        _ => return None,
    };

    // æå– reasoning_tokens
    // - é¡¶å±‚ reasoning_tokensï¼ˆéƒ¨åˆ†ä¸­è½¬ç«™/æ—§æ ¼å¼ï¼‰
    // - åµŒå¥— completion_tokens_details.reasoning_tokensï¼ˆOpenAI oç³»åˆ—/DeepSeek V3+ æ ‡å‡†æ ¼å¼ï¼‰
    let reasoning_tokens = usage
        .get("reasoning_tokens")
        .and_then(|v| v.as_u64())
        .map(|v| v as u32)
        .or_else(|| {
            usage
                .get("completion_tokens_details")
                .and_then(|d| d.get("reasoning_tokens"))
                .and_then(|v| v.as_u64())
                .map(|v| v as u32)
        });

    // æå– cached_tokens
    // - Anthropic æ ¼å¼ï¼šcache_creation_input_tokens + cache_read_input_tokensï¼ˆåº”ç›¸åŠ ï¼‰
    // - OpenAI æ ¼å¼ï¼šprompt_tokens_details.cached_tokens
    let anthropic_cache_creation = usage
        .get("cache_creation_input_tokens")
        .and_then(|v| v.as_u64())
        .unwrap_or(0) as u32;
    let anthropic_cache_read = usage
        .get("cache_read_input_tokens")
        .and_then(|v| v.as_u64())
        .unwrap_or(0) as u32;
    let openai_cached = usage
        .get("prompt_tokens_details")
        .and_then(|d| d.get("cached_tokens"))
        .and_then(|v| v.as_u64())
        .unwrap_or(0) as u32;
    let total_cached = anthropic_cache_creation + anthropic_cache_read + openai_cached;
    let cached_tokens = if total_cached > 0 {
        Some(total_cached)
    } else {
        None
    };

    Some(TokenUsage::from_api_with_cache(
        prompt,
        completion,
        reasoning_tokens,
        cached_tokens,
    ))
}

/// Chat V2 LLM æµå¼å›è°ƒé€‚é…å™¨
///
/// å®ç° `LLMStreamHooks` traitï¼Œå°† LLM æµå¼äº‹ä»¶è½¬æ¢ä¸º Chat V2 å—çº§äº‹ä»¶ã€‚
/// åŒæ—¶æ”¶é›†å·¥å…·è°ƒç”¨è¯·æ±‚ï¼Œä¾›é€’å½’å¤„ç†ä½¿ç”¨ã€‚
///
/// ğŸ”§ æ”¯æŒ `<think>` æ ‡ç­¾è§£æï¼šæŸäº›ä¸­è½¬ç«™ï¼ˆå¦‚ yunwu.aiï¼‰ä¸æ”¯æŒ Anthropic çš„ Extended Thinking APIï¼Œ
/// è€Œæ˜¯å°†æ€ç»´é“¾ä½œä¸º `<think>` æ ‡ç­¾åµŒå…¥åˆ°æ™®é€šå†…å®¹ä¸­è¿”å›ã€‚æ­¤é€‚é…å™¨å®æ—¶è§£æè¿™äº›æ ‡ç­¾ï¼Œ
/// å°†å†…å®¹æ­£ç¡®è·¯ç”±åˆ° thinking æˆ– content å—ã€‚
pub struct ChatV2LLMAdapter {
    emitter: Arc<ChatV2EventEmitter>,
    message_id: String,
    enable_thinking: bool,
    /// thinking å— IDï¼ˆæ´»è·ƒçš„ï¼‰
    thinking_block_id: std::sync::Mutex<Option<String>>,
    /// ğŸ”§ ä¿®å¤ï¼šå·²ç»“æŸçš„ thinking å— IDï¼ˆfinalize åä¿ç•™ï¼Œç¡®ä¿ collect_round_blocks èƒ½è·å–ï¼‰
    finalized_thinking_block_id: std::sync::Mutex<Option<String>>,
    /// content å— ID
    content_block_id: std::sync::Mutex<Option<String>>,
    /// ç´¯ç§¯çš„å†…å®¹
    accumulated_content: std::sync::Mutex<String>,
    /// ç´¯ç§¯çš„æ¨ç†
    accumulated_reasoning: std::sync::Mutex<String>,
    /// æ”¶é›†çš„å·¥å…·è°ƒç”¨ï¼ˆç”¨äºé€’å½’å¤„ç†ï¼‰
    collected_tool_calls: std::sync::Mutex<Vec<ToolCall>>,
    /// å­˜å‚¨ API è¿”å›çš„ usageï¼ˆç”¨äº Token ç»Ÿè®¡ï¼‰
    api_usage: std::sync::Mutex<Option<TokenUsage>>,
    /// ğŸ”§ <think> æ ‡ç­¾è§£æçŠ¶æ€ï¼šæ˜¯å¦å½“å‰åœ¨ <think> æ ‡ç­¾å†…éƒ¨
    in_think_tag: std::sync::Mutex<bool>,
    /// ğŸ”§ <think> æ ‡ç­¾è§£æç¼“å†²åŒºï¼šç”¨äºå¤„ç†è·¨ chunk çš„æ ‡ç­¾è¾¹ç•Œ
    think_tag_buffer: std::sync::Mutex<String>,
}

impl ChatV2LLMAdapter {
    pub fn new(
        emitter: Arc<ChatV2EventEmitter>,
        message_id: String,
        enable_thinking: bool,
    ) -> Self {
        Self {
            emitter,
            message_id,
            enable_thinking,
            thinking_block_id: std::sync::Mutex::new(None),
            finalized_thinking_block_id: std::sync::Mutex::new(None),
            content_block_id: std::sync::Mutex::new(None),
            accumulated_content: std::sync::Mutex::new(String::new()),
            accumulated_reasoning: std::sync::Mutex::new(String::new()),
            collected_tool_calls: std::sync::Mutex::new(Vec::new()),
            api_usage: std::sync::Mutex::new(None),
            in_think_tag: std::sync::Mutex::new(false),
            think_tag_buffer: std::sync::Mutex::new(String::new()),
        }
    }

    /// ç”Ÿæˆå— ID
    pub(crate) fn generate_block_id() -> String {
        format!("blk_{}", Uuid::new_v4())
    }

    /// ç¡®ä¿ thinking å—å·²å¯åŠ¨
    fn ensure_thinking_started(&self) -> Option<String> {
        if !self.enable_thinking {
            return None;
        }

        let mut guard = self
            .thinking_block_id
            .lock()
            .unwrap_or_else(|e| e.into_inner());
        if guard.is_none() {
            let block_id = Self::generate_block_id();
            self.emitter.emit_start(
                event_types::THINKING,
                &self.message_id,
                Some(&block_id),
                None,
                None, // variant_id
            );
            *guard = Some(block_id.clone());
        }
        guard.clone()
    }

    /// ç¡®ä¿ content å—å·²å¯åŠ¨ï¼ˆå¿…é¡»åœ¨ thinking å—ä¹‹åï¼‰
    fn ensure_content_started(&self) -> String {
        // å…ˆç»“æŸ thinking å—ï¼ˆå¦‚æœæœ‰ï¼‰
        self.finalize_thinking();

        let mut guard = self
            .content_block_id
            .lock()
            .unwrap_or_else(|e| e.into_inner());
        if let Some(existing) = guard.clone() {
            existing
        } else {
            let block_id = Self::generate_block_id();
            self.emitter.emit_start(
                event_types::CONTENT,
                &self.message_id,
                Some(&block_id),
                None,
                None, // variant_id
            );
            *guard = Some(block_id.clone());
            block_id
        }
    }

    /// ç»“æŸ thinking å—
    fn finalize_thinking(&self) {
        let mut guard = self
            .thinking_block_id
            .lock()
            .unwrap_or_else(|e| e.into_inner());
        if let Some(block_id) = guard.take() {
            // ğŸ”§ ä¿®å¤ï¼šå¤‡ä»½ thinking å— IDï¼Œç¡®ä¿ collect_round_blocks èƒ½è·å–
            *self
                .finalized_thinking_block_id
                .lock()
                .unwrap_or_else(|e| e.into_inner()) = Some(block_id.clone());
            self.emitter
                .emit_end(event_types::THINKING, &block_id, None, None); // variant_id
        }
    }

    /// ç»“æŸæ‰€æœ‰æ´»è·ƒå—
    pub fn finalize_all(&self) {
        // ğŸ”§ å…ˆå¤„ç†ç¼“å†²åŒºä¸­å‰©ä½™çš„å†…å®¹
        self.flush_think_tag_buffer();

        // ç»“æŸ thinking
        self.finalize_thinking();

        // ç»“æŸ content
        let content_guard = self
            .content_block_id
            .lock()
            .unwrap_or_else(|e| e.into_inner());
        if let Some(ref block_id) = *content_guard {
            self.emitter
                .emit_end(event_types::CONTENT, block_id, None, None); // variant_id
        }
        // ğŸ”§ P0ä¿®å¤ï¼šå·¥å…·å—çš„ç»“æŸäº‹ä»¶ç”± execute_single_tool ç›´æ¥å‘å°„ï¼Œä¸å†åœ¨è¿™é‡Œå¤„ç†
    }

    /// ğŸ”§ åˆ·æ–° think æ ‡ç­¾ç¼“å†²åŒºä¸­å‰©ä½™çš„å†…å®¹
    fn flush_think_tag_buffer(&self) {
        let mut buffer = self
            .think_tag_buffer
            .lock()
            .unwrap_or_else(|e| e.into_inner());

        if buffer.is_empty() {
            return;
        }

        let remaining = std::mem::take(&mut *buffer);
        let in_think = *self.in_think_tag.lock().unwrap_or_else(|e| e.into_inner());
        drop(buffer);

        if in_think && self.enable_thinking {
            // å‰©ä½™å†…å®¹å±äº thinkingï¼ˆæœªé—­åˆçš„ think æ ‡ç­¾ï¼‰
            log::warn!(
                "[ChatV2::LLMAdapter] Flushing unclosed <think> tag content: {} chars",
                remaining.len()
            );
            {
                let mut guard = self
                    .accumulated_reasoning
                    .lock()
                    .unwrap_or_else(|e| e.into_inner());
                guard.push_str(&remaining);
            }
            if let Some(block_id) = self.ensure_thinking_started() {
                self.emitter
                    .emit_chunk(event_types::THINKING, &block_id, &remaining, None);
            }
        } else if !remaining.is_empty() {
            // å‰©ä½™å†…å®¹å±äº content
            {
                let mut guard = self
                    .accumulated_content
                    .lock()
                    .unwrap_or_else(|e| e.into_inner());
                guard.push_str(&remaining);
            }
            let block_id = self.ensure_content_started();
            self.emitter
                .emit_chunk(event_types::CONTENT, &block_id, &remaining, None);
        }
    }

    /// è·å–ç´¯ç§¯çš„å†…å®¹
    pub fn get_accumulated_content(&self) -> String {
        self.accumulated_content
            .lock()
            .unwrap_or_else(|e| e.into_inner())
            .clone()
    }

    /// è·å–ç´¯ç§¯çš„æ¨ç†
    pub fn get_accumulated_reasoning(&self) -> Option<String> {
        let reasoning = self
            .accumulated_reasoning
            .lock()
            .unwrap_or_else(|e| e.into_inner())
            .clone();
        log::info!(
            "[ChatV2::LLMAdapter] get_accumulated_reasoning: len={}, is_empty={}",
            reasoning.len(),
            reasoning.is_empty()
        );
        if reasoning.is_empty() {
            None
        } else {
            Some(reasoning)
        }
    }

    /// è·å– thinking å— IDï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    /// ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆè¿”å›å·²ç»“æŸçš„ thinking å— IDï¼ˆå› ä¸º finalize_thinking ä¼šæ¸…ç©ºæ´»è·ƒ IDï¼‰
    pub fn get_thinking_block_id(&self) -> Option<String> {
        // å…ˆæ£€æŸ¥å·²ç»“æŸçš„ thinking å— ID
        let finalized = self
            .finalized_thinking_block_id
            .lock()
            .unwrap_or_else(|e| e.into_inner())
            .clone();
        if finalized.is_some() {
            return finalized;
        }
        // å¦åˆ™è¿”å›æ´»è·ƒçš„ thinking å— ID
        self.thinking_block_id
            .lock()
            .unwrap_or_else(|e| e.into_inner())
            .clone()
    }

    /// è·å– content å— IDï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    pub fn get_content_block_id(&self) -> Option<String> {
        self.content_block_id
            .lock()
            .unwrap_or_else(|e| e.into_inner())
            .clone()
    }

    /// è·å–å¹¶æ¸…ç©ºæ”¶é›†çš„å·¥å…·è°ƒç”¨
    ///
    /// ç”¨äºåœ¨ LLM è°ƒç”¨å®Œæˆåè·å–éœ€è¦æ‰§è¡Œçš„å·¥å…·è°ƒç”¨ã€‚
    /// è°ƒç”¨æ­¤æ–¹æ³•ä¼šæ¸…ç©ºå†…éƒ¨æ”¶é›†çš„å·¥å…·è°ƒç”¨åˆ—è¡¨ã€‚
    pub fn take_tool_calls(&self) -> Vec<ToolCall> {
        let mut guard = self
            .collected_tool_calls
            .lock()
            .unwrap_or_else(|e| e.into_inner());
        std::mem::take(&mut *guard)
    }

    /// æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„å·¥å…·è°ƒç”¨
    pub fn has_tool_calls(&self) -> bool {
        let guard = self
            .collected_tool_calls
            .lock()
            .unwrap_or_else(|e| e.into_inner());
        !guard.is_empty()
    }

    /// è·å– API è¿”å›çš„ usageï¼ˆå¦‚æœæœ‰ï¼‰
    ///
    /// è¿”å› LLM API åœ¨æµå¼å“åº”ä¸­è¿”å›çš„ token ä½¿ç”¨é‡ã€‚
    /// å¦‚æœ API æœªè¿”å› usage ä¿¡æ¯ï¼Œåˆ™è¿”å› Noneã€‚
    pub fn get_api_usage(&self) -> Option<TokenUsage> {
        self.api_usage
            .lock()
            .unwrap_or_else(|e| e.into_inner())
            .clone()
    }

    /// å¤„ç† LLM è°ƒç”¨é”™è¯¯
    ///
    /// å‘å°„é”™è¯¯äº‹ä»¶åˆ°æ‰€æœ‰æ´»è·ƒå—ï¼Œå¹¶ç»“æŸæµå¼å¤„ç†ã€‚
    pub fn on_error(&self, error: &str) {
        log::error!(
            "[ChatV2::pipeline] LLM adapter error for message {}: {}",
            self.message_id,
            error
        );

        // å¦‚æœ content å—å·²å¯åŠ¨ä½†æœªç»“æŸï¼Œå‘å°„é”™è¯¯äº‹ä»¶
        let content_guard = self
            .content_block_id
            .lock()
            .unwrap_or_else(|e| e.into_inner());
        if let Some(ref block_id) = *content_guard {
            self.emitter
                .emit_error(event_types::CONTENT, block_id, error, None);
        }

        // ç»“æŸ thinking å—ï¼ˆå¦‚æœæœ‰ï¼‰
        self.finalize_thinking();

        // ğŸ”§ P0ä¿®å¤ï¼šå·¥å…·å—çš„é”™è¯¯äº‹ä»¶ç”± execute_single_tool ç›´æ¥å‘å°„ï¼Œä¸å†åœ¨è¿™é‡Œå¤„ç†
    }

    /// ğŸ”§ P0ä¿®å¤ï¼šæ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦ä»¥å¯èƒ½çš„ <think> æˆ– <thinking> æ ‡ç­¾å¼€å§‹å‰ç¼€ç»“å°¾
    ///
    /// è¿™ä¸ªå‡½æ•°ç²¾ç¡®æ£€æµ‹æ ‡ç­¾å‰ç¼€ï¼Œé¿å…è¯¯åŒ¹é… <table>, <td>, <tr> ç­‰ HTML æ ‡ç­¾ã€‚
    /// åªæœ‰å½“å­—ç¬¦ä¸²ä»¥ `<`, `<t`, `<th`, `<thi`, `<thin`, `<think`, `<thinki`, `<thinkin`, `<thinking` ç»“å°¾æ—¶è¿”å› trueã€‚
    fn ends_with_potential_think_start(s: &str) -> bool {
        const PREFIXES: &[&str] = &[
            "<thinking",
            "<thinkin",
            "<thinki",
            "<think",
            "<thin",
            "<thi",
            "<th",
            "<t",
            "<",
        ];
        // æ£€æŸ¥æ˜¯å¦ä»¥ä»»ä½•å¯èƒ½çš„æ ‡ç­¾å‰ç¼€ç»“å°¾
        for prefix in PREFIXES {
            if s.ends_with(prefix) {
                return true;
            }
        }
        false
    }

    /// ğŸ”§ P0ä¿®å¤ï¼šæ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦ä»¥å¯èƒ½çš„ </think> æˆ– </thinking> æ ‡ç­¾ç»“æŸå‰ç¼€ç»“å°¾
    ///
    /// è¿™ä¸ªå‡½æ•°ç²¾ç¡®æ£€æµ‹ç»“æŸæ ‡ç­¾å‰ç¼€ï¼Œé¿å…è¯¯åŒ¹é… </table>, </td> ç­‰ HTML æ ‡ç­¾ã€‚
    fn ends_with_potential_think_end(s: &str) -> bool {
        const PREFIXES: &[&str] = &[
            "</thinking",
            "</thinkin",
            "</thinki",
            "</think",
            "</thin",
            "</thi",
            "</th",
            "</t",
            "</",
            "<",
        ];
        for prefix in PREFIXES {
            if s.ends_with(prefix) {
                return true;
            }
        }
        false
    }

    fn is_builtin_retrieval_tool(tool_name: &str) -> bool {
        if let Some(stripped) = tool_name.strip_prefix("builtin-") {
            matches!(
                stripped,
                "rag_search"
                    | "multimodal_search"
                    | "unified_search"
                    | "memory_search"
                    | "web_search"
            )
        } else {
            false
        }
    }

    /// ğŸ”§ å¤„ç† think æ ‡ç­¾ç¼“å†²åŒºï¼Œå°†å†…å®¹è·¯ç”±åˆ° thinking æˆ– content å—
    ///
    /// æ”¯æŒä¸­è½¬ç«™è¿”å›çš„ `<think>...</think>` æˆ– `<thinking>...</thinking>` æ ¼å¼
    fn process_think_tag_buffer(&self) {
        // å¼€å§‹æ ‡ç­¾æ¨¡å¼ï¼ˆæ”¯æŒ <think> å’Œ <thinking>ï¼‰
        const START_TAGS: &[&str] = &["<thinking>", "<think>"];
        // ç»“æŸæ ‡ç­¾æ¨¡å¼ï¼ˆæ”¯æŒ </think> å’Œ </thinking>ï¼‰
        const END_TAGS: &[&str] = &["</thinking>", "</think>"];

        loop {
            let mut buffer = self
                .think_tag_buffer
                .lock()
                .unwrap_or_else(|e| e.into_inner());
            let in_think = *self.in_think_tag.lock().unwrap_or_else(|e| e.into_inner());

            if buffer.is_empty() {
                return;
            }

            if in_think {
                // å½“å‰åœ¨ <think> æ ‡ç­¾å†…ï¼Œå¯»æ‰¾ç»“æŸæ ‡ç­¾
                let mut found_end = false;
                let mut end_pos = 0;
                let mut tag_len = 0;

                for end_tag in END_TAGS {
                    if let Some(pos) = buffer.find(end_tag) {
                        if !found_end || pos < end_pos {
                            found_end = true;
                            end_pos = pos;
                            tag_len = end_tag.len();
                        }
                    }
                }

                if found_end {
                    // æ‰¾åˆ°ç»“æŸæ ‡ç­¾ï¼Œè¾“å‡º thinking å†…å®¹
                    let thinking_content: String = buffer.drain(..end_pos).collect();
                    // ç§»é™¤ç»“æŸæ ‡ç­¾
                    let _: String = buffer.drain(..tag_len).collect();
                    drop(buffer);

                    if !thinking_content.is_empty() && self.enable_thinking {
                        // ç´¯ç§¯æ¨ç†å†…å®¹
                        {
                            let mut guard = self
                                .accumulated_reasoning
                                .lock()
                                .unwrap_or_else(|e| e.into_inner());
                            guard.push_str(&thinking_content);
                        }
                        // å‘å°„ thinking chunk
                        if let Some(block_id) = self.ensure_thinking_started() {
                            self.emitter.emit_chunk(
                                event_types::THINKING,
                                &block_id,
                                &thinking_content,
                                None,
                            );
                        }
                    }

                    // é€€å‡º thinking æ¨¡å¼
                    *self.in_think_tag.lock().unwrap_or_else(|e| e.into_inner()) = false;
                    // ç»§ç»­å¤„ç†å‰©ä½™å†…å®¹
                } else {
                    // æœªæ‰¾åˆ°å®Œæ•´çš„ç»“æŸæ ‡ç­¾ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ½œåœ¨çš„ä¸å®Œæ•´æ ‡ç­¾
                    if Self::ends_with_potential_think_end(&buffer) {
                        // ä¿ç•™å¯èƒ½çš„ä¸å®Œæ•´æ ‡ç­¾ï¼Œç­‰å¾…æ›´å¤šæ•°æ®
                        return;
                    }
                    // æ²¡æœ‰æ½œåœ¨æ ‡ç­¾ï¼Œè¾“å‡ºæ‰€æœ‰å†…å®¹åˆ° thinking
                    let thinking_content = std::mem::take(&mut *buffer);
                    drop(buffer);

                    if !thinking_content.is_empty() && self.enable_thinking {
                        {
                            let mut guard = self
                                .accumulated_reasoning
                                .lock()
                                .unwrap_or_else(|e| e.into_inner());
                            guard.push_str(&thinking_content);
                        }
                        if let Some(block_id) = self.ensure_thinking_started() {
                            self.emitter.emit_chunk(
                                event_types::THINKING,
                                &block_id,
                                &thinking_content,
                                None,
                            );
                        }
                    }
                    return;
                }
            } else {
                // å½“å‰ä¸åœ¨ <think> æ ‡ç­¾å†…ï¼Œå¯»æ‰¾å¼€å§‹æ ‡ç­¾
                let mut found_start = false;
                let mut start_pos = 0;
                let mut tag_len = 0;

                for start_tag in START_TAGS {
                    if let Some(pos) = buffer.find(start_tag) {
                        if !found_start || pos < start_pos {
                            found_start = true;
                            start_pos = pos;
                            tag_len = start_tag.len();
                        }
                    }
                }

                if found_start {
                    // æ‰¾åˆ°å¼€å§‹æ ‡ç­¾ï¼Œå…ˆè¾“å‡ºæ ‡ç­¾å‰çš„ content
                    let content_before: String = buffer.drain(..start_pos).collect();
                    // ç§»é™¤å¼€å§‹æ ‡ç­¾
                    let _: String = buffer.drain(..tag_len).collect();
                    drop(buffer);

                    if !content_before.is_empty() {
                        // ç´¯ç§¯å†…å®¹
                        {
                            let mut guard = self
                                .accumulated_content
                                .lock()
                                .unwrap_or_else(|e| e.into_inner());
                            guard.push_str(&content_before);
                        }
                        // å‘å°„ content chunk
                        let block_id = self.ensure_content_started();
                        self.emitter.emit_chunk(
                            event_types::CONTENT,
                            &block_id,
                            &content_before,
                            None,
                        );
                    }

                    // è¿›å…¥ thinking æ¨¡å¼
                    *self.in_think_tag.lock().unwrap_or_else(|e| e.into_inner()) = true;
                    // ç»§ç»­å¤„ç†å‰©ä½™å†…å®¹
                } else {
                    // æœªæ‰¾åˆ°å®Œæ•´çš„å¼€å§‹æ ‡ç­¾ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ½œåœ¨çš„ä¸å®Œæ•´æ ‡ç­¾
                    if Self::ends_with_potential_think_start(&buffer) {
                        // æ‰¾åˆ°æœ€åä¸€ä¸ª '<' çš„ä½ç½®ï¼Œä¿ç•™å¯èƒ½çš„ä¸å®Œæ•´æ ‡ç­¾
                        if let Some(lt_pos) = buffer.rfind('<') {
                            // è¾“å‡º '<' ä¹‹å‰çš„å†…å®¹
                            let content_before: String = buffer.drain(..lt_pos).collect();
                            drop(buffer);

                            if !content_before.is_empty() {
                                {
                                    let mut guard = self
                                        .accumulated_content
                                        .lock()
                                        .unwrap_or_else(|e| e.into_inner());
                                    guard.push_str(&content_before);
                                }
                                let block_id = self.ensure_content_started();
                                self.emitter.emit_chunk(
                                    event_types::CONTENT,
                                    &block_id,
                                    &content_before,
                                    None,
                                );
                            }
                        }
                        return;
                    }
                    // æ²¡æœ‰æ½œåœ¨æ ‡ç­¾ï¼Œè¾“å‡ºæ‰€æœ‰å†…å®¹åˆ° content
                    let content = std::mem::take(&mut *buffer);
                    drop(buffer);

                    if !content.is_empty() {
                        {
                            let mut guard = self
                                .accumulated_content
                                .lock()
                                .unwrap_or_else(|e| e.into_inner());
                            guard.push_str(&content);
                        }
                        let block_id = self.ensure_content_started();
                        self.emitter
                            .emit_chunk(event_types::CONTENT, &block_id, &content, None);
                    }
                    return;
                }
            }
        }
    }
}

impl LLMStreamHooks for ChatV2LLMAdapter {
    /// ğŸ”§ å¢å¼ºçš„ on_content_chunkï¼šæ”¯æŒ `<think>` æ ‡ç­¾å®æ—¶è§£æ
    ///
    /// æŸäº›ä¸­è½¬ç«™ä¸æ”¯æŒ Anthropic Extended Thinking APIï¼Œè€Œæ˜¯å°†æ€ç»´é“¾ä½œä¸º
    /// `<think>...</think>` æˆ– `<thinking>...</thinking>` æ ‡ç­¾åµŒå…¥åˆ°æ™®é€šå†…å®¹ä¸­ã€‚
    /// æ­¤æ–¹æ³•å®æ—¶è§£æè¿™äº›æ ‡ç­¾ï¼Œå°†å†…å®¹æ­£ç¡®è·¯ç”±åˆ° thinking æˆ– content å—ã€‚
    fn on_content_chunk(&self, text: &str) {
        if text.is_empty() {
            return;
        }

        // ğŸ”§ <think> æ ‡ç­¾è§£æï¼šå°† chunk è¿½åŠ åˆ°ç¼“å†²åŒºå¹¶å¤„ç†
        {
            let mut buffer = self
                .think_tag_buffer
                .lock()
                .unwrap_or_else(|e| e.into_inner());
            buffer.push_str(text);
        }
        self.process_think_tag_buffer();
    }

    fn on_reasoning_chunk(&self, text: &str) {
        if text.is_empty() || !self.enable_thinking {
            return;
        }

        // ç´¯ç§¯æ¨ç†ï¼ˆç®€åŒ–æ—¥å¿—ï¼šåªè¾“å‡º / ä»£è¡¨æ¥æ”¶åˆ° chunkï¼‰
        {
            let mut guard = self
                .accumulated_reasoning
                .lock()
                .unwrap_or_else(|e| e.into_inner());
            guard.push_str(text);
            // æ¯ 500 å­—ç¬¦è¾“å‡ºä¸€ä¸ª / ä»¥å‡å°‘æ—¥å¿—é‡
            if guard.len() % 500 < text.len() {
                print!("/");
                use std::io::Write;
                let _ = std::io::stdout().flush();
            }
        }

        if let Some(block_id) = self.ensure_thinking_started() {
            self.emitter
                .emit_chunk(event_types::THINKING, &block_id, text, None);
        }
    }

    /// ğŸ†• 2026-01-15: å·¥å…·è°ƒç”¨å‚æ•°å¼€å§‹ç´¯ç§¯æ—¶é€šçŸ¥å‰ç«¯
    /// åœ¨ LLM å¼€å§‹ç”Ÿæˆå·¥å…·è°ƒç”¨å‚æ•°æ—¶ç«‹å³è°ƒç”¨ï¼Œè®©å‰ç«¯æ˜¾ç¤º"æ­£åœ¨å‡†å¤‡å·¥å…·è°ƒç”¨"
    fn on_tool_call_start(&self, tool_call_id: &str, tool_name: &str) {
        log::info!(
            "[ChatV2::pipeline] Tool call start: id={}, name={} (å‚æ•°ç´¯ç§¯ä¸­...)",
            tool_call_id,
            tool_name
        );

        // ğŸ”§ 2026-01-16: æ£€ç´¢å·¥å…·ï¼ˆbuiltin-*ï¼‰æœ‰è‡ªå·±çš„äº‹ä»¶ç±»å‹å’Œå—æ¸²æŸ“å™¨
        // å¦‚æœå‘å°„ tool_call_preparingï¼Œä¼šåˆ›å»ºä¸€ä¸ª mcp_tool ç±»å‹çš„ preparing å—
        // ä½†æ£€ç´¢å·¥å…·çš„ execute_* æ–¹æ³•ä¼šåˆ›å»ºå¦ä¸€ä¸ªæ£€ç´¢ç±»å‹å—ï¼ˆå¦‚ web_searchï¼‰
        // ç”±äºæ£€ç´¢å·¥å…·ä¸å‘å°„ tool_call_startï¼Œpreparing å—ä¸ä¼šè¢«å¤ç”¨ï¼Œå¯¼è‡´ä¸¤ä¸ªå—
        // è§£å†³æ–¹æ¡ˆï¼šæ£€ç´¢å·¥å…·è·³è¿‡ tool_call_preparing äº‹ä»¶
        if Self::is_builtin_retrieval_tool(tool_name) {
            log::debug!(
                "[ChatV2::pipeline] Skipping tool_call_preparing for builtin retrieval tool: {}",
                tool_name
            );
            return;
        }

        // å‘å°„ tool_call_preparing äº‹ä»¶ï¼Œè®©å‰ç«¯æ˜¾ç¤º"æ­£åœ¨å‡†å¤‡å·¥å…·è°ƒç”¨"çŠ¶æ€
        // ä½¿ç”¨æ–°çš„äº‹ä»¶ç±»å‹ï¼Œå‰ç«¯å¯ä»¥æ®æ­¤æ˜¾ç¤ºå·¥å…·è°ƒç”¨å‡†å¤‡ä¸­çš„ UI
        self.emitter
            .emit_tool_call_preparing(&self.message_id, tool_call_id, tool_name);
    }

    fn on_tool_call(&self, msg: &LegacyChatMessage) {
        // ä» ChatMessage ä¸­æå–å·¥å…·è°ƒç”¨ä¿¡æ¯
        if let Some(ref tool_call) = msg.tool_call {
            let tool_call_id = &tool_call.id;
            let tool_name = &tool_call.tool_name;
            let tool_input = tool_call.args_json.clone();

            // ğŸ”§ P0ä¿®å¤ï¼šç§»é™¤ block_id ç”Ÿæˆå’Œ active_tool_blocks æ˜ å°„
            // block_id ç»Ÿä¸€åœ¨ execute_single_tool ä¸­ç”Ÿæˆï¼Œå¹¶è®°å½•åˆ° ToolResultInfo.block_id
            // è¿™é¿å…äº†å‰ç«¯äº‹ä»¶ block_id å’Œæ•°æ®åº“ä¿å­˜ block_id ä¸ä¸€è‡´çš„é—®é¢˜

            // æ”¶é›†å·¥å…·è°ƒç”¨ä¿¡æ¯ä¾› Pipeline æ‰§è¡Œ
            {
                let mut guard = self
                    .collected_tool_calls
                    .lock()
                    .unwrap_or_else(|e| e.into_inner());
                guard.push(ToolCall {
                    id: tool_call_id.clone(),
                    name: tool_name.clone(),
                    arguments: tool_input.clone(),
                });
                log::info!(
                    "[ChatV2::pipeline] Collected tool call: id={}, name={}",
                    tool_call_id,
                    tool_name
                );
            }

            // ğŸ”§ P0ä¿®å¤ï¼šä¸å†å‘å°„ start äº‹ä»¶
            // start/end äº‹ä»¶ç»Ÿä¸€ç”± execute_single_tool å‘å°„
        }
    }

    fn on_tool_result(&self, msg: &LegacyChatMessage) {
        // ğŸ”§ P0ä¿®å¤ï¼šç”±äº disable_tools=trueï¼ŒLLM Manager ä¸ä¼šå†…éƒ¨æ‰§è¡Œå·¥å…·
        // å› æ­¤è¿™ä¸ªå›è°ƒä¸ä¼šè¢«è°ƒç”¨ã€‚å·¥å…·ç»“æœäº‹ä»¶ç”± execute_single_tool ç›´æ¥å‘å°„ã€‚
        // ä¿ç•™æ­¤æ–¹æ³•ä»…ä¸ºæ»¡è¶³ LLMStreamHooks trait è¦æ±‚ã€‚
        if let Some(ref tool_result) = msg.tool_result {
            log::debug!(
                "[ChatV2::pipeline] on_tool_result called (unexpected in Chat V2): call_id={}",
                tool_result.call_id
            );
        }
    }

    fn on_usage(&self, usage: &Value) {
        // è§£æ API è¿”å›çš„ usageï¼Œæ”¯æŒå¤šç§æ ¼å¼
        // æ³¨æ„ï¼šæµå¼å“åº”ä¸­æ¯ä¸ª token éƒ½ä¼šè§¦å‘ usage æ›´æ–°ï¼Œè¿™é‡Œåªå­˜å‚¨ä¸æ‰“å°æ—¥å¿—
        // æœ€ç»ˆ usage ä¼šåœ¨ LLM è°ƒç”¨ç»“æŸåçš„ Token usage for round æ—¥å¿—ä¸­è¾“å‡º
        let token_usage = parse_api_usage(usage);

        if let Some(u) = token_usage {
            // å­˜å‚¨åˆ° api_usage å­—æ®µï¼ˆå¤šæ¬¡è°ƒç”¨æ—¶è¦†ç›–ä¹‹å‰çš„å€¼ï¼‰
            let mut guard = self.api_usage.lock().unwrap_or_else(|e| e.into_inner());
            *guard = Some(u);
        }
        // ç§»é™¤æ¯æ¬¡è°ƒç”¨çš„æ—¥å¿—è¾“å‡ºï¼Œé¿å…æµå¼å“åº”æ—¶äº§ç”Ÿå¤§é‡é‡å¤æ—¥å¿—
    }

    fn on_complete(&self, _final_text: &str, _reasoning: Option<&str>) {
        self.finalize_all();
    }
}

// ============================================================
// æµæ°´çº¿ä¸»ç»“æ„
// ============================================================

/// Chat V2 ç¼–æ’å¼•æ“
///
/// åè°ƒæ•´ä¸ªæ¶ˆæ¯å‘é€æµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
/// - æ¶ˆæ¯åˆ›å»º
/// - æ£€ç´¢æ‰§è¡Œ
/// - LLM è°ƒç”¨
/// - å·¥å…·å¤„ç†
/// - æ•°æ®æŒä¹…åŒ–
#[derive(Clone)]
pub struct ChatV2Pipeline {
    db: Arc<ChatV2Database>,
    /// ä¸»æ•°æ®åº“ï¼ˆç”¨äºå·¥å…·è°ƒç”¨è¯»å–ç”¨æˆ·é…ç½®ï¼‰
    main_db: Option<Arc<MainDatabase>>,
    /// Anki æ•°æ®åº“ï¼ˆç”¨äº Anki åˆ¶å¡å·¥å…·è¿›åº¦æŸ¥è¯¢ï¼‰
    anki_db: Option<Arc<MainDatabase>>,
    /// VFS æ•°æ®åº“ï¼ˆç”¨äºç»Ÿä¸€èµ„æºå­˜å‚¨ï¼‰
    /// ğŸ†• VFS ç»Ÿä¸€å­˜å‚¨ï¼ˆ2025-12-07ï¼‰ï¼šæ‰€æœ‰èµ„æºæ“ä½œä½¿ç”¨æ­¤æ•°æ®åº“
    vfs_db: Option<Arc<VfsDatabase>>,
    llm_manager: Arc<LLMManager>,
    tool_registry: Arc<ToolRegistry>,
    /// ç¬”è®°ç®¡ç†å™¨ï¼ˆç”¨äº Canvas å·¥å…·è°ƒç”¨ï¼‰
    notes_manager: Option<Arc<crate::notes_manager::NotesManager>>,
    /// ğŸ†• å·¥å…·æ‰§è¡Œå™¨æ³¨å†Œè¡¨ï¼ˆæ–‡æ¡£ 29 P0-1ï¼‰
    executor_registry: Arc<ToolExecutorRegistry>,
    /// ğŸ†• å·¥å…·å®¡æ‰¹ç®¡ç†å™¨ï¼ˆæ–‡æ¡£ 29 P1-3ï¼‰
    approval_manager: Option<Arc<ApprovalManager>>,
    workspace_coordinator: Option<Arc<WorkspaceCoordinator>>,
    /// ğŸ†• æ™ºèƒ½é¢˜ç›®é›†æœåŠ¡ï¼ˆç”¨äº qbank_* MCP å·¥å…·ï¼Œ2026-01ï¼‰
    question_bank_service: Option<Arc<crate::question_bank_service::QuestionBankService>>,
    /// ğŸ†• PDF å¤„ç†æœåŠ¡ï¼ˆç”¨äºè®ºæ–‡ä¿å­˜åè§¦å‘ OCR/å‹ç¼© Pipelineï¼‰
    pdf_processing_service: Option<Arc<crate::vfs::pdf_processing_service::PdfProcessingService>>,
}

impl ChatV2Pipeline {
    /// åˆ›å»ºæ–°çš„æµæ°´çº¿å®ä¾‹
    ///
    /// ## å‚æ•°
    /// - `db`: Chat V2 ç‹¬ç«‹æ•°æ®åº“
    /// - `main_db`: ä¸»æ•°æ®åº“ï¼ˆå¯é€‰ï¼Œç”¨äºå·¥å…·è°ƒç”¨è¯»å–ç”¨æˆ·é…ç½®ï¼‰
    /// - `vfs_db`: VFS æ•°æ®åº“ï¼ˆå¯é€‰ï¼Œç”¨äºç»Ÿä¸€èµ„æºå­˜å‚¨ï¼‰
    /// - `llm_manager`: LLM ç®¡ç†å™¨
    /// - `tool_registry`: å·¥å…·æ³¨å†Œè¡¨
    /// - `notes_manager`: ç¬”è®°ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼Œç”¨äº Canvas å·¥å…·è°ƒç”¨ï¼‰
    ///
    pub fn new(
        db: Arc<ChatV2Database>,
        main_db: Option<Arc<MainDatabase>>,
        anki_db: Option<Arc<MainDatabase>>,
        vfs_db: Option<Arc<VfsDatabase>>,
        llm_manager: Arc<LLMManager>,
        tool_registry: Arc<ToolRegistry>,
        notes_manager: Option<Arc<crate::notes_manager::NotesManager>>,
    ) -> Self {
        // ğŸ†• åˆå§‹åŒ–å·¥å…·æ‰§è¡Œå™¨æ³¨å†Œè¡¨ï¼ˆæ–‡æ¡£ 29 P0-1ï¼‰
        let executor_registry = Self::create_executor_registry();

        Self {
            db,
            main_db,
            anki_db,
            vfs_db,
            llm_manager,
            tool_registry,
            notes_manager,
            executor_registry,
            approval_manager: None,
            workspace_coordinator: None,
            question_bank_service: None,
            pdf_processing_service: None,
        }
    }

    /// è®¾ç½®å®¡æ‰¹ç®¡ç†å™¨
    ///
    /// ğŸ†• æ–‡æ¡£ 29 P1-3ï¼šæ•æ„Ÿå·¥å…·éœ€è¦ç”¨æˆ·å®¡æ‰¹
    pub fn with_approval_manager(mut self, approval_manager: Arc<ApprovalManager>) -> Self {
        self.approval_manager = Some(approval_manager);
        self
    }

    pub fn with_workspace_coordinator(mut self, coordinator: Arc<WorkspaceCoordinator>) -> Self {
        self.workspace_coordinator = Some(coordinator.clone());
        self.executor_registry = Self::create_executor_registry_with_workspace(Some(coordinator));
        self
    }

    /// ğŸ†• è®¾ç½®æ™ºèƒ½é¢˜ç›®é›†æœåŠ¡ï¼ˆç”¨äº qbank_* MCP å·¥å…·ï¼Œ2026-01ï¼‰
    pub fn with_question_bank_service(
        mut self,
        service: Arc<crate::question_bank_service::QuestionBankService>,
    ) -> Self {
        self.question_bank_service = Some(service);
        self
    }

    /// ğŸ†• è®¾ç½® PDF å¤„ç†æœåŠ¡ï¼ˆç”¨äºè®ºæ–‡ä¿å­˜åè§¦å‘ OCR/å‹ç¼© Pipelineï¼‰
    pub fn with_pdf_processing_service(
        mut self,
        service: Option<Arc<crate::vfs::pdf_processing_service::PdfProcessingService>>,
    ) -> Self {
        self.pdf_processing_service = service;
        self
    }

    fn create_executor_registry() -> Arc<ToolExecutorRegistry> {
        Self::create_executor_registry_with_workspace(None)
    }

    fn create_executor_registry_with_workspace(
        workspace_coordinator: Option<Arc<WorkspaceCoordinator>>,
    ) -> Arc<ToolExecutorRegistry> {
        let mut registry = ToolExecutorRegistry::new();

        registry.register(Arc::new(AttemptCompletionExecutor::new()));
        registry.register(Arc::new(CanvasToolExecutor::new()));
        // AnkiToolExecutor å·²ç§»é™¤ â€” æ—§ CardForge 2.0 ç®¡çº¿ç”± ChatAnki å®Œå…¨æ¥ç®¡
        registry.register(Arc::new(ChatAnkiToolExecutor::new()));
        registry.register(Arc::new(BuiltinRetrievalExecutor::new()));
        registry.register(Arc::new(BuiltinResourceExecutor::new()));
        registry.register(Arc::new(super::tools::AttachmentToolExecutor::new())); // ğŸ†• é™„ä»¶å·¥å…·æ‰§è¡Œå™¨ï¼ˆè§£å†³ P0 æ–­è£‚ç‚¹ï¼‰
        registry.register(Arc::new(FetchExecutor::new())); // ğŸ†• å†…ç½® Web Fetch å·¥å…·
        registry.register(Arc::new(AcademicSearchExecutor::new())); // ğŸ†• å­¦æœ¯è®ºæ–‡æœç´¢å·¥å…·ï¼ˆarXiv + OpenAlexï¼‰
        registry.register(Arc::new(super::tools::PaperSaveExecutor::new())); // ğŸ†• è®ºæ–‡ä¿å­˜+å¼•ç”¨æ ¼å¼åŒ–å·¥å…·
        registry.register(Arc::new(KnowledgeExecutor::new()));
        registry.register(Arc::new(super::tools::TodoListExecutor::new()));
        registry.register(Arc::new(super::tools::qbank_executor::QBankExecutor::new()));
        registry.register(Arc::new(MemoryToolExecutor::new()));
        registry.register(Arc::new(super::tools::SkillsExecutor::new())); // ğŸ†• Skills å·¥å…·æ‰§è¡Œå™¨ï¼ˆæ¸è¿›æŠ«éœ²æ¶æ„ï¼‰
        registry.register(Arc::new(TemplateDesignerExecutor::new())); // ğŸ†• æ¨¡æ¿è®¾è®¡å¸ˆå·¥å…·æ‰§è¡Œå™¨
        registry.register(Arc::new(super::tools::AskUserExecutor::new())); // ğŸ†• ç”¨æˆ·æé—®å·¥å…·æ‰§è¡Œå™¨
        registry.register(Arc::new(super::tools::DocxToolExecutor::new())); // ğŸ†• DOCX æ–‡æ¡£è¯»å†™å·¥å…·æ‰§è¡Œå™¨
        registry.register(Arc::new(super::tools::PptxToolExecutor::new())); // ğŸ†• PPTX æ¼”ç¤ºæ–‡ç¨¿è¯»å†™å·¥å…·æ‰§è¡Œå™¨
        registry.register(Arc::new(super::tools::XlsxToolExecutor::new())); // ğŸ†• XLSX ç”µå­è¡¨æ ¼è¯»å†™å·¥å…·æ‰§è¡Œå™¨

        if let Some(coordinator) = workspace_coordinator {
            registry.register(Arc::new(WorkspaceToolExecutor::new(coordinator.clone())));
            // æ³¨å†Œ SubagentExecutorï¼ˆsubagent_call è¯­æ³•ç³–ï¼‰
            registry.register(Arc::new(super::tools::SubagentExecutor::new(
                coordinator.clone(),
            )));
            // ğŸ†• æ³¨å†Œ CoordinatorSleepExecutorï¼ˆä¸»ä»£ç†ç¡çœ /å”¤é†’æœºåˆ¶ï¼‰
            registry.register(Arc::new(super::tools::CoordinatorSleepExecutor::new(
                coordinator,
            )));
        }

        registry.register(Arc::new(GeneralToolExecutor::new()));

        log::info!(
            "[ChatV2::pipeline] ToolExecutorRegistry initialized with {} executors: {:?}",
            registry.len(),
            registry.executor_names()
        );

        Arc::new(registry)
    }

    /// æ ¹æ®å·¥å…·åç§°åˆ¤æ–­æ­£ç¡®çš„ block_type
    ///
    /// æ£€ç´¢å·¥å…·ä½¿ç”¨å¯¹åº”çš„æ£€ç´¢å—ç±»å‹ï¼Œå…¶ä»–å·¥å…·ä½¿ç”¨ mcp_tool ç±»å‹ã€‚
    /// è¿™ç¡®ä¿å‰ç«¯æ¸²æŸ“æ—¶ä½¿ç”¨æ­£ç¡®çš„å—æ¸²æŸ“å™¨ã€‚
    ///
    /// ## å‚æ•°
    /// - `tool_name`: å·¥å…·åç§°ï¼ˆå¯èƒ½å¸¦æœ‰ builtin- å‰ç¼€ï¼‰
    ///
    /// ## è¿”å›
    /// å¯¹åº”çš„ block_type å­—ç¬¦ä¸²
    fn tool_name_to_block_type(tool_name: &str) -> String {
        let stripped = Self::normalize_tool_name_for_skill_match(tool_name);

        match stripped {
            "rag_search" | "multimodal_search" | "unified_search" => block_types::RAG.to_string(),
            "memory_search" => block_types::MEMORY.to_string(),
            "web_search" => block_types::WEB_SEARCH.to_string(),
            "ask_user" => block_types::ASK_USER.to_string(),
            _ => block_types::MCP_TOOL.to_string(),
        }
    }

    pub(crate) fn normalize_tool_name_for_skill_match(tool_name: &str) -> &str {
        tool_name
            .strip_prefix("builtin-")
            .or_else(|| tool_name.strip_prefix("mcp_"))
            .unwrap_or(tool_name)
    }

    pub(crate) fn skill_allows_tool(tool_name: &str, allowed: &str) -> bool {
        let tool_raw = tool_name.to_lowercase();
        let allowed_raw = allowed.to_lowercase();

        let tool_normalized = Self::normalize_tool_name_for_skill_match(&tool_raw);
        let allowed_normalized = Self::normalize_tool_name_for_skill_match(&allowed_raw);

        tool_raw == allowed_raw
            || tool_normalized == allowed_normalized
            || tool_normalized.starts_with(&format!("{}_", allowed_normalized))
            || tool_normalized.starts_with(allowed_normalized)
    }

    /// æ‰§è¡Œæ¶ˆæ¯å‘é€æµæ°´çº¿
    ///
    /// ## æµç¨‹
    /// 1. åˆ›å»ºç”¨æˆ·æ¶ˆæ¯å’ŒåŠ©æ‰‹æ¶ˆæ¯
    /// 2. æ‰§è¡Œæ£€ç´¢ï¼ˆRAG/å›¾è°±/è®°å¿†/ç½‘ç»œæœç´¢ï¼‰
    /// 3. æ„å»º system prompt
    /// 4. è°ƒç”¨ LLMï¼ˆæµå¼ï¼‰
    /// 5. å¤„ç†å·¥å…·è°ƒç”¨
    /// 6. ä¿å­˜ç»“æœ
    ///
    /// ## å‚æ•°
    /// - `window`: Tauri çª—å£ï¼Œç”¨äºäº‹ä»¶å‘å°„
    /// - `request`: å‘é€æ¶ˆæ¯è¯·æ±‚
    /// - `cancel_token`: å–æ¶ˆä»¤ç‰Œ
    ///
    /// ## è¿”å›
    /// åŠ©æ‰‹æ¶ˆæ¯ ID
    /// ğŸ”§ P1ä¿®å¤ï¼šæ·»åŠ  chat_v2_state å‚æ•°ï¼Œç”¨äºæ³¨å†Œæ¯ä¸ªå˜ä½“çš„ cancel token
    pub async fn execute(
        &self,
        window: Window,
        mut request: SendMessageRequest,
        cancel_token: CancellationToken,
        chat_v2_state: Option<Arc<super::state::ChatV2State>>,
    ) -> ChatV2Result<String> {
        // === Feature Flag æ£€æŸ¥ ===
        let multi_variant_enabled = feature_flags::is_multi_variant_enabled();
        log::info!(
            "[ChatV2::pipeline] Feature flags: {}",
            feature_flags::get_flags_summary()
        );

        // === å¤šå˜ä½“æ¨¡å¼æ£€æŸ¥ ===
        // å¦‚æœ parallel_model_ids æœ‰ 2+ ä¸ªæ¨¡å‹ï¼Œèµ°å¤šå˜ä½“æ‰§è¡Œè·¯å¾„
        // ğŸ”§ è°ƒè¯•æ—¥å¿—ï¼šæ‰“å°æ”¶åˆ°çš„ options
        log::info!(
            "[ChatV2::pipeline] execute() received options: {:?}",
            request.options.as_ref().map(|o| format!(
                "parallelModelIds={:?}, modelId={:?}",
                o.parallel_model_ids, o.model_id
            ))
        );

        // æ³¨æ„ï¼šå…ˆæå– model_ids é¿å…å€Ÿç”¨é—®é¢˜
        let multi_variant_model_ids = request
            .options
            .as_ref()
            .and_then(|opts| opts.parallel_model_ids.as_ref())
            .filter(|ids| ids.len() >= 2)
            .cloned();

        // === Feature Flag æ‹¦æˆªï¼šå¦‚æœå¤šå˜ä½“åŠŸèƒ½å…³é—­ï¼Œå¼ºåˆ¶èµ°å•å˜ä½“è·¯å¾„ ===
        if let Some(ref model_ids) = multi_variant_model_ids {
            if !multi_variant_enabled {
                log::warn!(
                    "[ChatV2::pipeline] Multi-variant DISABLED by feature flag. \
                     Received {} models, forcing single-variant mode with first model: {:?}",
                    model_ids.len(),
                    model_ids.first()
                );

                // å¼ºåˆ¶ä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å‹èµ°å•å˜ä½“è·¯å¾„
                if let Some(first_model) = model_ids.first() {
                    // ä¿®æ”¹ request.options.model_id ä¸ºç¬¬ä¸€ä¸ªæ¨¡å‹
                    if let Some(ref mut opts) = request.options {
                        opts.model_id = Some(first_model.clone());
                        // æ¸…é™¤ parallel_model_ids é˜²æ­¢åç»­é€»è¾‘è¯¯åˆ¤
                        opts.parallel_model_ids = None;
                    }
                }
                // ç»§ç»­æ‰§è¡Œä¸‹é¢çš„å•å˜ä½“è·¯å¾„ï¼Œä¸è¿›å…¥å¤šå˜ä½“åˆ†æ”¯
            } else {
                // Feature flag å¯ç”¨ï¼Œæ­£å¸¸èµ°å¤šå˜ä½“è·¯å¾„
                log::info!(
                    "[ChatV2::pipeline] Multi-variant mode detected: {} models",
                    model_ids.len()
                );
                return self
                    .execute_multi_variant(
                        window,
                        request,
                        model_ids.clone(),
                        cancel_token,
                        chat_v2_state,
                    )
                    .await;
            }
        }

        // === å•å˜ä½“æ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰===
        let mut ctx = PipelineContext::new(request);
        // ğŸ†• è®¾ç½®å–æ¶ˆä»¤ç‰Œï¼šä¼ é€’ç»™å·¥å…·æ‰§è¡Œå™¨ï¼Œæ”¯æŒå·¥å…·æ‰§è¡Œå–æ¶ˆ
        ctx.set_cancellation_token(cancel_token.clone());
        let session_id = ctx.session_id.clone();
        let assistant_message_id = ctx.assistant_message_id.clone();

        // åˆ›å»ºäº‹ä»¶å‘å°„å™¨
        let emitter = Arc::new(ChatV2EventEmitter::new(window.clone(), session_id.clone()));

        // è·å–æ¨¡å‹åç§°ç”¨äºå‰ç«¯æ˜¾ç¤º
        // ä» API é…ç½®ä¸­è§£æ model_id åˆ°çœŸæ­£çš„æ¨¡å‹åç§°ï¼ˆå¦‚ "Qwen/Qwen3-8B"ï¼‰
        log::info!(
            "[ChatV2::pipeline] Single variant: options.model_id = {:?}",
            ctx.options.model_id
        );

        let model_name: Option<String> =
            if let Some(config_id) = ctx.options.model_id.as_ref().filter(|s| !s.is_empty()) {
                // æœ‰æŒ‡å®šæ¨¡å‹ IDï¼Œä» API é…ç½®ä¸­æŸ¥æ‰¾
                match self.llm_manager.get_api_configs().await {
                    Ok(configs) => {
                        log::info!(
                            "[ChatV2::pipeline] Found {} API configs, looking for config_id: {}",
                            configs.len(),
                            config_id
                        );
                        // ğŸ”§ Bugä¿®å¤ï¼šä¼˜å…ˆé€šè¿‡ c.id åŒ¹é…ï¼Œå¦‚æœæ‰¾ä¸åˆ°å†é€šè¿‡ c.model åŒ¹é…
                        // è¿™æ ·æ— è®ºå‰ç«¯ä¼ é€’çš„æ˜¯ API é…ç½® IDï¼ˆUUIDï¼‰è¿˜æ˜¯æ¨¡å‹æ˜¾ç¤ºåç§°ï¼Œéƒ½èƒ½æ­£ç¡®è§£æ
                        let found = configs
                            .iter()
                            .find(|c| &c.id == config_id)
                            .map(|c| c.model.clone())
                            .or_else(|| {
                                // å¦‚æœé€šè¿‡ id æ‰¾ä¸åˆ°ï¼Œå°è¯•é€šè¿‡ model åç§°åŒ¹é…
                                // è¿™å¤„ç†äº† config_id æœ¬èº«å°±æ˜¯æ¨¡å‹æ˜¾ç¤ºåç§°çš„æƒ…å†µ
                                configs
                                    .iter()
                                    .find(|c| &c.model == config_id)
                                    .map(|c| c.model.clone())
                            })
                            .or_else(|| {
                                // ğŸ”§ æœ€åçš„å›é€€ï¼šåˆ¤æ–­ config_id æ˜¯å¦æ˜¯ API é…ç½® IDï¼ˆä¸å¯ä½œä¸ºæ˜¾ç¤ºåç§°ï¼‰
                                // é…ç½® ID æœ‰ä¸¤ç§å·²çŸ¥æ ¼å¼ï¼š
                                //   1. builtin-* ï¼ˆå†…ç½®æ¨¡å‹ï¼Œå¦‚ "builtin-deepseek-chat"ï¼‰
                                //   2. UUID æ ¼å¼ ï¼ˆç”¨æˆ·è‡ªå»ºæ¨¡å‹ï¼Œå¦‚ "a1b2c3d4-e5f6-7890-abcd-ef1234567890"ï¼‰
                                // å¦‚æœ config_id ä¸å±äºè¿™ä¸¤ç§æ ¼å¼ï¼Œåˆ™è®¤ä¸ºå®ƒæœ¬èº«å°±æ˜¯æ¨¡å‹æ˜¾ç¤ºåç§°
                                // ï¼ˆä¾‹å¦‚åˆ é™¤äº†é…ç½®åé‡è¯•æ—§æ¶ˆæ¯ï¼Œconfig_id ä¸­ä¿å­˜çš„å¯èƒ½æ˜¯æ—§çš„æ¨¡å‹åï¼‰
                                if is_config_id_format(config_id) {
                                    log::warn!(
                                        "[ChatV2::pipeline] config_id is a config UUID/builtin ID, not usable as display name: {}",
                                        config_id
                                    );
                                    None
                                } else {
                                    log::info!(
                                        "[ChatV2::pipeline] Using config_id as model_name directly (not a config ID pattern): {}",
                                        config_id
                                    );
                                    Some(config_id.clone())
                                }
                            });
                        log::info!("[ChatV2::pipeline] Resolved model_name: {:?}", found);
                        found
                    }
                    Err(e) => {
                        log::warn!(
                            "[ChatV2::pipeline] Failed to get API configs for model name: {}",
                            e
                        );
                        None
                    }
                }
            } else {
                // æ²¡æœ‰æŒ‡å®šæ¨¡å‹ IDï¼ˆä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼‰ï¼Œä»é»˜è®¤é…ç½®è·å–æ¨¡å‹åç§°
                log::info!(
                    "[ChatV2::pipeline] options.model_id is None/empty, getting default model name"
                );
                match self
                    .llm_manager
                    .select_model_for("default", None, None, None, None, None, None)
                    .await
                {
                    Ok((config, _)) => {
                        log::info!(
                            "[ChatV2::pipeline] Default model resolved: {}",
                            config.model
                        );
                        Some(config.model)
                    }
                    Err(e) => {
                        log::warn!("[ChatV2::pipeline] Failed to get default model: {}", e);
                        None
                    }
                }
            };

        // ğŸ”§ Bugä¿®å¤ï¼šå°†æ¨¡å‹æ˜¾ç¤ºåç§°å­˜å‚¨åˆ° ctxï¼Œç”¨äºæ¶ˆæ¯ä¿å­˜
        ctx.model_display_name = model_name.clone();

        // å‘å°„æµå¼å¼€å§‹äº‹ä»¶ï¼ˆå¸¦æ¨¡å‹åç§°ï¼‰
        log::info!(
            "[ChatV2::pipeline] Emitting stream_start with model_name: {:?}",
            model_name
        );
        emitter.emit_stream_start(&assistant_message_id, model_name.as_deref());

        log::info!(
            "[ChatV2::pipeline] Starting pipeline for session={}, assistant_msg={}",
            session_id,
            assistant_message_id
        );

        // ğŸ†• P0é˜²é—ªé€€ï¼šç”¨æˆ·æ¶ˆæ¯å³æ—¶ä¿å­˜
        // åœ¨ Pipeline æ‰§è¡Œå‰ç«‹å³ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼Œç¡®ä¿ç”¨æˆ·è¾“å…¥ä¸ä¼šå› é—ªé€€ä¸¢å¤±
        // æ³¨æ„ï¼šskip_user_message_save ä¸º true æ—¶è·³è¿‡ï¼ˆç¼–è¾‘é‡å‘åœºæ™¯ï¼‰
        if !ctx.options.skip_user_message_save.unwrap_or(false) {
            if let Err(e) = self.save_user_message_immediately(&ctx).await {
                log::warn!(
                    "[ChatV2::pipeline] Failed to save user message immediately: {}",
                    e
                );
                // ä¸é˜»å¡æµç¨‹ï¼Œç»§ç»­æ‰§è¡Œï¼ˆsave_results ä¼šå†æ¬¡ä¿å­˜ï¼‰
            } else {
                log::info!(
                    "[ChatV2::pipeline] User message saved immediately: id={}",
                    ctx.user_message_id
                );
            }
        }

        // æ‰§è¡Œæµæ°´çº¿
        let result = self
            .execute_internal(&mut ctx, emitter.clone(), cancel_token)
            .await;

        match result {
            Ok(_) => {
                // å‘å°„æµå¼å®Œæˆäº‹ä»¶ï¼ˆå¸¦ token ç»Ÿè®¡ï¼‰
                let usage = if ctx.token_usage.has_tokens() {
                    Some(&ctx.token_usage)
                } else {
                    None
                };
                emitter.emit_stream_complete_with_usage(
                    &assistant_message_id,
                    ctx.elapsed_ms(),
                    usage,
                );

                // æ³¨æ„ï¼šä¸å†å•ç‹¬æ›´æ–° assistant_meta
                // save_results() å·²ç»ä¿å­˜äº†å®Œæ•´çš„ MessageMetaï¼ˆåŒ…å« model_id, usage, sources, tool_results, chat_params, context_snapshotï¼‰
                // è¿™é‡Œå¦‚æœå†æ¬¡è°ƒç”¨ update_message_meta_with_conn ä¼šè¦†ç›–è¿™äº›å­—æ®µï¼Œå¯¼è‡´æ•°æ®ä¸¢å¤±

                log::info!(
                    "[ChatV2::pipeline] Pipeline completed for session={}, duration={}ms",
                    session_id,
                    ctx.elapsed_ms()
                );

                // ğŸ”§ è‡ªåŠ¨ç”Ÿæˆä¼šè¯æ‘˜è¦ï¼ˆæ¯è½®å¯¹è¯åï¼‰
                // é€šè¿‡å†…å®¹å“ˆå¸Œé˜²æ­¢é‡å¤ç”Ÿæˆ
                let user_content_for_summary = ctx.user_content.clone();
                let assistant_content_for_summary = ctx.final_content.clone();
                if self
                    .should_generate_summary(
                        &session_id,
                        &user_content_for_summary,
                        &assistant_content_for_summary,
                    )
                    .await
                {
                    let pipeline = self.clone();
                    let sid = session_id.clone();
                    let emitter_clone = emitter.clone();

                    // ğŸ†• P1ä¿®å¤ï¼šä½¿ç”¨ TaskTracker è¿½è¸ªå¼‚æ­¥ä»»åŠ¡ï¼Œç¡®ä¿ä¼˜é›…å…³é—­
                    // å¼‚æ­¥æ‰§è¡Œæ‘˜è¦ç”Ÿæˆï¼Œä¸é˜»å¡è¿”å›
                    let summary_future = async move {
                        pipeline
                            .generate_summary(
                                &sid,
                                &user_content_for_summary,
                                &assistant_content_for_summary,
                                emitter_clone,
                            )
                            .await;
                    };

                    // ğŸ”§ P1ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ spawn_tracked è¿½è¸ªæ‘˜è¦ä»»åŠ¡
                    if let Some(ref state) = chat_v2_state {
                        state.spawn_tracked(summary_future);
                    } else {
                        log::warn!("[ChatV2::pipeline] spawn_tracked unavailable, using untracked tokio::spawn for summary task");
                        tokio::spawn(summary_future);
                    }
                }

                Ok(assistant_message_id)
            }
            Err(ChatV2Error::Cancelled) => {
                // ğŸ”§ ä¿®å¤ï¼šå–æ¶ˆæ—¶ä¹Ÿä¿å­˜å·²ç´¯ç§¯çš„å†…å®¹ï¼Œé¿å…ç”¨æˆ·æ¶ˆæ¯ä¸¢å¤±
                log::info!(
                    "[ChatV2::pipeline] Pipeline cancelled for session={}, attempting to save partial results...",
                    session_id
                );

                // ğŸ”§ å…³é”®ä¿®å¤ï¼šä» adapter è·å–å·²ç´¯ç§¯å†…å®¹ï¼ˆtokio::select! å–æ¶ˆæ—¶ä¸ä¼šæ‰§è¡Œ ctx æ›´æ–°ï¼‰
                if let Some(adapter) = &ctx.current_adapter {
                    if ctx.final_content.is_empty() {
                        ctx.final_content = adapter.get_accumulated_content();
                    }
                    if ctx.final_reasoning.is_none() {
                        ctx.final_reasoning = adapter.get_accumulated_reasoning();
                    }
                    if ctx.streaming_thinking_block_id.is_none() {
                        ctx.streaming_thinking_block_id = adapter.get_thinking_block_id();
                    }
                    if ctx.streaming_content_block_id.is_none() {
                        ctx.streaming_content_block_id = adapter.get_content_block_id();
                    }
                    log::info!(
                        "[ChatV2::pipeline] Retrieved partial content from adapter on cancel: content_len={}, reasoning_len={:?}",
                        ctx.final_content.len(),
                        ctx.final_reasoning.as_ref().map(|r| r.len())
                    );
                }

                // å°è¯•ä¿å­˜å·²ç´¯ç§¯çš„å†…å®¹ï¼ˆå³ä½¿ä¸ºç©ºä¹Ÿä¼šä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼‰
                if let Err(save_err) = self.save_results(&ctx).await {
                    log::warn!(
                        "[ChatV2::pipeline] Failed to save partial results on cancel: {}",
                        save_err
                    );
                } else {
                    log::info!(
                        "[ChatV2::pipeline] Partial results saved on cancel: content_len={}, reasoning_len={:?}",
                        ctx.final_content.len(),
                        ctx.final_reasoning.as_ref().map(|r| r.len())
                    );
                }

                // å‘å°„å–æ¶ˆäº‹ä»¶
                emitter.emit_stream_cancelled(&assistant_message_id);
                Err(ChatV2Error::Cancelled)
            }
            Err(e) => {
                // ğŸ”§ ä¿®å¤ï¼šé”™è¯¯æ—¶ä¹Ÿä¿å­˜å·²ç´¯ç§¯çš„å†…å®¹ï¼Œé¿å…ç”¨æˆ·æ¶ˆæ¯ä¸¢å¤±
                log::error!(
                    "[ChatV2::pipeline] Pipeline error for session={}: {}, attempting to save partial results...",
                    session_id,
                    e
                );

                // ğŸ”§ å…³é”®ä¿®å¤ï¼šä» adapter è·å–å·²ç´¯ç§¯å†…å®¹
                if let Some(adapter) = &ctx.current_adapter {
                    if ctx.final_content.is_empty() {
                        ctx.final_content = adapter.get_accumulated_content();
                    }
                    if ctx.final_reasoning.is_none() {
                        ctx.final_reasoning = adapter.get_accumulated_reasoning();
                    }
                    if ctx.streaming_thinking_block_id.is_none() {
                        ctx.streaming_thinking_block_id = adapter.get_thinking_block_id();
                    }
                    if ctx.streaming_content_block_id.is_none() {
                        ctx.streaming_content_block_id = adapter.get_content_block_id();
                    }
                    log::info!(
                        "[ChatV2::pipeline] Retrieved partial content from adapter on error: content_len={}, reasoning_len={:?}",
                        ctx.final_content.len(),
                        ctx.final_reasoning.as_ref().map(|r| r.len())
                    );
                }

                // å°è¯•ä¿å­˜å·²ç´¯ç§¯çš„å†…å®¹ï¼ˆå³ä½¿ä¸ºç©ºä¹Ÿä¼šä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼‰
                if let Err(save_err) = self.save_results(&ctx).await {
                    log::warn!(
                        "[ChatV2::pipeline] Failed to save partial results on error: {}",
                        save_err
                    );
                } else {
                    log::info!(
                        "[ChatV2::pipeline] Partial results saved on error: content_len={}, reasoning_len={:?}",
                        ctx.final_content.len(),
                        ctx.final_reasoning.as_ref().map(|r| r.len())
                    );
                }

                // å‘å°„é”™è¯¯äº‹ä»¶
                emitter.emit_stream_error(&assistant_message_id, &e.to_string());
                Err(e)
            }
        }
    }

    /// å†…éƒ¨æ‰§è¡Œæµç¨‹
    async fn execute_internal(
        &self,
        ctx: &mut PipelineContext,
        emitter: Arc<ChatV2EventEmitter>,
        cancel_token: CancellationToken,
    ) -> ChatV2Result<()> {
        // é˜¶æ®µ 0ï¼šåˆå§‹åŒ–ä¸Šä¸‹æ–‡å¿«ç…§ï¼ˆç»Ÿä¸€ä¸Šä¸‹æ–‡æ³¨å…¥ç³»ç»Ÿï¼‰
        ctx.init_context_snapshot();

        // é˜¶æ®µ 1ï¼šæ£€æŸ¥å–æ¶ˆ
        if cancel_token.is_cancelled() {
            return Err(ChatV2Error::Cancelled);
        }

        // é˜¶æ®µ 2ï¼šåŠ è½½èŠå¤©å†å²
        self.load_chat_history(ctx).await?;

        // é˜¶æ®µ 3ï¼šå¹¶è¡Œæ‰§è¡Œæ£€ç´¢
        if cancel_token.is_cancelled() {
            return Err(ChatV2Error::Cancelled);
        }

        // ä½¿ç”¨ tokio::select! æ”¯æŒå–æ¶ˆ
        let retrieval_result = tokio::select! {
            result = self.execute_retrievals(ctx, emitter.clone()) => result,
            _ = cancel_token.cancelled() => return Err(ChatV2Error::Cancelled),
        };
        retrieval_result?;

        // é˜¶æ®µ 3.5ï¼šåˆ›å»ºæ£€ç´¢èµ„æºå¹¶æ·»åŠ åˆ°ä¸Šä¸‹æ–‡å¿«ç…§ï¼ˆç»Ÿä¸€ä¸Šä¸‹æ–‡æ³¨å…¥ç³»ç»Ÿï¼‰
        let retrieval_refs = self
            .create_retrieval_resources(&ctx.retrieved_sources)
            .await;
        ctx.add_retrieval_refs_to_snapshot(retrieval_refs);

        // é˜¶æ®µ 4ï¼šæ„å»ºç³»ç»Ÿæç¤º
        let system_prompt = self.build_system_prompt(ctx).await;

        // é˜¶æ®µ 5ï¼šè°ƒç”¨ LLMï¼ˆå¸¦å·¥å…·é€’å½’ï¼‰
        if cancel_token.is_cancelled() {
            return Err(ChatV2Error::Cancelled);
        }

        let llm_result = tokio::select! {
            result = self.execute_with_tools(ctx, emitter.clone(), &system_prompt, 0) => result,
            _ = cancel_token.cancelled() => {
                log::info!("[ChatV2::pipeline] LLM call cancelled");
                return Err(ChatV2Error::Cancelled);
            }
        };
        llm_result?;

        // é˜¶æ®µ 5.5ï¼šç©ºé—²æœŸæ£€æµ‹ - æ£€æŸ¥å·¥ä½œåŒº inbox æ˜¯å¦æœ‰å¾…å¤„ç†æ¶ˆæ¯
        // è®¾è®¡æ–‡æ¡£ 30ï¼šåœ¨ stream_complete å‰æ£€æŸ¥ inbox
        if let Some(workspace_id) = ctx.get_workspace_id() {
            if let Some(ref coordinator) = self.workspace_coordinator {
                use super::workspace::WorkspaceInjector;

                let injector = WorkspaceInjector::new(coordinator.clone());
                let max_injections = 3u32; // å•æ¬¡ç©ºé—²æœŸæœ€å¤šå¤„ç† 3 æ‰¹æ¶ˆæ¯

                match injector.check_and_inject(workspace_id, &ctx.session_id, max_injections) {
                    Ok(injection_result) => {
                        if !injection_result.messages.is_empty() {
                            let formatted = WorkspaceInjector::format_injected_messages(
                                &injection_result.messages,
                            );
                            ctx.inject_workspace_messages(formatted);

                            log::info!(
                                "[ChatV2::pipeline] Workspace idle injection: {} messages injected, should_continue={}",
                                injection_result.messages.len(),
                                injection_result.should_continue
                            );

                            // å¦‚æœæ³¨å…¥äº†æ¶ˆæ¯ä¸”éœ€è¦ç»§ç»­ï¼Œé€’å½’è°ƒç”¨ LLM å¤„ç†
                            if injection_result.should_continue
                                || ctx.should_continue_for_workspace()
                            {
                                let continue_result = tokio::select! {
                                    result = self.execute_with_tools(ctx, emitter.clone(), &system_prompt, 0) => result,
                                    _ = cancel_token.cancelled() => {
                                        log::info!("[ChatV2::pipeline] Workspace continuation cancelled");
                                        return Err(ChatV2Error::Cancelled);
                                    }
                                };
                                continue_result?;
                            }
                        }
                    }
                    Err(e) => {
                        log::warn!("[ChatV2::pipeline] Workspace injection check failed: {}", e);
                    }
                }
            }
        }

        // é˜¶æ®µ 6ï¼šä¿å­˜ç»“æœ
        self.save_results(ctx).await?;

        Ok(())
    }

    /// åŠ è½½èŠå¤©å†å²
    ///
    /// ä»æ•°æ®åº“åŠ è½½ä¼šè¯çš„å†å²æ¶ˆæ¯ï¼Œåº”ç”¨ context_limit é™åˆ¶ï¼Œ
    /// å¹¶æå– content ç±»å‹å—çš„å†…å®¹æ„å»º LLM å¯¹è¯å†å²ã€‚
    async fn load_chat_history(&self, ctx: &mut PipelineContext) -> ChatV2Result<()> {
        log::debug!(
            "[ChatV2::pipeline] Loading chat history for session={}",
            ctx.session_id
        );

        // è·å–æ•°æ®åº“è¿æ¥
        let conn = self.db.get_conn_safe()?;

        // ğŸ†• è·å– VFS æ•°æ®åº“è¿æ¥ï¼ˆç”¨äºè§£æå†å²æ¶ˆæ¯ä¸­çš„ context_snapshotï¼‰
        let vfs_conn_opt = self.vfs_db.as_ref().and_then(|vfs_db| {
            match vfs_db.get_conn_safe() {
                Ok(vfs_conn) => Some(vfs_conn),
                Err(e) => {
                    log::warn!("[ChatV2::pipeline] Failed to get vfs.db connection for history context_snapshot: {}", e);
                    None
                }
            }
        });
        let vfs_blobs_dir = self
            .vfs_db
            .as_ref()
            .map(|vfs_db| vfs_db.blobs_dir().to_path_buf());

        // ä»æ•°æ®åº“åŠ è½½æ¶ˆæ¯
        let messages = ChatV2Repo::get_session_messages_with_conn(&conn, &ctx.session_id)?;

        if messages.is_empty() {
            log::debug!(
                "[ChatV2::pipeline] No chat history found for session={}",
                ctx.session_id
            );
            ctx.chat_history = Vec::new();
            return Ok(());
        }

        // ğŸ”§ P1ä¿®å¤ï¼šä½¿ç”¨å›ºå®šçš„æ¶ˆæ¯æ¡æ•°é™åˆ¶ï¼Œè€Œé context_limit
        // context_limit åº”è¯¥ç”¨äº LLM çš„ max_input_tokens_override
        let max_messages = DEFAULT_MAX_HISTORY_MESSAGES;
        let messages_to_load: Vec<_> = if messages.len() > max_messages {
            // å–æœ€æ–°çš„ max_messages æ¡æ¶ˆæ¯
            messages
                .into_iter()
                .rev()
                .take(max_messages)
                .rev()
                .collect()
        } else {
            messages
        };

        log::debug!(
            "[ChatV2::pipeline] Loading {} messages (max_messages={})",
            messages_to_load.len(),
            max_messages
        );

        // è½¬æ¢ä¸º LegacyChatMessage æ ¼å¼
        let mut chat_history = Vec::new();
        for message in messages_to_load {
            // åŠ è½½è¯¥æ¶ˆæ¯çš„æ‰€æœ‰å—
            let blocks = ChatV2Repo::get_message_blocks_with_conn(&conn, &message.id)?;

            // åªæå– content ç±»å‹å—çš„å†…å®¹
            let content: String = blocks
                .iter()
                .filter(|b| b.block_type == block_types::CONTENT)
                .filter_map(|b| b.content.as_ref())
                .cloned()
                .collect::<Vec<_>>()
                .join("");

            // æå– thinking ç±»å‹å—çš„å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
            let thinking_content: Option<String> = {
                let thinking: String = blocks
                    .iter()
                    .filter(|b| b.block_type == block_types::THINKING)
                    .filter_map(|b| b.content.as_ref())
                    .cloned()
                    .collect::<Vec<_>>()
                    .join("");
                if thinking.is_empty() {
                    None
                } else {
                    Some(thinking)
                }
            };

            // ğŸ”§ P1ä¿®å¤ï¼šæå– mcp_tool ç±»å‹å—çš„å·¥å…·è°ƒç”¨ä¿¡æ¯
            // å¯¹äº assistant æ¶ˆæ¯ï¼Œå¦‚æœåŒ…å«å·¥å…·è°ƒç”¨ï¼Œéœ€è¦å…ˆæ·»åŠ å·¥å…·è°ƒç”¨æ¶ˆæ¯
            // ğŸ”§ æ”¹è¿› 5ï¼šæŒ‰ block_index æ’åºï¼Œç¡®ä¿å¤šè½®å·¥å…·è°ƒç”¨é¡ºåºæ­£ç¡®
            let mut tool_blocks: Vec<_> = blocks
                .iter()
                .filter(|b| b.block_type == block_types::MCP_TOOL)
                .collect();
            tool_blocks.sort_by_key(|b| b.block_index);

            // ğŸ†• å¯¹äºç”¨æˆ·æ¶ˆæ¯ï¼Œè§£æ context_snapshot.user_refs å¹¶å°†å†…å®¹è¿½åŠ åˆ° content
            // â˜… 2025-12-10 ä¿®å¤ï¼šåŒæ—¶æå–å›¾ç‰‡ base64ï¼Œæ³¨å…¥åˆ° image_base64 å­—æ®µ
            let (content, vfs_image_base64) = if message.role == MessageRole::User {
                if let (Some(ref vfs_conn), Some(ref blobs_dir)) = (&vfs_conn_opt, &vfs_blobs_dir) {
                    self.resolve_history_context_snapshot_v2(
                        &content,
                        &message,
                        &**vfs_conn, // è§£å¼•ç”¨ PooledConnection è·å– &Connection
                        blobs_dir,
                    )
                } else {
                    (content, Vec::new())
                }
            } else {
                (content, Vec::new())
            };

            // æ„å»º LegacyChatMessage
            let role = match message.role {
                MessageRole::User => "user",
                MessageRole::Assistant => "assistant",
            };

            // å¦‚æœæ˜¯ assistant æ¶ˆæ¯ä¸”æœ‰å·¥å…·è°ƒç”¨ï¼Œå…ˆæ·»åŠ å·¥å…·è°ƒç”¨æ¶ˆæ¯
            if role == "assistant" && !tool_blocks.is_empty() {
                for (idx, tool_block) in tool_blocks.iter().enumerate() {
                    // ç”Ÿæˆ tool_call_idï¼ˆä½¿ç”¨å— ID æˆ–ç”Ÿæˆæ–°çš„ï¼‰
                    let tool_call_id = format!("tc_{}", tool_block.id.replace("blk_", ""));

                    // æå–å·¥å…·åç§°å’Œè¾“å…¥
                    let tool_name = tool_block.tool_name.clone().unwrap_or_default();
                    let tool_input = tool_block
                        .tool_input
                        .clone()
                        .unwrap_or(serde_json::Value::Null);
                    let tool_output = tool_block
                        .tool_output
                        .clone()
                        .unwrap_or(serde_json::Value::Null);
                    let tool_success = tool_block.status == block_status::SUCCESS;
                    let tool_error = tool_block.error.clone();

                    // 1. æ·»åŠ  assistant æ¶ˆæ¯ï¼ˆåŒ…å« tool_callï¼‰
                    let tool_call = crate::models::ToolCall {
                        id: tool_call_id.clone(),
                        tool_name: tool_name.clone(),
                        args_json: tool_input,
                    };
                    let assistant_tool_msg = LegacyChatMessage {
                        role: "assistant".to_string(),
                        content: String::new(),
                        timestamp: chrono::Utc::now(),
                        thinking_content: None,
                        thought_signature: None,
                        rag_sources: None,
                        memory_sources: None,
                        graph_sources: None,
                        web_search_sources: None,
                        image_paths: None,
                        image_base64: None,
                        doc_attachments: None,
                        multimodal_content: None,
                        tool_call: Some(tool_call),
                        tool_result: None,
                        overrides: None,
                        relations: None,
                        persistent_stable_id: None,
                        metadata: None,
                    };
                    chat_history.push(assistant_tool_msg);

                    // 2. æ·»åŠ  tool æ¶ˆæ¯ï¼ˆåŒ…å« tool_resultï¼‰
                    let tool_result = crate::models::ToolResult {
                        call_id: tool_call_id,
                        ok: tool_success,
                        error: tool_error,
                        error_details: None,
                        data_json: Some(tool_output.clone()),
                        usage: None,
                        citations: None,
                    };
                    let tool_msg = LegacyChatMessage {
                        role: "tool".to_string(),
                        content: serde_json::to_string(&tool_output).unwrap_or_default(),
                        timestamp: chrono::Utc::now(),
                        thinking_content: None,
                        thought_signature: None,
                        rag_sources: None,
                        memory_sources: None,
                        graph_sources: None,
                        web_search_sources: None,
                        image_paths: None,
                        image_base64: None,
                        doc_attachments: None,
                        multimodal_content: None,
                        tool_call: None,
                        tool_result: Some(tool_result),
                        overrides: None,
                        relations: None,
                        persistent_stable_id: None,
                        metadata: None,
                    };
                    chat_history.push(tool_msg);

                    log::debug!(
                        "[ChatV2::pipeline] Loaded tool call from history: tool={}, block_id={}, index={}",
                        tool_name,
                        tool_block.id,
                        idx
                    );
                }
            }

            // è·³è¿‡ç©ºå†…å®¹æ¶ˆæ¯ï¼ˆä½†å·¥å…·è°ƒç”¨æ¶ˆæ¯å·²ç»æ·»åŠ ï¼‰
            if content.is_empty() {
                continue;
            }

            // ä»é™„ä»¶ä¸­æå–å›¾ç‰‡ base64ï¼ˆä»…ç”¨æˆ·æ¶ˆæ¯æœ‰é™„ä»¶ï¼‰
            // â˜… 2025-12-10 ä¿®å¤ï¼šåˆå¹¶æ—§é™„ä»¶å›¾ç‰‡å’Œ VFS å›¾ç‰‡
            let mut all_images: Vec<String> = message
                .attachments
                .as_ref()
                .map(|attachments| {
                    attachments
                        .iter()
                        .filter(|a| a.r#type == "image")
                        .filter_map(|a| {
                            // preview_url æ ¼å¼ä¸º "data:image/xxx;base64,{base64_content}"
                            a.preview_url
                                .as_ref()
                                .and_then(|url| url.split(',').nth(1).map(|s| s.to_string()))
                        })
                        .collect::<Vec<_>>()
                })
                .unwrap_or_default();

            // â˜… 2025-12-10 ä¿®å¤ï¼šè¿½åŠ ä» VFS context_snapshot è§£æçš„å›¾ç‰‡
            all_images.extend(vfs_image_base64);

            let image_base64: Option<Vec<String>> = if all_images.is_empty() {
                None
            } else {
                Some(all_images)
            };

            // ğŸ”§ P2ä¿®å¤ï¼šä»é™„ä»¶ä¸­æå–æ–‡æ¡£é™„ä»¶ï¼ˆåŒæ—¶æ”¯æŒæ–‡æœ¬å’ŒäºŒè¿›åˆ¶æ–‡æ¡£ï¼‰
            // ğŸ”§ P0ä¿®å¤ï¼šä½¿ç”¨ DocumentParser è§£æ docx/pdf ç­‰äºŒè¿›åˆ¶æ–‡æ¡£
            let doc_attachments: Option<Vec<crate::models::DocumentAttachment>> = message.attachments
                .as_ref()
                .map(|attachments| {
                    attachments.iter()
                        .filter(|a| a.r#type == "document")
                        .map(|a| {
                            // åˆ¤æ–­æ˜¯å¦ä¸ºæ–‡æœ¬ç±»å‹
                            let is_text_type = a.mime_type.starts_with("text/") ||
                                               a.mime_type == "application/json" ||
                                               a.mime_type == "application/xml" ||
                                               a.mime_type == "application/javascript";

                            let mut text_content: Option<String> = None;
                            let mut base64_content: Option<String> = None;

                            // ä» preview_url æå–å†…å®¹
                            if let Some(ref url) = a.preview_url {
                                if url.starts_with("data:") {
                                    if let Some(data_part) = url.split(',').nth(1) {
                                        if is_text_type {
                                            // æ–‡æœ¬ç±»å‹ï¼šè§£ç  base64 ä¸ºæ–‡æœ¬
                                            use base64::Engine;
                                            text_content = base64::engine::general_purpose::STANDARD
                                                .decode(data_part)
                                                .ok()
                                                .and_then(|bytes| String::from_utf8(bytes).ok());
                                        } else {
                                            // äºŒè¿›åˆ¶ç±»å‹ï¼ˆå¦‚ docx/PDFï¼‰ï¼šå…ˆä¿å­˜ base64
                                            base64_content = Some(data_part.to_string());

                                            // ğŸ”§ P0ä¿®å¤ï¼šå°è¯•ä½¿ç”¨ DocumentParser è§£æäºŒè¿›åˆ¶æ–‡æ¡£
                                            let parser = crate::document_parser::DocumentParser::new();
                                            match parser.extract_text_from_base64(&a.name, data_part) {
                                                Ok(text) => {
                                                    log::debug!("[ChatV2::pipeline] Extracted {} chars from history document: {}", text.len(), a.name);
                                                    text_content = Some(text);
                                                }
                                                Err(e) => {
                                                    log::debug!("[ChatV2::pipeline] Could not parse history document {}: {}", a.name, e);
                                                }
                                            }
                                        }
                                    }
                                }
                            }

                            crate::models::DocumentAttachment {
                                name: a.name.clone(),
                                mime_type: a.mime_type.clone(),
                                size_bytes: a.size as usize,
                                text_content,
                                base64_content,
                            }
                        })
                        .collect::<Vec<_>>()
                })
                .filter(|v| !v.is_empty());

            let legacy_message = LegacyChatMessage {
                role: role.to_string(),
                content: content.clone(),
                timestamp: chrono::Utc::now(), // å†å²æ¶ˆæ¯çš„æ—¶é—´æˆ³ï¼ˆç”¨äºæ ¼å¼å…¼å®¹ï¼‰
                thinking_content,
                thought_signature: None,
                rag_sources: None,
                memory_sources: None,
                graph_sources: None,
                web_search_sources: None,
                image_paths: None,
                image_base64,
                doc_attachments,
                multimodal_content: None,
                tool_call: None,
                tool_result: None,
                overrides: None,
                relations: None,
                persistent_stable_id: message.persistent_stable_id.clone(),
                metadata: None,
            };

            chat_history.push(legacy_message);
        }

        log::info!(
            "[ChatV2::pipeline] Loaded {} messages from history for session={}",
            chat_history.len(),
            ctx.session_id
        );

        // ğŸ”§ æ”¹è¿› 5ï¼šéªŒè¯å·¥å…·è°ƒç”¨é“¾å®Œæ•´æ€§
        validate_tool_chain(&chat_history);

        // ğŸ†• 2026-02-22: ä¸ºå·²æ¿€æ´»çš„é»˜è®¤æŠ€èƒ½è‡ªåŠ¨æ³¨å…¥åˆæˆ load_skills å·¥å…·äº¤äº’
        // æŠ€èƒ½å†…å®¹é€šè¿‡ role: tool æŠ•é€’ï¼Œæ¨¡å‹éµå¾ªåº¦è¿œé«˜äº user message ä¸­çš„ XML å—
        inject_synthetic_load_skills(&mut chat_history, &ctx.options);

        ctx.chat_history = chat_history;
        Ok(())
    }

    /// è§£æå†å²æ¶ˆæ¯ä¸­çš„ context_snapshotï¼ˆV2 ç‰ˆæœ¬ï¼‰
    ///
    /// ä½¿ç”¨ç»Ÿä¸€çš„ `vfs_resolver` æ¨¡å—å¤„ç†æ‰€æœ‰èµ„æºç±»å‹çš„è§£å¼•ç”¨ã€‚
    /// è¿”å› `(String, Vec<String>)`ï¼š
    /// - ç¬¬ä¸€ä¸ªå€¼æ˜¯åˆå¹¶åçš„æ–‡æœ¬å†…å®¹
    /// - ç¬¬äºŒä¸ªå€¼æ˜¯å›¾ç‰‡ base64 åˆ—è¡¨ï¼Œç”¨äºæ³¨å…¥åˆ° `image_base64` å­—æ®µ
    ///
    /// è¿™ç¡®ä¿å†å²æ¶ˆæ¯ä¸­çš„ VFS å›¾ç‰‡é™„ä»¶èƒ½æ­£ç¡®æ³¨å…¥åˆ°å¤šæ¨¡æ€è¯·æ±‚ä¸­ã€‚
    fn resolve_history_context_snapshot_v2(
        &self,
        original_content: &str,
        message: &ChatMessage,
        vfs_conn: &rusqlite::Connection,
        blobs_dir: &std::path::Path,
    ) -> (String, Vec<String>) {
        use super::vfs_resolver::{resolve_context_ref_data_to_content, ResolvedContent};
        use crate::vfs::repos::VfsResourceRepo;
        use crate::vfs::types::VfsContextRefData;

        // æ£€æŸ¥æ˜¯å¦æœ‰ context_snapshot
        let context_snapshot = match &message.meta {
            Some(meta) => match &meta.context_snapshot {
                Some(snapshot) if !snapshot.user_refs.is_empty() => snapshot,
                _ => return (original_content.to_string(), Vec::new()),
            },
            None => return (original_content.to_string(), Vec::new()),
        };

        log::debug!(
            "[ChatV2::pipeline] resolve_history_context_snapshot_v2 for message {}: {} user_refs",
            message.id,
            context_snapshot.user_refs.len()
        );

        let mut total_result = ResolvedContent::new();

        // éå† user_refs
        for context_ref in &context_snapshot.user_refs {
            // 1. ä» VFS resources è¡¨è·å–èµ„æº
            let resource =
                match VfsResourceRepo::get_resource_with_conn(vfs_conn, &context_ref.resource_id) {
                    Ok(Some(r)) => r,
                    Ok(None) => {
                        log::warn!(
                            "[ChatV2::pipeline] Resource not found: {}",
                            context_ref.resource_id
                        );
                        continue;
                    }
                    Err(e) => {
                        log::warn!(
                            "[ChatV2::pipeline] Failed to get resource {}: {}",
                            context_ref.resource_id,
                            e
                        );
                        continue;
                    }
                };

            // 2. è§£æèµ„æºçš„ data å­—æ®µè·å– VFS å¼•ç”¨
            let data_str = match &resource.data {
                Some(d) => d,
                None => {
                    log::debug!(
                        "[ChatV2::pipeline] Resource {} has no data",
                        context_ref.resource_id
                    );
                    continue;
                }
            };

            // å°è¯•è§£æä¸º VfsContextRefDataï¼ˆé™„ä»¶ç­‰å¼•ç”¨æ¨¡å¼èµ„æºï¼‰
            if let Ok(mut ref_data) = serde_json::from_str::<VfsContextRefData>(data_str) {
                // â˜… 2026-02 ä¿®å¤ï¼šå†å²æ¶ˆæ¯è§£å¼•ç”¨æ—¶ä¹Ÿè¦æ¢å¤ inject_modes
                // å¦åˆ™ç¼–è¾‘é‡å‘/é‡è¯•æ—¶ä¼šé”™è¯¯æ³¨å…¥æ–‡æœ¬
                if let Some(ref saved_inject_modes) = context_ref.inject_modes {
                    for vfs_ref in &mut ref_data.refs {
                        vfs_ref.inject_modes = Some(saved_inject_modes.clone());
                    }
                }
                // â˜… ä½¿ç”¨ç»Ÿä¸€çš„ vfs_resolver æ¨¡å—è§£æ
                // â˜… 2026-01-17 ä¿®å¤ï¼šå†å²åŠ è½½æ—¶ä½¿ç”¨ is_multimodal=falseï¼ŒåŒæ—¶æ”¶é›†å›¾ç‰‡å’Œ OCR æ–‡æœ¬
                // å®é™…å‘é€ç»™ LLM æ—¶ï¼Œç”± model2_pipeline æ ¹æ® config.is_multimodal å†³å®šï¼š
                // - å¤šæ¨¡æ€æ¨¡å‹ï¼šä½¿ç”¨ image_base64 å‘é€å›¾ç‰‡
                // - éå¤šæ¨¡æ€æ¨¡å‹ï¼šä½¿ç”¨ content ä¸­çš„ OCR æ–‡æœ¬
                let content =
                    resolve_context_ref_data_to_content(vfs_conn, blobs_dir, &ref_data, false);
                total_result.merge(content);
            } else {
                // éå¼•ç”¨æ¨¡å¼èµ„æºï¼ˆå¦‚ç¬”è®°å†…å®¹ç›´æ¥å­˜å‚¨ï¼‰ï¼Œç›´æ¥ä½¿ç”¨ data
                match context_ref.type_id.as_str() {
                    "note" | "translation" | "essay" => {
                        if !data_str.is_empty() {
                            let title = resource
                                .metadata
                                .as_ref()
                                .and_then(|m| m.title.clone())
                                .unwrap_or_else(|| context_ref.type_id.clone());
                            total_result.add_text(format!(
                                "<injected_context>\n[{}]\n{}\n</injected_context>",
                                title, data_str
                            ));
                        }
                    }
                    _ => {
                        log::debug!(
                            "[ChatV2::pipeline] Unknown type_id for resource {}: {}",
                            context_ref.resource_id,
                            context_ref.type_id
                        );
                    }
                }
            }
        }

        // è®°å½•æ—¥å¿—
        if !total_result.is_empty() {
            log::info!(
                "[ChatV2::pipeline] Resolved {} context items and {} images for message {}",
                total_result.text_contents.len(),
                total_result.image_base64_list.len(),
                message.id
            );
        }

        // è¿”å›åˆå¹¶åçš„å†…å®¹å’Œå›¾ç‰‡åˆ—è¡¨
        let final_content = total_result.to_formatted_text(original_content);
        (final_content, total_result.image_base64_list)
    }

    /// æ£€ç´¢é˜¶æ®µï¼ˆå·²åºŸå¼ƒé¢„è°ƒç”¨æ¨¡å¼ï¼‰
    ///
    /// ğŸ”§ 2026-01-11 é‡æ„ï¼šå½»åº•ç§»é™¤é¢„è°ƒç”¨æ£€ç´¢ï¼Œå®Œå…¨é‡‡ç”¨å·¥å…·åŒ–æ¨¡å¼
    ///
    /// åŸé¢„è°ƒç”¨æ¨¡å¼ï¼ˆå·²åºŸå¼ƒï¼‰ï¼š
    /// - åœ¨ LLM è°ƒç”¨å‰è‡ªåŠ¨æ‰§è¡Œ RAGã€å›¾è°±ã€è®°å¿†ã€ç½‘ç»œæœç´¢
    /// - ç»“æœæ³¨å…¥åˆ°ç³»ç»Ÿæç¤ºä¸­
    ///
    /// æ–°å·¥å…·åŒ–æ¨¡å¼ï¼ˆå½“å‰ï¼‰ï¼š
    /// - æ£€ç´¢å·¥å…·ä½œä¸º MCP å·¥å…·æ³¨å…¥åˆ° LLM
    /// - LLM æ ¹æ®ç”¨æˆ·é—®é¢˜ä¸»åŠ¨å†³å®šæ˜¯å¦è°ƒç”¨æ£€ç´¢å·¥å…·
    /// - æ›´æ™ºèƒ½ã€æ›´èŠ‚çœèµ„æº
    ///
    /// å†…ç½®æ£€ç´¢å·¥å…·ï¼ˆbuiltin-* å‰ç¼€ï¼‰ï¼š
    /// - builtin-rag_search - çŸ¥è¯†åº“æ£€ç´¢
    /// - builtin-graph_search - çŸ¥è¯†å›¾è°±æ£€ç´¢
    /// - builtin-memory_search - å¯¹è¯è®°å¿†æ£€ç´¢
    /// - builtin-web_search - ç½‘ç»œæœç´¢
    /// - builtin-resource_* - å­¦ä¹ èµ„æºå·¥å…·
    /// - builtin-note_* - Canvas ç¬”è®°å·¥å…·
    /// - builtin-memory_* - VFS è®°å¿†å·¥å…·
    /// - builtin-knowledge_* - çŸ¥è¯†å†…åŒ–å·¥å…·
    #[allow(unused_variables)]
    async fn execute_retrievals(
        &self,
        ctx: &mut PipelineContext,
        _emitter: Arc<ChatV2EventEmitter>,
    ) -> ChatV2Result<()> {
        // ğŸ”§ å·¥å…·åŒ–æ¨¡å¼ï¼šè·³è¿‡æ‰€æœ‰é¢„è°ƒç”¨æ£€ç´¢
        // æ£€ç´¢ç”± LLM é€šè¿‡ tool_calls ä¸»åŠ¨è°ƒç”¨å†…ç½®å·¥å…·å®Œæˆ
        log::info!(
            "[ChatV2::pipeline] Tool-based retrieval mode: skipping pre-call retrievals for session={}",
            ctx.session_id
        );
        Ok(())
    }

    /// ğŸ†• æ‰§è¡Œ VFS RAG ç»Ÿä¸€çŸ¥è¯†ç®¡ç†æ£€ç´¢
    ///
    /// ä½¿ç”¨ VFS ç»Ÿä¸€å­˜å‚¨çš„å‘é‡æ£€ç´¢æ›¿ä»£ä¼ ç»Ÿ RagManagerï¼Œæ”¯æŒï¼š
    /// - æ–‡ä»¶å¤¹èŒƒå›´è¿‡æ»¤
    /// - èµ„æºç±»å‹è¿‡æ»¤
    /// - å¯é€‰é‡æ’åº
    ///
    /// ## è¿”å›
    /// (sources, block_id)
    async fn execute_vfs_rag_retrieval(
        &self,
        query: &str,
        folder_ids: Option<Vec<String>>,
        resource_types: Option<Vec<String>>,
        top_k: u32,
        enable_reranking: bool,
        enabled: bool,
        emitter: &Arc<ChatV2EventEmitter>,
        message_id: &str,
    ) -> ChatV2Result<(Vec<SourceInfo>, Option<String>)> {
        if !enabled {
            return Ok((Vec::new(), None));
        }

        // æ£€æŸ¥ VFS æ•°æ®åº“æ˜¯å¦å¯ç”¨
        let vfs_db = match &self.vfs_db {
            Some(db) => db.clone(),
            None => {
                log::debug!("[ChatV2::pipeline] VFS database not available, skipping VFS RAG");
                return Ok((Vec::new(), None));
            }
        };

        let block_id = format!("blk_{}", Uuid::new_v4());

        // å‘å°„ start äº‹ä»¶
        emitter.emit_start(event_types::RAG, message_id, Some(&block_id), None, None);

        let start_time = Instant::now();

        // åˆ›å»º VFS æœç´¢æœåŠ¡
        let lance_store = match VfsLanceStore::new(vfs_db.clone()) {
            Ok(store) => Arc::new(store),
            Err(e) => {
                log::warn!("[ChatV2::pipeline] Failed to create VFS Lance store: {}", e);
                emitter.emit_error(event_types::RAG, &block_id, &e.to_string(), None);
                return Ok((Vec::new(), Some(block_id)));
            }
        };
        let search_service =
            VfsFullSearchService::new(vfs_db.clone(), lance_store, self.llm_manager.clone());

        // æ„å»ºæœç´¢å‚æ•°
        let params = VfsSearchParams {
            query: query.to_string(),
            folder_ids,
            resource_ids: None,
            resource_types,
            modality: MODALITY_TEXT.to_string(),
            top_k,
        };

        // æ‰§è¡Œæœç´¢
        let result = search_service
            .search_with_resource_info(query, &params, enable_reranking)
            .await;

        match result {
            Ok(results) => {
                let raw_sources: Vec<SourceInfo> = results
                    .into_iter()
                    .map(|r| SourceInfo {
                        title: r.resource_title,
                        url: None,
                        snippet: Some(r.chunk_text),
                        score: Some(r.score as f32),
                        metadata: Some(json!({
                            "resourceId": r.resource_id,
                            "resourceType": r.resource_type,
                            "chunkIndex": r.chunk_index,
                            "embeddingId": r.embedding_id,
                            "sourceType": "vfs_rag",
                        })),
                    })
                    .collect();

                // åº”ç”¨ç›¸å…³æ€§è¿‡æ»¤
                let sources = filter_retrieval_results(
                    raw_sources,
                    RETRIEVAL_MIN_SCORE,
                    RETRIEVAL_RELATIVE_THRESHOLD,
                    top_k as usize,
                );

                let duration = start_time.elapsed().as_millis() as u64;

                // å‘å°„ end äº‹ä»¶
                emitter.emit_end(
                    event_types::RAG,
                    &block_id,
                    Some(json!({
                        "sources": sources,
                        "durationMs": duration,
                        "sourceType": "vfs_rag",
                    })),
                    None,
                );

                log::debug!(
                    "[ChatV2::pipeline] VFS RAG retrieval completed: {} sources in {}ms",
                    sources.len(),
                    duration
                );

                Ok((sources, Some(block_id)))
            }
            Err(e) => {
                // å‘å°„ error äº‹ä»¶
                emitter.emit_error(event_types::RAG, &block_id, &e.to_string(), None);
                log::warn!("[ChatV2::pipeline] VFS RAG retrieval error: {}", e);
                Ok((Vec::new(), Some(block_id))) // ä¸ä¸­æ–­æµç¨‹ï¼Œä½†ä¿ç•™å— ID
            }
        }
    }

    /// æ‰§è¡Œå¤šæ¨¡æ€çŸ¥è¯†åº“æ£€ç´¢
    /// è¿”å› (sources, block_id)
    async fn execute_multimodal_retrieval(
        &self,
        query: &str,
        library_ids: &Option<Vec<String>>,
        top_k: u32,
        _enable_reranking: bool,
        enabled: bool,
        emitter: &Arc<ChatV2EventEmitter>,
        message_id: &str,
    ) -> ChatV2Result<(Vec<SourceInfo>, Option<String>)> {
        if !enabled {
            return Ok((Vec::new(), None));
        }

        // æ£€æŸ¥å¤šæ¨¡æ€ RAG æ˜¯å¦å·²é…ç½®
        if !self.llm_manager.is_multimodal_rag_configured().await {
            log::debug!("[ChatV2::pipeline] Multimodal RAG not configured, skipping");
            return Ok((Vec::new(), None));
        }

        let block_id = format!("blk_{}", Uuid::new_v4());

        // å‘å°„ start äº‹ä»¶
        emitter.emit_start(
            event_types::MULTIMODAL_RAG,
            message_id,
            Some(&block_id),
            None,
            None,
        );

        let start_time = Instant::now();

        // â˜… ä½¿ç”¨ VFS å¤šæ¨¡æ€æ£€ç´¢æœåŠ¡ï¼ˆ2026-01 æ”¹é€ ï¼‰
        let vfs_db = match &self.vfs_db {
            Some(db) => db.clone(),
            None => {
                log::warn!("[ChatV2::pipeline] VFS database not available");
                emitter.emit_error(
                    event_types::MULTIMODAL_RAG,
                    &block_id,
                    "VFS æ•°æ®åº“ä¸å¯ç”¨",
                    None,
                );
                return Ok((Vec::new(), Some(block_id)));
            }
        };

        let lance_store = match VfsLanceStore::new(vfs_db.clone()) {
            Ok(ls) => Arc::new(ls),
            Err(e) => {
                log::warn!("[ChatV2::pipeline] Failed to create VFS Lance store: {}", e);
                emitter.emit_error(event_types::MULTIMODAL_RAG, &block_id, &e.to_string(), None);
                return Ok((Vec::new(), Some(block_id)));
            }
        };

        let mm_service = VfsMultimodalService::new(vfs_db, self.llm_manager.clone(), lance_store);

        // æ‰§è¡Œ VFS å¤šæ¨¡æ€æ£€ç´¢
        let folder_ids_ref: Option<Vec<String>> = library_ids.clone();
        let result = mm_service
            .search(
                query,
                top_k as usize,
                folder_ids_ref.as_ref().map(|v| v.as_slice()),
                None, // resource_types
            )
            .await;

        match result {
            Ok(results) => {
                let sources: Vec<SourceInfo> = results
                    .into_iter()
                    .map(|r| {
                        let page_display = r.page_index + 1;
                        SourceInfo {
                            title: Some(format!("Page {} - {}", page_display, r.resource_type)),
                            url: None,
                            snippet: r.text_content,
                            score: Some(r.score),
                            metadata: Some(json!({
                                "sourceType": r.resource_type,
                                "sourceId": r.resource_id,
                                "pageIndex": r.page_index,
                                "blobHash": r.blob_hash,
                                "folderId": r.folder_id,
                            })),
                        }
                    })
                    .collect();

                let duration = start_time.elapsed().as_millis() as u64;

                // å‘å°„ end äº‹ä»¶
                emitter.emit_end(
                    event_types::MULTIMODAL_RAG,
                    &block_id,
                    Some(json!({
                        "results": sources,
                        "durationMs": duration,
                    })),
                    None,
                );

                log::debug!(
                    "[ChatV2::pipeline] Multimodal retrieval completed: {} sources in {}ms",
                    sources.len(),
                    duration
                );

                Ok((sources, Some(block_id)))
            }
            Err(e) => {
                emitter.emit_error(event_types::MULTIMODAL_RAG, &block_id, &e.to_string(), None);
                log::warn!("[ChatV2::pipeline] Multimodal retrieval error: {}", e);
                Ok((Vec::new(), Some(block_id)))
            }
        }
    }

    /// æˆªæ–­æ–‡æœ¬åˆ°æŒ‡å®šé•¿åº¦
    pub(crate) fn truncate_text(text: &str, max_len: usize) -> String {
        if text.chars().count() <= max_len {
            text.to_string()
        } else {
            let truncated: String = text.chars().take(max_len).collect();
            format!("{}...", truncated)
        }
    }

    /// æ‰§è¡Œè®°å¿†æ£€ç´¢ï¼Œè¿”å› (sources, block_id)
    ///
    /// â˜… 2026-01ï¼šå·²æ”¹ç”¨ Memory-as-VFSï¼Œé€šè¿‡ MemoryToolExecutor æ‰§è¡Œ
    /// æ­¤æ–¹æ³•ä»…åœ¨å¼€å¯è®°å¿†æ£€ç´¢æ—¶å‘å°„äº‹ä»¶ï¼Œå®é™…æ£€ç´¢ç”± LLM å·¥å…·å®Œæˆ
    async fn execute_memory_retrieval(
        &self,
        _query: &str,
        _session_id: &str,
        enabled: bool,
        emitter: &Arc<ChatV2EventEmitter>,
        message_id: &str,
    ) -> ChatV2Result<(Vec<SourceInfo>, Option<String>)> {
        if !enabled {
            return Ok((Vec::new(), None));
        }

        let block_id = format!("blk_{}", Uuid::new_v4());
        emitter.emit_start(event_types::MEMORY, message_id, Some(&block_id), None, None);

        let start_time = Instant::now();

        // â˜… 2026-01ï¼šä½¿ç”¨ Memory-as-VFS
        // è®°å¿†æ£€ç´¢ç°åœ¨é€šè¿‡ builtin-memory_search å·¥å…·æ‰§è¡Œï¼Œæ­¤å¤„ä»…è¿”å›ç©ºç»“æœ
        // LLM ä¼šæ ¹æ®éœ€è¦ä¸»åŠ¨è°ƒç”¨ memory_search å·¥å…·
        let sources: Vec<SourceInfo> = Vec::new();

        let duration = start_time.elapsed().as_millis() as u64;

        emitter.emit_end(
            event_types::MEMORY,
            &block_id,
            Some(json!({
                "sources": sources,
                "durationMs": duration,
                "note": "Memory retrieval now uses builtin-memory_search tool"
            })),
            None,
        );

        log::debug!(
            "[ChatV2::pipeline] Memory retrieval placeholder completed in {}ms (use builtin-memory_search tool)",
            duration
        );

        Ok((sources, Some(block_id)))
    }

    /// æ‰§è¡Œç½‘ç»œæœç´¢
    ///
    /// è°ƒç”¨ web_search æ¨¡å—æ‰§è¡Œç½‘ç»œæœç´¢ï¼Œæ”¯æŒå¤šç§æœç´¢å¼•æ“ã€‚
    ///
    /// ## å‚æ•°
    /// - `query`: æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
    /// - `engines`: å¯é€‰çš„æœç´¢å¼•æ“åˆ—è¡¨ï¼ˆå¦‚ ["google_cse", "bing"]ï¼‰
    /// - `enabled`: æ˜¯å¦å¯ç”¨ç½‘ç»œæœç´¢
    /// - `emitter`: äº‹ä»¶å‘å°„å™¨
    /// - `message_id`: æ¶ˆæ¯ ID
    ///
    /// ## è¿”å›
    /// (sources, block_id) - æœç´¢ç»“æœåˆ—è¡¨å’Œå— ID
    async fn execute_web_search(
        &self,
        query: &str,
        engines: &Option<Vec<String>>,
        enabled: bool,
        emitter: &Arc<ChatV2EventEmitter>,
        message_id: &str,
    ) -> ChatV2Result<(Vec<SourceInfo>, Option<String>)> {
        if !enabled {
            return Ok((Vec::new(), None));
        }

        let block_id = format!("blk_{}", Uuid::new_v4());

        // å‘å°„ start äº‹ä»¶
        emitter.emit_start(
            event_types::WEB_SEARCH,
            message_id,
            Some(&block_id),
            None,
            None,
        );

        let start_time = Instant::now();

        // ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®åŠ è½½ web_search é…ç½®ï¼Œå¹¶åº”ç”¨æ•°æ®åº“è¦†ç›–
        let mut config = match WebSearchConfig::from_env_and_file() {
            Ok(cfg) => cfg,
            Err(e) => {
                log::warn!("[ChatV2::pipeline] Failed to load web_search config: {}", e);
                // ä½¿ç”¨é»˜è®¤é…ç½®ç»§ç»­
                WebSearchConfig::default()
            }
        };
        // ğŸ”§ ä¿®å¤ #14: ç»Ÿä¸€åº”ç”¨æ•°æ®åº“é…ç½®è¦†ç›–ï¼ˆAPI Keysã€è¿‡æ»¤ã€ç­–ç•¥ç­‰ï¼‰
        if let Some(ref db) = self.main_db {
            config.apply_db_overrides(
                |k| db.get_setting(k).ok().flatten(),
                |k| db.get_secret(k).ok().flatten(),
            );
        }

        // æ„å»ºæœç´¢è¾“å…¥
        let search_input = SearchInput {
            query: query.to_string(),
            top_k: 5, // é»˜è®¤è¿”å› 5 æ¡ç»“æœ
            engine: engines.as_ref().and_then(|e| e.first().cloned()),
            site: None,
            time_range: None,
            start: None,
            force_engine: None,
        };

        // æ‰§è¡Œæœç´¢
        let result = do_search(&config, search_input).await;
        let duration = start_time.elapsed().as_millis() as u64;

        if result.ok {
            // å°† web_search çš„ citations è½¬æ¢ä¸º SourceInfo
            let sources: Vec<SourceInfo> = result
                .citations
                .unwrap_or_default()
                .into_iter()
                .map(|citation| SourceInfo {
                    title: Some(citation.file_name),
                    url: Some(citation.document_id), // document_id å­˜å‚¨çš„æ˜¯ URL
                    snippet: Some(citation.chunk_text),
                    score: Some(citation.score),
                    metadata: Some(json!({
                        "sourceType": "web_search",
                        "chunkIndex": citation.chunk_index,
                        "provider": result.usage.as_ref()
                            .and_then(|u| u.get("provider"))
                            .and_then(|p| p.as_str())
                            .unwrap_or("unknown"),
                    })),
                })
                .collect();

            // å‘å°„ end äº‹ä»¶
            emitter.emit_end(
                event_types::WEB_SEARCH,
                &block_id,
                Some(json!({
                    "sources": sources,
                    "durationMs": duration,
                    "usage": result.usage,
                })),
                None,
            );

            log::debug!(
                "[ChatV2::pipeline] Web search completed: {} sources in {}ms",
                sources.len(),
                duration
            );

            Ok((sources, Some(block_id)))
        } else {
            // æœç´¢å¤±è´¥ï¼Œå‘å°„ error äº‹ä»¶
            let error_msg = result
                .error
                .map(|e| {
                    if let Some(s) = e.as_str() {
                        s.to_string()
                    } else {
                        e.to_string()
                    }
                })
                .or_else(|| result.error_details.as_ref().map(|d| d.message.clone()))
                .unwrap_or_else(|| "Unknown web search error".to_string());

            emitter.emit_error(event_types::WEB_SEARCH, &block_id, &error_msg, None);

            log::warn!(
                "[ChatV2::pipeline] Web search failed: {} ({}ms)",
                error_msg,
                duration
            );

            // ä¸ä¸­æ–­æµç¨‹ï¼Œè¿”å›ç©ºç»“æœä½†ä¿ç•™å— ID
            Ok((Vec::new(), Some(block_id)))
        }
    }

    /// æ„å»ºç³»ç»Ÿæç¤º
    ///
    /// ä½¿ç”¨ prompt_builder æ¨¡å—ç»Ÿä¸€æ ¼å¼åŒ–ï¼Œé‡‡ç”¨ XML æ ‡ç­¾åˆ†éš”å„éƒ¨åˆ†ï¼Œ
    /// ç»Ÿä¸€å¼•ç”¨æ ¼å¼ä¸º `[ç±»å‹-ç¼–å·]`ï¼Œå¹¶æ·»åŠ ä½¿ç”¨æŒ‡å¼•ã€‚
    /// å¦‚æœæœ‰ Canvas ç¬”è®°ï¼Œä¹Ÿä¼šä¸€å¹¶æ³¨å…¥ã€‚
    async fn build_system_prompt(&self, ctx: &PipelineContext) -> String {
        // æ„å»º Canvas ç¬”è®°ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        let canvas_note = self.build_canvas_note_info(ctx).await;
        prompt_builder::build_system_prompt(&ctx.options, &ctx.retrieved_sources, canvas_note)
    }

    /// æ„å»º Canvas ç¬”è®°ä¿¡æ¯
    async fn build_canvas_note_info(
        &self,
        ctx: &PipelineContext,
    ) -> Option<prompt_builder::CanvasNoteInfo> {
        let note_id = ctx.options.canvas_note_id.as_ref()?;
        let notes_mgr = self.notes_manager.as_ref()?;
        match notes_mgr.get_note(note_id) {
            Ok(note) => {
                let word_count = note.content_md.chars().count();
                log::info!(
                    "[ChatV2::pipeline] Canvas mode: loaded note '{}' ({} chars, is_long={})",
                    note.title,
                    word_count,
                    word_count >= 3000
                );
                Some(prompt_builder::CanvasNoteInfo::new(
                    note_id.clone(),
                    note.title,
                    note.content_md,
                ))
            }
            Err(e) => {
                log::warn!(
                    "[ChatV2::pipeline] Canvas mode: failed to read note {}: {}",
                    note_id,
                    e
                );
                None
            }
        }
    }

    /// æ„å»ºå½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼ˆç”¨äº LLM è°ƒç”¨ï¼‰
    ///
    /// â˜… 2025-12-10 ç»Ÿä¸€æ”¹é€ ï¼šç§»é™¤ ctx.attachments çš„ç›´æ¥å¤„ç†
    /// æ‰€æœ‰é™„ä»¶ç°åœ¨é€šè¿‡ user_context_refs ä¼ é€’ï¼Œå›¾ç‰‡å’Œæ–‡æ¡£å†…å®¹å·²åœ¨å‰ç«¯ formatToBlocks ä¸­å¤„ç†
    ///
    /// ## ç»Ÿä¸€ä¸Šä¸‹æ–‡æ³¨å…¥ç³»ç»Ÿï¼ˆPrompt 8ï¼‰
    /// ä½¿ç”¨ `get_combined_user_content()` åˆå¹¶ä¸Šä¸‹æ–‡å†…å®¹å’Œç”¨æˆ·è¾“å…¥ï¼Œ
    /// å°† formattedBlocks ä¸­çš„æ–‡æœ¬æ‹¼æ¥åˆ°ç”¨æˆ·å†…å®¹å‰é¢ï¼Œå›¾ç‰‡æ·»åŠ åˆ° image_base64ã€‚
    ///
    /// ## â˜… æ–‡æ¡£25ï¼šå¤šæ¨¡æ€å›¾æ–‡äº¤æ›¿æ”¯æŒ
    /// å½“ä¸Šä¸‹æ–‡å¼•ç”¨åŒ…å«å›¾ç‰‡æ—¶ï¼Œä½¿ç”¨ `get_content_blocks_ordered()` è·å–æœ‰åºå†…å®¹å—ï¼Œ
    /// å¡«å…… `multimodal_content` å­—æ®µä»¥ä¿æŒå›¾æ–‡äº¤æ›¿é¡ºåºã€‚
    fn build_current_user_message(&self, ctx: &PipelineContext) -> LegacyChatMessage {
        // â˜… æ–‡æ¡£25ï¼šæ£€æŸ¥ä¸Šä¸‹æ–‡å¼•ç”¨æ˜¯å¦åŒ…å«å›¾ç‰‡ï¼ˆéœ€è¦å›¾æ–‡äº¤æ›¿ï¼‰
        let has_context_images = ctx.user_context_refs.iter().any(|r| {
            r.formatted_blocks
                .iter()
                .any(|b| matches!(b, ContentBlock::Image { .. }))
        });

        // â˜… 2025-12-10 ç»Ÿä¸€æ”¹é€ ï¼šæ‰€æœ‰å†…å®¹éƒ½é€šè¿‡ user_context_refs ä¼ é€’
        // ä¸å†ä» ctx.attachments æå–å›¾ç‰‡å’Œæ–‡æ¡£

        let (combined_content, image_base64, multimodal_content) = if has_context_images {
            // ä½¿ç”¨ get_content_blocks_ordered() è·å–å›¾æ–‡äº¤æ›¿çš„å†…å®¹å—
            let ordered_blocks = ctx.get_content_blocks_ordered();

            // è½¬æ¢ä¸º MultimodalContentPart æ•°ç»„
            let multimodal_parts: Vec<MultimodalContentPart> = ordered_blocks
                .into_iter()
                .map(|block| match block {
                    ContentBlock::Text { text } => MultimodalContentPart::text(text),
                    ContentBlock::Image { media_type, base64 } => {
                        MultimodalContentPart::image(media_type, base64)
                    }
                })
                .collect();

            log::info!(
                "[ChatV2::pipeline] build_current_user_message: Using multimodal mode with {} parts from context refs",
                multimodal_parts.len()
            );

            // å¤šæ¨¡æ€æ¨¡å¼ï¼šcontent ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œå›¾ç‰‡åœ¨ multimodal_content ä¸­
            (String::new(), None, Some(multimodal_parts))
        } else {
            // ä¼ ç»Ÿæ¨¡å¼ï¼šä½¿ç”¨ get_combined_user_content()
            let (combined_content, context_images) = ctx.get_combined_user_content();

            let image_base64: Option<Vec<String>> = if context_images.is_empty() {
                None
            } else {
                Some(context_images)
            };

            (combined_content, image_base64, None)
        };

        // â˜… 2025-12-10 ç»Ÿä¸€æ”¹é€ ï¼šdoc_attachments ä¸å†ä» ctx.attachments æ„å»º
        // æ–‡æ¡£å†…å®¹ç°åœ¨é€šè¿‡ user_context_refs çš„ formattedBlocks ä¼ é€’ï¼ˆå·²ç”± formatToBlocks è§£æï¼‰

        LegacyChatMessage {
            role: "user".to_string(),
            content: combined_content,
            timestamp: chrono::Utc::now(),
            thinking_content: None,
            thought_signature: None,
            rag_sources: None,
            memory_sources: None,
            graph_sources: None,
            web_search_sources: None,
            image_paths: None,
            image_base64,
            doc_attachments: None, // â˜… æ–‡æ¡£é™„ä»¶ç°åœ¨é€šè¿‡ user_context_refs ä¼ é€’
            multimodal_content,    // â˜… æ–‡æ¡£25ï¼šå¤šæ¨¡æ€å›¾æ–‡äº¤æ›¿å†…å®¹
            tool_call: None,
            tool_result: None,
            overrides: None,
            relations: None,
            persistent_stable_id: None,
            metadata: None,
        }
    }

    /// æ‰§è¡Œ LLM è°ƒç”¨ï¼ˆæ”¯æŒå·¥å…·é€’å½’ï¼‰
    ///
    /// ## å·¥å…·é€’å½’æµç¨‹
    /// 1. è°ƒç”¨ LLM è·å–å“åº”
    /// 2. å¦‚æœå“åº”åŒ…å«å·¥å…·è°ƒç”¨ï¼Œæ‰§è¡Œå·¥å…·
    /// 3. å°†å·¥å…·ç»“æœæ·»åŠ åˆ°èŠå¤©å†å²
    /// 4. é€’å½’è°ƒç”¨ç›´åˆ°æ— å·¥å…·è°ƒç”¨æˆ–è¾¾åˆ°æœ€å¤§æ·±åº¦
    ///
    /// ## å‚æ•°
    /// - `ctx`: æµæ°´çº¿ä¸Šä¸‹æ–‡ï¼ˆå¯å˜ï¼Œç”¨äºå­˜å‚¨å·¥å…·ç»“æœï¼‰
    /// - `emitter`: äº‹ä»¶å‘å°„å™¨
    /// - `system_prompt`: ç³»ç»Ÿæç¤º
    /// - `recursion_depth`: å½“å‰é€’å½’æ·±åº¦
    ///
    /// ## é”™è¯¯
    /// - è¶…è¿‡æœ€å¤§é€’å½’æ·±åº¦ (MAX_TOOL_RECURSION = 5)
    /// - LLM è°ƒç”¨å¤±è´¥
    async fn execute_with_tools(
        &self,
        ctx: &mut PipelineContext,
        emitter: Arc<ChatV2EventEmitter>,
        system_prompt: &str,
        recursion_depth: u32,
    ) -> ChatV2Result<()> {
        // æ£€æŸ¥é€’å½’æ·±åº¦é™åˆ¶
        // ğŸ”§ é…ç½®åŒ–ï¼šä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„é™åˆ¶å€¼ï¼Œé»˜è®¤ MAX_TOOL_RECURSION (30)
        let max_recursion = ctx
            .options
            .max_tool_recursion
            .unwrap_or(MAX_TOOL_RECURSION)
            .clamp(1, 100); // é™åˆ¶èŒƒå›´ 1-100

        // ğŸ†• å¿ƒè·³æœºåˆ¶ï¼šæ£€æµ‹ä¸Šä¸€è½®æ˜¯å¦æœ‰ continue_execution æ ‡å¿—
        // å¦‚æœæœ‰ï¼Œåˆ™ç»•è¿‡æ™®é€šçš„é€’å½’é™åˆ¶ï¼ˆä½†ä»å—ç»å¯¹ä¸Šé™ ABSOLUTE_MAX_RECURSION é™åˆ¶ï¼‰
        const ABSOLUTE_MAX_RECURSION: u32 = 500; // ç¡¬ç¼–ç ç»å¯¹ä¸Šé™ï¼Œé˜²æ­¢æ— é™å¾ªç¯
        let has_heartbeat = ctx.tool_results.iter().any(|r| {
            r.output
                .get("continue_execution")
                .and_then(|v| v.as_bool())
                .unwrap_or(false)
        });

        // ç»å¯¹ä¸Šé™æ£€æŸ¥ï¼ˆä¸å¯ç»•è¿‡ï¼‰
        if recursion_depth > ABSOLUTE_MAX_RECURSION {
            log::error!(
                "[ChatV2::pipeline] ABSOLUTE recursion limit reached: depth={}, absolute_max={}",
                recursion_depth,
                ABSOLUTE_MAX_RECURSION
            );
            return Err(ChatV2Error::Tool(format!(
                "è¾¾åˆ°ç»å¯¹é€’å½’ä¸Šé™ ({})ï¼Œä»»åŠ¡å·²ç»ˆæ­¢",
                ABSOLUTE_MAX_RECURSION
            )));
        }

        // æ™®é€šé™åˆ¶æ£€æŸ¥ï¼ˆå¯è¢«å¿ƒè·³ç»•è¿‡ï¼‰
        if recursion_depth > max_recursion && !has_heartbeat {
            log::warn!(
                "[ChatV2::pipeline] Tool recursion limit reached: depth={}, max={}",
                recursion_depth,
                max_recursion
            );

            // åˆ›å»º tool_limit å—ï¼Œæç¤ºç”¨æˆ·è¾¾åˆ°é™åˆ¶
            let block_id = MessageBlock::generate_id();
            let now_ms = chrono::Utc::now().timestamp_millis();
            let limit_message = format!(
                "âš ï¸ å·²è¾¾åˆ°å·¥å…·è°ƒç”¨é™åˆ¶ï¼ˆ{} è½®ï¼‰\n\n\
                AI å·²æ‰§è¡Œäº† {} è½®å·¥å…·è°ƒç”¨ã€‚ä¸ºé˜²æ­¢æ— é™å¾ªç¯ï¼Œå·²æš‚åœè‡ªåŠ¨æ‰§è¡Œã€‚\n\n\
                å¦‚æœä»»åŠ¡å°šæœªå®Œæˆï¼Œæ‚¨å¯ä»¥ï¼š\n\
                â€¢ å‘é€ã€Œç»§ç»­ã€è®© AI ç»§ç»­æ‰§è¡Œ\n\
                â€¢ å‘é€æ–°çš„æŒ‡ä»¤è°ƒæ•´æ–¹å‘\n\
                â€¢ æ‰‹åŠ¨å®Œæˆå‰©ä½™æ­¥éª¤",
                max_recursion, max_recursion
            );

            // å‘é€ start äº‹ä»¶
            emitter.emit_start(
                event_types::TOOL_LIMIT,
                &ctx.assistant_message_id,
                Some(&block_id),
                None,
                None,
            );

            // å‘é€ end äº‹ä»¶ï¼Œæºå¸¦æç¤ºå†…å®¹
            let result_payload = serde_json::json!({
                "content": limit_message,
                "recursionDepth": recursion_depth,
                "maxRecursion": max_recursion,
            });
            emitter.emit_end(
                event_types::TOOL_LIMIT,
                &block_id,
                Some(result_payload),
                None,
            );

            // åˆ›å»ºå—å¹¶æ·»åŠ åˆ° interleaved åˆ—è¡¨
            let tool_limit_block = MessageBlock {
                id: block_id.clone(),
                message_id: ctx.assistant_message_id.clone(),
                block_type: block_types::TOOL_LIMIT.to_string(),
                status: block_status::SUCCESS.to_string(),
                content: Some(limit_message),
                tool_name: None,
                tool_input: None,
                tool_output: None,
                citations: None,
                error: None,
                started_at: Some(now_ms),
                ended_at: Some(now_ms),
                first_chunk_at: Some(now_ms),
                block_index: 0, // ä¼šè¢« add_interleaved_block è¦†ç›–
            };
            ctx.add_interleaved_block(tool_limit_block);

            log::info!(
                "[ChatV2::pipeline] Created tool_limit block: id={}, message_id={}",
                block_id,
                ctx.assistant_message_id
            );

            // æ­£å¸¸è¿”å›ï¼Œä¸æŠ›å‡ºé”™è¯¯
            return Ok(());
        }

        log::info!(
            "[ChatV2::pipeline] Executing LLM call: session={}, recursion_depth={}, tool_results={}",
            ctx.session_id,
            recursion_depth,
            ctx.tool_results.len()
        );

        // åˆ›å»º LLM é€‚é…å™¨
        // ğŸ”§ ä¿®å¤ï¼šé»˜è®¤å¯ç”¨ thinkingï¼Œç¡®ä¿æ€ç»´é“¾å†…å®¹èƒ½æ­£ç¡®ç´¯ç§¯å’Œä¿å­˜
        let enable_thinking = ctx.options.enable_thinking.unwrap_or(true);
        log::info!(
            "[ChatV2::pipeline] enable_thinking={} (from options: {:?})",
            enable_thinking,
            ctx.options.enable_thinking
        );
        let adapter = Arc::new(ChatV2LLMAdapter::new(
            emitter.clone(),
            ctx.assistant_message_id.clone(),
            enable_thinking,
        ));

        // ğŸ”§ ä¿®å¤ï¼šå­˜å‚¨ adapter å¼•ç”¨åˆ° ctxï¼Œç¡®ä¿å–æ¶ˆæ—¶å¯ä»¥è·å–å·²ç´¯ç§¯å†…å®¹
        ctx.current_adapter = Some(adapter.clone());

        // ============================================================
        // æ„å»ºèŠå¤©å†å²ï¼ˆåŒ…å«ä¹‹å‰çš„å·¥å…·ç»“æœ + å½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼‰
        // ============================================================
        let mut messages = ctx.chat_history.clone();

        // ğŸ”´ å…³é”®ä¿®å¤ï¼šæ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯åˆ°æ¶ˆæ¯åˆ—è¡¨
        // ä¹‹å‰è¿™é‡Œç¼ºå¤±ï¼Œå¯¼è‡´ LLM çœ‹ä¸åˆ°ç”¨æˆ·å½“å‰å‘é€çš„é—®é¢˜
        let current_user_message = self.build_current_user_message(ctx);
        messages.push(current_user_message);
        log::debug!(
            "[ChatV2::pipeline] Added current user message: content_len={}, has_images={}, has_docs={}",
            ctx.user_content.len(),
            ctx.attachments.iter().any(|a| a.mime_type.starts_with("image/")),
            ctx.attachments.iter().any(|a| !a.mime_type.starts_with("image/"))
        );

        // å¦‚æœæœ‰å·¥å…·ç»“æœï¼ˆé€’å½’è°ƒç”¨æ—¶ï¼‰ï¼Œå°†**æ‰€æœ‰**å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
        // ğŸ”§ å…³é”®ä¿®å¤ï¼šç”±äº messages æ¯æ¬¡ä» chat_history.clone() é‡å»ºï¼Œ
        // ä¹‹å‰åªæ·»åŠ "æ–°"å·¥å…·ç»“æœä¼šå¯¼è‡´å†å²ä¸¢å¤±ã€‚ç°åœ¨æ”¹ä¸ºæ¯æ¬¡æ·»åŠ æ‰€æœ‰å·¥å…·ç»“æœï¼Œ
        // ç¡®ä¿ LLM èƒ½çœ‹åˆ°å®Œæ•´çš„å·¥å…·è°ƒç”¨å†å²ï¼ˆç¬¦åˆ Anthropic æœ€ä½³å®è·µï¼š
        // "Messages API æ˜¯æ— çŠ¶æ€çš„ï¼Œå¿…é¡»æ¯æ¬¡å‘é€å®Œæ•´å¯¹è¯å†å²"ï¼‰
        if !ctx.tool_results.is_empty() {
            let tool_messages = ctx.all_tool_results_to_messages();
            let tool_count = tool_messages.len();
            messages.extend(tool_messages);

            log::debug!(
                "[ChatV2::pipeline] Added ALL {} tool result messages to chat history (tool_results count: {})",
                tool_count,
                ctx.tool_results.len()
            );
        }

        // ============================================================
        // è°ƒç”¨ LLM
        // ============================================================
        // æ„å»º LLM è°ƒç”¨ä¸Šä¸‹æ–‡
        let mut llm_context: HashMap<String, Value> = HashMap::new();

        // æ³¨å…¥æ£€ç´¢åˆ°çš„æ¥æºåˆ°ä¸Šä¸‹æ–‡
        if let Some(ref rag_sources) = ctx.retrieved_sources.rag {
            llm_context.insert(
                "prefetched_rag_sources".into(),
                serde_json::to_value(rag_sources).unwrap_or(Value::Null),
            );
        }
        if let Some(ref memory_sources) = ctx.retrieved_sources.memory {
            llm_context.insert(
                "prefetched_memory_sources".into(),
                serde_json::to_value(memory_sources).unwrap_or(Value::Null),
            );
        }
        if let Some(ref web_sources) = ctx.retrieved_sources.web_search {
            llm_context.insert(
                "prefetched_web_search_sources".into(),
                serde_json::to_value(web_sources).unwrap_or(Value::Null),
            );
        }

        // ====================================================================
        // ğŸ†• å›¾ç‰‡å‹ç¼©ç­–ç•¥ï¼švision_quality æ™ºèƒ½é»˜è®¤
        // ====================================================================
        // ç­–ç•¥é€»è¾‘ï¼š
        // 1. ç”¨æˆ·æ˜¾å¼æŒ‡å®š â†’ ç›´æ¥ä½¿ç”¨
        // 2. auto/ç©º â†’ æ ¹æ®å›¾ç‰‡æ•°é‡å’Œæ¥æºè‡ªåŠ¨é€‰æ‹©ï¼š
        //    - å•å›¾ + é PDFï¼šhighï¼ˆä¿æŒåŸè´¨é‡ï¼Œä¾¿äº OCRï¼‰
        //    - 2-5 å¼ å›¾ï¼šmedium
        //    - 6+ å¼ å›¾æˆ– PDF/æ•™æï¼šlowï¼ˆæœ€å¤§å‹ç¼©ï¼ŒèŠ‚çœ tokenï¼‰
        let vision_quality = {
            // æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æ˜¾å¼æŒ‡å®š
            let user_specified = ctx
                .options
                .vision_quality
                .as_deref()
                .filter(|v| !v.is_empty() && *v != "auto");

            if let Some(vq) = user_specified {
                // ç”¨æˆ·æ˜¾å¼æŒ‡å®š
                log::debug!("[ChatV2::pipeline] vision_quality: user specified '{}'", vq);
                vq.to_string()
            } else {
                // è‡ªåŠ¨ç­–ç•¥ï¼šç»Ÿè®¡å›¾ç‰‡æ•°é‡å’Œ PDF/æ•™ææ¥æº
                let mut image_count = 0usize;
                let mut has_pdf_or_textbook = false;

                for ctx_ref in &ctx.user_context_refs {
                    // ç»Ÿè®¡å›¾ç‰‡å—æ•°é‡
                    for block in &ctx_ref.formatted_blocks {
                        if matches!(block, super::resource_types::ContentBlock::Image { .. }) {
                            image_count += 1;
                        }
                    }
                    // æ£€æŸ¥æ˜¯å¦æœ‰ PDF/æ•™ææ¥æºï¼ˆé€šè¿‡ type_id åˆ¤æ–­ï¼‰
                    let type_id_lower = ctx_ref.type_id.to_lowercase();
                    if type_id_lower.contains("pdf")
                        || type_id_lower.contains("textbook")
                        || type_id_lower.contains("file")
                        || ctx_ref.resource_id.starts_with("tb_")
                    {
                        has_pdf_or_textbook = true;
                    }
                }

                // æ™ºèƒ½ç­–ç•¥
                let auto_quality = if has_pdf_or_textbook || image_count >= 6 {
                    "low" // PDF/æ•™æ æˆ–å¤§é‡å›¾ç‰‡ï¼šæœ€å¤§å‹ç¼©
                } else if image_count >= 2 {
                    "medium" // ä¸­ç­‰æ•°é‡ï¼šå¹³è¡¡å‹ç¼©
                } else {
                    "high" // å•å›¾æˆ–æ— å›¾ï¼šä¿æŒåŸè´¨é‡
                };

                log::info!(
                    "[ChatV2::pipeline] vision_quality: auto -> '{}' (images={}, has_pdf_or_textbook={})",
                    auto_quality, image_count, has_pdf_or_textbook
                );
                auto_quality.to_string()
            }
        };

        // æ³¨å…¥åˆ° LLM ä¸Šä¸‹æ–‡
        llm_context.insert(
            "vision_quality".into(),
            Value::String(vision_quality.clone()),
        );

        // ====================================================================
        // ç»Ÿä¸€å·¥å…·æ³¨å…¥ï¼šä½¿ç”¨ schema_tool_ids æ³¨å…¥å·¥å…· Schema
        // éµå¾ªæ–‡æ¡£ 26ï¼šç»Ÿä¸€å·¥å…·æ³¨å…¥ç³»ç»Ÿæ¶æ„è®¾è®¡
        // ğŸ†• æ–‡æ¡£ 29 P1-4ï¼šè‡ªåŠ¨æ³¨å…¥ attempt_completion å·¥å…·ï¼ˆAgent æ¨¡å¼å¿…å¤‡ï¼‰
        // ====================================================================

        // æ„å»ºå·¥å…·åˆ—è¡¨ï¼Œè‡ªåŠ¨æ·»åŠ  Agent å¿…å¤‡å·¥å…·ï¼ˆå¦‚æœæœ‰å…¶ä»–å·¥å…·è¢«æ³¨å…¥ï¼‰
        // æ³¨æ„ï¼šå†…ç½®å·¥å…·ï¼ˆåŒ…æ‹¬ TodoListï¼‰åº”è¯¥é€šè¿‡å†…ç½® MCP æœåŠ¡å™¨æ³¨å…¥ï¼Œä¸åœ¨æ­¤å¤„æ·»åŠ 
        let effective_tool_ids: Option<Vec<String>> = match ctx.options.schema_tool_ids.as_ref() {
            Some(ids) if !ids.is_empty() => {
                let mut extended_ids = ids.clone();

                // ğŸ†• è‡ªåŠ¨æ·»åŠ  attempt_completion åˆ°å·¥å…·åˆ—è¡¨ï¼ˆå¦‚æœå°šæœªåŒ…å«ï¼‰
                // è¿™æ˜¯å”¯ä¸€éœ€è¦åœ¨æ­¤æ·»åŠ çš„å·¥å…·ï¼Œå› ä¸ºå®ƒæ˜¯ Agent æ¨¡å¼çš„ç»ˆæ­¢ä¿¡å·
                if !extended_ids
                    .iter()
                    .any(|id| id == super::tools::attempt_completion::TOOL_NAME)
                {
                    extended_ids.push(super::tools::attempt_completion::TOOL_NAME.to_string());
                    log::debug!(
                        "[ChatV2::pipeline] Auto-injected attempt_completion tool (Agent mode)"
                    );
                }

                Some(extended_ids)
            }
            _ => None,
        };

        let injected_count = super::tools::injector::inject_tool_schemas(
            effective_tool_ids.as_ref(),
            &mut llm_context,
        );
        if injected_count > 0 {
            log::info!(
                "[ChatV2::pipeline] Injected {} tool schemas via schema_tool_ids",
                injected_count
            );
        }

        // ====================================================================
        // ğŸ†• Workspace å·¥å…·æ³¨å…¥ï¼šå·²è¿ç§»åˆ°å†…ç½® MCP æœåŠ¡å™¨
        // ====================================================================
        // 2026-01-16: Workspace å·¥å…·å·²è¿ç§»åˆ° builtinMcpServer.tsï¼Œ
        // é€šè¿‡å‰ç«¯ mcp_tool_schemas ä¼ é€’ï¼Œä¸å†éœ€è¦åç«¯è‡ªåŠ¨æ³¨å…¥ã€‚
        // æ‰§è¡Œå™¨ WorkspaceToolExecutor ä»ç„¶ä¿ç•™ï¼Œè´Ÿè´£å¤„ç† builtin-workspace_* å·¥å…·è°ƒç”¨ã€‚
        //
        // æ—§ä»£ç å·²ç§»é™¤ï¼šåç«¯è‡ªåŠ¨æ³¨å…¥ä¼šå¯¼è‡´å·¥å…·é‡å¤ï¼ˆbuiltin-workspace_create vs workspace_createï¼‰
        if ctx.get_workspace_id().is_some() && self.workspace_coordinator.is_some() {
            log::debug!(
                "[ChatV2::pipeline] Workspace session detected, tools should come from builtin MCP server"
            );
        }

        // ====================================================================
        // ğŸ†• MCP å·¥å…·æ³¨å…¥ï¼šä½¿ç”¨å‰ç«¯ä¼ é€’çš„ mcp_tool_schemas
        // ====================================================================
        // æ¶æ„è¯´æ˜ï¼š
        // - å‰ç«¯ mcpService ç®¡ç†å¤š MCP æœåŠ¡å™¨è¿æ¥ï¼Œå¹¶ç¼“å­˜å·¥å…· Schema
        // - å‰ç«¯ TauriAdapter ä» mcpService è·å–é€‰ä¸­æœåŠ¡å™¨çš„å·¥å…· Schema
        // - åç«¯ç›´æ¥ä½¿ç”¨å‰ç«¯ä¼ é€’çš„ Schemaï¼Œæ— éœ€è‡ªå·±è¿æ¥ MCP æœåŠ¡å™¨
        // - ğŸ”§ P1-49ï¼šåç«¯åº”ç”¨ whitelist/blacklist ç­–ç•¥è¿‡æ»¤ï¼Œç¡®ä¿é…ç½®ç”Ÿæ•ˆ

        // ğŸ” è°ƒè¯•æ—¥å¿—ï¼šæ£€æŸ¥ mcp_tool_schemas åœ¨ pipeline ä¸­çš„çŠ¶æ€
        let mcp_schema_count = ctx
            .options
            .mcp_tool_schemas
            .as_ref()
            .map(|s| s.len())
            .unwrap_or(0);
        log::info!(
            "[ChatV2::pipeline] ğŸ” MCP tool schemas check: count={}, is_some={}",
            mcp_schema_count,
            ctx.options.mcp_tool_schemas.is_some()
        );

        if let Some(ref tool_schemas) = ctx.options.mcp_tool_schemas {
            if !tool_schemas.is_empty() {
                log::info!(
                    "[ChatV2::pipeline] Processing {} MCP tool schemas from frontend",
                    tool_schemas.len()
                );

                // ğŸ”§ P1-49: è¯»å– MCP ç­–ç•¥é…ç½®ï¼ˆwhitelist/blacklistï¼‰
                let (whitelist, blacklist) = if let Some(ref main_db) = self.main_db {
                    let whitelist: Vec<String> = main_db
                        .get_setting("mcp.tools.whitelist")
                        .ok()
                        .flatten()
                        .map(|s| {
                            s.split(',')
                                .map(|x| x.trim().to_string())
                                .filter(|x| !x.is_empty())
                                .collect()
                        })
                        .unwrap_or_default();
                    let blacklist: Vec<String> = main_db
                        .get_setting("mcp.tools.blacklist")
                        .ok()
                        .flatten()
                        .map(|s| {
                            s.split(',')
                                .map(|x| x.trim().to_string())
                                .filter(|x| !x.is_empty())
                                .collect()
                        })
                        .unwrap_or_default();
                    (whitelist, blacklist)
                } else {
                    (Vec::new(), Vec::new())
                };

                log::debug!(
                    "[ChatV2::pipeline] MCP policy: whitelist={:?}, blacklist={:?}",
                    whitelist,
                    blacklist
                );

                // å°†å‰ç«¯ä¼ é€’çš„ MCP å·¥å…· Schema è½¬æ¢ä¸º LLM å¯ç”¨çš„æ ¼å¼
                // ğŸ”§ P1-49: åº”ç”¨ whitelist/blacklist è¿‡æ»¤
                let mcp_tool_values: Vec<Value> = tool_schemas
                    .iter()
                    .filter(|tool| {
                        // builtin- å‰ç¼€çš„å·¥å…·ä¸å—ç­–ç•¥è¿‡æ»¤å½±å“
                        if tool.name.starts_with(BUILTIN_NAMESPACE) {
                            return true;
                        }
                        // é»‘åå•ä¼˜å…ˆçº§æœ€é«˜
                        if !blacklist.is_empty() && blacklist.iter().any(|b| b == &tool.name) {
                            log::debug!(
                                "[ChatV2::pipeline] Tool '{}' blocked by blacklist",
                                tool.name
                            );
                            return false;
                        }
                        // å¦‚æœç™½åå•éç©ºï¼Œå·¥å…·å¿…é¡»åœ¨ç™½åå•ä¸­
                        if !whitelist.is_empty() && !whitelist.iter().any(|w| w == &tool.name) {
                            log::debug!("[ChatV2::pipeline] Tool '{}' not in whitelist", tool.name);
                            return false;
                        }
                        true
                    })
                    .map(|tool| {
                        // ğŸ”§ P0-19 ä¿®å¤ï¼šbuiltin- å‰ç¼€çš„å·¥å…·ä¿æŒåŸåï¼ŒMCP å·¥å…·æ·»åŠ  mcp_ å‰ç¼€
                        // åŸå› ï¼šexecutor æ£€æŸ¥ tool_name.starts_with("builtin-")ï¼Œ
                        //       å¦‚æœå˜æˆ "mcp_builtin-..." åˆ™æ— æ³•åŒ¹é…
                        let tool_name = if tool.name.starts_with(BUILTIN_NAMESPACE) {
                            tool.name.clone()
                        } else {
                            format!("mcp_{}", tool.name)
                        };
                        json!({
                            "type": "function",
                            "function": {
                                "name": tool_name,
                                "description": tool.description.clone().unwrap_or_default(),
                                "parameters": tool.input_schema.clone().unwrap_or(json!({}))
                            }
                        })
                    })
                    .collect();

                let filtered_count = mcp_tool_values.len();
                let original_count = tool_schemas.len();
                if filtered_count < original_count {
                    log::info!(
                        "[ChatV2::pipeline] MCP policy filtered: {}/{} tools allowed",
                        filtered_count,
                        original_count
                    );
                }

                // åˆå¹¶åˆ° custom_toolsï¼ˆå¦‚æœå·²å­˜åœ¨åˆ™è¿½åŠ ï¼‰
                if !mcp_tool_values.is_empty() {
                    if let Some(existing) = llm_context.get_mut("custom_tools") {
                        if let Some(arr) = existing.as_array_mut() {
                            for schema in mcp_tool_values {
                                arr.push(schema);
                            }
                            log::info!(
                                "[ChatV2::pipeline] Appended {} MCP tools to custom_tools",
                                filtered_count
                            );
                        }
                    } else {
                        llm_context.insert("custom_tools".into(), Value::Array(mcp_tool_values));
                        log::info!(
                            "[ChatV2::pipeline] Injected {} MCP tools as custom_tools",
                            filtered_count
                        );
                    }
                }

                // è®°å½•å·¥å…·åç§°ç”¨äºè°ƒè¯•
                let tool_names: Vec<&str> = tool_schemas.iter().map(|t| t.name.as_str()).collect();
                log::debug!(
                    "[ChatV2::pipeline] MCP tools (before filter): {:?}",
                    tool_names
                );
            }
        }

        // ç”Ÿæˆæµäº‹ä»¶æ ‡è¯†ç¬¦
        let stream_event = format!("chat_v2_event_{}", ctx.session_id);

        // æ³¨å†Œ LLM æµå¼å›è°ƒ hooks
        self.llm_manager
            .register_stream_hooks(&stream_event, adapter.clone())
            .await;

        // è·å–è°ƒç”¨é€‰é¡¹
        // ğŸ”§ P0ä¿®å¤ï¼šå§‹ç»ˆç¦ç”¨ LLM Manager å†…éƒ¨çš„å·¥å…·æ‰§è¡Œï¼Œç”± Pipeline å®Œå…¨æ¥ç®¡
        // è¿™é¿å…äº†å·¥å…·è¢«æ‰§è¡Œä¸¤æ¬¡ï¼ˆLLM Manager å†…éƒ¨ä¸€æ¬¡ï¼ŒPipeline ä¸€æ¬¡ï¼‰
        // ä»¥åŠå·¥å…·è°ƒç”¨ start äº‹ä»¶è¢«é‡å¤å‘å°„çš„é—®é¢˜
        let disable_tools = true;
        // ğŸ”§ P0ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ model2_override_idï¼ˆModelPanel ä¸­é€‰æ‹©çš„æ¨¡å‹ï¼‰ï¼Œå…¶æ¬¡ä½¿ç”¨ model_id
        let model_override = ctx
            .options
            .model2_override_id
            .clone()
            .or_else(|| ctx.options.model_id.clone());
        let temp_override = ctx.options.temperature;
        let top_p_override = ctx.options.top_p;
        let frequency_penalty_override = ctx.options.frequency_penalty;
        let presence_penalty_override = ctx.options.presence_penalty;
        let max_tokens_override = ctx.options.max_tokens;
        // ğŸ”§ P1ä¿®å¤ï¼šå°† context_limit ä½œä¸º max_input_tokens_override ä¼ é€’ç»™ LLM
        let max_input_tokens_override = ctx.options.context_limit.map(|v| v as usize);
        // ğŸ”§ P2ä¿®å¤ï¼šå§‹ç»ˆä½¿ç”¨ prompt_builder ç”Ÿæˆçš„ system_promptï¼ˆXML æ ¼å¼ï¼‰
        // prompt_builder å·²ç»å°†å‰ç«¯ä¼ å…¥çš„ system_prompt_override ä½œä¸º base_prompt å¤„ç†
        // ä¸å†è®©å‰ç«¯çš„å€¼ç›´æ¥è¦†ç›–ï¼Œé¿å…ä¸¢å¤± LaTeX è§„åˆ™ç­‰ XML æ ¼å¼å†…å®¹
        let system_prompt_override = Some(system_prompt.to_string());

        // è·å– window ç”¨äºæµå¼äº‹ä»¶å‘å°„
        let window = emitter.window();

        log::info!(
            "[ChatV2::pipeline] Calling LLMManager, stream_event={}, model_override={:?}, top_p={:?}, max_tokens={:?}, max_input_tokens={:?}",
            stream_event,
            model_override,
            top_p_override,
            max_tokens_override,
            max_input_tokens_override
        );

        // è°ƒç”¨ LLMManager çš„æµå¼æ¥å£
        // ğŸ”§ P1ä¿®å¤ï¼šæ·»åŠ  Pipeline å±‚è¶…æ—¶ä¿æŠ¤ï¼Œä¸å®Œå…¨ä¾èµ–ä¸Šæ¸¸ LLM é…ç½®
        let llm_future = self.llm_manager.call_unified_model_2_stream(
            &llm_context,
            &messages,
            "",   // subject - Chat V2 ä¸ä½¿ç”¨ç§‘ç›®
            true, // enable_chain_of_thought
            enable_thinking,
            Some("chat_v2"),
            window,
            &stream_event,
            None, // trace_id
            disable_tools,
            max_input_tokens_override, // ğŸ”§ P1ä¿®å¤ï¼šä¼ é€’ context_limit ä½œä¸ºè¾“å…¥ token é™åˆ¶
            model_override,
            temp_override,
            system_prompt_override,
            top_p_override,
            frequency_penalty_override,
            presence_penalty_override,
            max_tokens_override,
        );

        let call_result =
            match timeout(Duration::from_secs(LLM_STREAM_TIMEOUT_SECS), llm_future).await {
                Ok(result) => result,
                Err(_) => {
                    log::error!(
                        "[ChatV2::pipeline] LLM stream call timeout after {}s, session={}",
                        LLM_STREAM_TIMEOUT_SECS,
                        ctx.session_id
                    );
                    return Err(ChatV2Error::Timeout(format!(
                        "LLM stream call timed out after {}s",
                        LLM_STREAM_TIMEOUT_SECS
                    )));
                }
            };

        // æ³¨é”€ hooks
        self.llm_manager
            .unregister_stream_hooks(&stream_event)
            .await;

        // å¤„ç† LLM è°ƒç”¨ç»“æœ
        match call_result {
            Ok(output) => {
                log::info!(
                    "[ChatV2::pipeline] LLM call succeeded, cancelled={}, content_len={}",
                    output.cancelled,
                    output.assistant_message.len()
                );

                // æ›´æ–°ä¸Šä¸‹æ–‡
                ctx.final_content = adapter.get_accumulated_content();
                ctx.final_reasoning = adapter.get_accumulated_reasoning();
                // ğŸ”§ ä¿®å¤ï¼šä¿å­˜æµå¼è¿‡ç¨‹ä¸­åˆ›å»ºçš„å— IDï¼Œç¡®ä¿ save_results ä½¿ç”¨ç›¸åŒçš„ ID
                ctx.streaming_thinking_block_id = adapter.get_thinking_block_id();
                ctx.streaming_content_block_id = adapter.get_content_block_id();

                log::info!(
                    "[ChatV2::pipeline] After LLM call: final_content_len={}, final_reasoning={:?}, thinking_block_id={:?}, content_block_id={:?}",
                    ctx.final_content.len(),
                    ctx.final_reasoning.as_ref().map(|r| r.len()),
                    ctx.streaming_thinking_block_id,
                    ctx.streaming_content_block_id
                );

                // å¦‚æœ adapter ç´¯ç§¯å†…å®¹ä¸ºç©ºä½†è¾“å‡ºä¸ä¸ºç©ºï¼Œä½¿ç”¨ LLM è¾“å‡º
                if ctx.final_content.is_empty() && !output.assistant_message.is_empty() {
                    ctx.final_content = output.assistant_message.clone();
                }

                // ============================================================
                // Token ä½¿ç”¨é‡ç»Ÿè®¡ä¸ç´¯åŠ ï¼ˆPrompt 4ï¼‰
                // ============================================================
                let round_usage = self.get_or_estimate_usage(
                    &adapter,
                    &messages,
                    &ctx.final_content,
                    system_prompt,
                    ctx.options.model_id.as_deref(),
                );

                // ç´¯åŠ åˆ° PipelineContext.token_usage
                ctx.token_usage.accumulate(&round_usage);

                log::info!(
                    "[ChatV2::pipeline] Token usage for round {}: prompt={}, completion={}, total={}, source={}; Accumulated: prompt={}, completion={}, total={}, source={}",
                    recursion_depth,
                    round_usage.prompt_tokens,
                    round_usage.completion_tokens,
                    round_usage.total_tokens,
                    round_usage.source,
                    ctx.token_usage.prompt_tokens,
                    ctx.token_usage.completion_tokens,
                    ctx.token_usage.total_tokens,
                    ctx.token_usage.source
                );

                // è®°å½• LLM ä½¿ç”¨é‡åˆ°æ•°æ®åº“
                // ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨è§£æåçš„æ¨¡å‹æ˜¾ç¤ºåç§°ï¼Œé¿å…æ˜¾ç¤ºé…ç½® ID
                let model_for_usage = ctx
                    .model_display_name
                    .as_deref()
                    .or(ctx.options.model_id.as_deref())
                    .unwrap_or("unknown");
                crate::llm_usage::record_llm_usage(
                    crate::llm_usage::CallerType::ChatV2,
                    model_for_usage,
                    round_usage.prompt_tokens,
                    round_usage.completion_tokens,
                    None, // reasoning_tokens - adapter å±‚é¢å·²å•ç‹¬å¤„ç†
                    None, // cached_tokens
                    Some(ctx.session_id.clone()),
                    None, // duration_ms - åœ¨ adapter å±‚é¢å·²è®°å½•
                    true,
                    None,
                );
            }
            Err(e) => {
                // è°ƒç”¨ adapter çš„é”™è¯¯å¤„ç†
                adapter.on_error(&e.to_string());
                log::error!("[ChatV2::pipeline] LLM call failed: {}", e);

                // è®°å½•å¤±è´¥çš„ LLM è°ƒç”¨
                // ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨è§£æåçš„æ¨¡å‹æ˜¾ç¤ºåç§°ï¼Œé¿å…æ˜¾ç¤ºé…ç½® ID
                let model_for_usage = ctx
                    .model_display_name
                    .as_deref()
                    .or(ctx.options.model_id.as_deref())
                    .unwrap_or("unknown");
                crate::llm_usage::record_llm_usage(
                    crate::llm_usage::CallerType::ChatV2,
                    model_for_usage,
                    0,
                    0,
                    None,
                    None,
                    Some(ctx.session_id.clone()),
                    None,
                    false,
                    Some(e.to_string()),
                );

                return Err(ChatV2Error::Llm(e.to_string()));
            }
        }

        // ============================================================
        // å¤„ç† LLM è¿”å›çš„å·¥å…·è°ƒç”¨
        // å·¥å…·è°ƒç”¨é€šè¿‡ LLMStreamHooks.on_tool_call() å›è°ƒæ”¶é›†åˆ° adapter ä¸­ã€‚
        // åœ¨ LLM è°ƒç”¨å®Œæˆåï¼Œä» adapter å–å‡ºæ”¶é›†åˆ°çš„å·¥å…·è°ƒç”¨è¿›è¡Œå¤„ç†ã€‚
        // ============================================================
        let tool_calls = adapter.take_tool_calls();

        // å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ‰§è¡Œå¹¶é€’å½’
        if !tool_calls.is_empty() {
            log::info!(
                "[ChatV2::pipeline] LLM returned {} tool calls, executing sequentially...",
                tool_calls.len()
            );

            // ============================================================
            // Interleaved Thinking æ”¯æŒï¼šæ”¶é›†æœ¬è½®äº§ç”Ÿçš„ thinking/content å—
            // åœ¨å·¥å…·è°ƒç”¨ä¹‹å‰ï¼Œå°†æœ¬è½®çš„ thinking å—æ·»åŠ åˆ°äº¤æ›¿åˆ—è¡¨
            // æ³¨æ„ï¼šå·¥å…·è°ƒç”¨æ¨¡å¼ä¸‹ï¼ŒLLM é€šå¸¸ä¸ä¼šè¿”å› contentï¼ˆè¿”å› tool_use ä»£æ›¿ï¼‰
            // ============================================================
            let current_reasoning = adapter.get_accumulated_reasoning();
            ctx.collect_round_blocks(
                adapter.get_thinking_block_id(),
                current_reasoning.clone(),
                None, // å·¥å…·è°ƒç”¨æ¨¡å¼ä¸‹ï¼Œcontent å—é€šå¸¸ä¸ºç©º
                None,
                &ctx.assistant_message_id.clone(),
            );

            // ğŸ”§ ä¿®å¤ï¼šå‘å°„ thinking å—çš„ end äº‹ä»¶ï¼Œé€šçŸ¥å‰ç«¯æ€ç»´é“¾å·²ç»“æŸ
            // ä¹‹å‰åªè°ƒç”¨äº† collect_round_blocks æ”¶é›†æ•°æ®ï¼Œä½†æ²¡æœ‰å‘å°„ end äº‹ä»¶
            // è¿™å¯¼è‡´å‰ç«¯ä¸€ç›´æ˜¾ç¤º"æ€è€ƒä¸­..."çŠ¶æ€
            adapter.finalize_all();

            // ğŸ”§ DeepSeek Thinking Modeï¼šä¿å­˜ reasoning_content ç”¨äºä¸‹ä¸€è½® API è°ƒç”¨
            // æ ¹æ® DeepSeek API æ–‡æ¡£ï¼Œåœ¨å·¥å…·è°ƒç”¨è¿­ä»£ä¸­éœ€è¦å›ä¼  reasoning_content
            ctx.pending_reasoning_for_api = current_reasoning;
            log::debug!(
                "[ChatV2::pipeline] Interleaved: collected thinking block for round {}, total blocks={}, pending_reasoning={}",
                recursion_depth,
                ctx.interleaved_block_ids.len(),
                ctx.pending_reasoning_for_api.as_ref().map(|s| s.len()).unwrap_or(0)
            );

            // ============================================================
            // ğŸ†• P15 ä¿®å¤ï¼ˆè¡¥å……ï¼‰ï¼šå·¥å…·æ‰§è¡Œå‰ä¸­é—´ä¿å­˜ç‚¹
            // ç¡®ä¿ thinking å—ç­‰å·²ç”Ÿæˆå†…å®¹åœ¨å·¥å…·æ‰§è¡Œï¼ˆå¯èƒ½é˜»å¡ï¼‰å‰è¢«æŒä¹…åŒ–
            // å…³é”®åœºæ™¯ï¼šcoordinator_sleep ä¼šé˜»å¡ï¼Œå¦‚æœåªåœ¨å·¥å…·æ‰§è¡Œåä¿å­˜ï¼Œä¿å­˜æ°¸è¿œä¸ä¼šæ‰§è¡Œ
            // ============================================================
            if let Err(e) = self.save_intermediate_results(ctx).await {
                log::warn!(
                    "[ChatV2::pipeline] Failed to save intermediate results before tool execution: {}",
                    e
                );
            } else if !ctx.interleaved_blocks.is_empty() {
                log::info!(
                    "[ChatV2::pipeline] Pre-tool intermediate save completed, blocks={}",
                    ctx.interleaved_block_ids.len()
                );
            }

            // å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
            let canvas_note_id = ctx.options.canvas_note_id.clone();
            // ğŸ†• P1-C: ä¼ é€’ skill_allowed_tools è¿›è¡Œå·¥å…·æ‰§è¡Œæ ¡éªŒ
            let skill_allowed_tools = ctx.options.skill_allowed_tools.clone();
            // ğŸ†• æ¸è¿›æŠ«éœ²ï¼šä¼ é€’ skill_contents ç»™å·¥å…·æ‰§è¡Œå™¨
            let skill_contents = ctx.options.skill_contents.clone();
            let active_skill_ids = ctx.options.active_skill_ids.clone();
            let rag_top_k = ctx.options.rag_top_k;
            let rag_enable_reranking = ctx.options.rag_enable_reranking;
            // ğŸ†• å–æ¶ˆæ”¯æŒï¼šä¼ é€’å–æ¶ˆä»¤ç‰Œç»™å·¥å…·æ‰§è¡Œå™¨
            let cancel_token = ctx.cancellation_token();
            let tool_results = self
                .execute_tool_calls(
                    &tool_calls,
                    &emitter,
                    &ctx.session_id,
                    &ctx.assistant_message_id,
                    &canvas_note_id,
                    &skill_allowed_tools,
                    &skill_contents,
                    &active_skill_ids,
                    cancel_token,
                    rag_top_k,
                    rag_enable_reranking,
                )
                .await?;

            // è®°å½•æ‰§è¡Œç»“æœ
            let success_count = tool_results.iter().filter(|r| r.success).count();
            log::info!(
                "[ChatV2::pipeline] Tool execution completed: {}/{} succeeded",
                success_count,
                tool_results.len()
            );

            // ============================================================
            // ğŸ†• æ¸è¿›æŠ«éœ²ï¼šload_skills æ‰§è¡ŒååŠ¨æ€è¿½åŠ å·¥å…·åˆ° tools æ•°ç»„
            // ============================================================
            for tool_result in &tool_results {
                if super::tools::SkillsExecutor::is_load_skills_tool(&tool_result.tool_name)
                    && tool_result.success
                {
                    // ä»å·¥å…·ç»“æœä¸­æå–åŠ è½½çš„ skill_ids
                    if let Some(skill_ids) = tool_result
                        .output
                        .get("result")
                        .and_then(|r| r.get("skill_ids"))
                        .and_then(|ids| ids.as_array())
                    {
                        let loaded_skill_ids: Vec<String> = skill_ids
                            .iter()
                            .filter_map(|id| id.as_str().map(|s| s.to_string()))
                            .collect();

                        if !loaded_skill_ids.is_empty() {
                            // ä» skill_embedded_tools ä¸­è·å–å¯¹åº”çš„å·¥å…· Schema
                            if let Some(ref embedded_tools_map) = ctx.options.skill_embedded_tools {
                                let mut new_tools: Vec<super::types::McpToolSchema> = Vec::new();
                                for skill_id in &loaded_skill_ids {
                                    if let Some(tools) = embedded_tools_map.get(skill_id) {
                                        for tool in tools {
                                            new_tools.push(tool.clone());
                                        }
                                    }
                                }

                                if !new_tools.is_empty() {
                                    // åŠ¨æ€è¿½åŠ åˆ° mcp_tool_schemasï¼ˆå»é‡ï¼‰
                                    let mcp_schemas =
                                        ctx.options.mcp_tool_schemas.get_or_insert_with(Vec::new);
                                    let before_count = mcp_schemas.len();

                                    // æ”¶é›†å·²å­˜åœ¨çš„å·¥å…·åç§°ç”¨äºå»é‡ï¼ˆä½¿ç”¨ owned String é¿å…å€Ÿç”¨é—®é¢˜ï¼‰
                                    let existing_names: std::collections::HashSet<String> =
                                        mcp_schemas.iter().map(|t| t.name.clone()).collect();

                                    let mut added_count = 0;
                                    for tool in new_tools {
                                        if !existing_names.contains(&tool.name) {
                                            mcp_schemas.push(tool);
                                            added_count += 1;
                                        }
                                    }

                                    if added_count > 0 {
                                        log::info!(
                                            "[ChatV2::pipeline] ğŸ†• Progressive disclosure: added {} tools from skills {:?}, total tools: {} -> {}",
                                            added_count,
                                            loaded_skill_ids,
                                            before_count,
                                            mcp_schemas.len()
                                        );
                                    }
                                }
                            }
                        }
                    }
                }
            }

            // ============================================================
            // Interleaved Thinking æ”¯æŒï¼šæ·»åŠ å·¥å…·è°ƒç”¨å—åˆ°äº¤æ›¿åˆ—è¡¨
            // ============================================================
            let message_id = ctx.assistant_message_id.clone();
            for tool_result in &tool_results {
                ctx.add_tool_block(tool_result, &message_id);
            }
            log::debug!(
                "[ChatV2::pipeline] Interleaved: added {} tool blocks, total blocks={}",
                tool_results.len(),
                ctx.interleaved_block_ids.len()
            );

            // ğŸ†• æ–‡æ¡£ 29 P1-4ï¼šæ£€æµ‹ attempt_completion çš„ task_completed æ ‡å¿—
            // å¦‚æœæ£€æµ‹åˆ°ä»»åŠ¡å®Œæˆï¼Œç»ˆæ­¢é€’å½’å¾ªç¯ï¼Œä¸å†ç»§ç»­è°ƒç”¨ LLM
            let task_completed = tool_results.iter().any(|r| {
                r.output
                    .get("task_completed")
                    .and_then(|v| v.as_bool())
                    .unwrap_or(false)
            });

            // ğŸ†• å¿ƒè·³æœºåˆ¶ï¼šæ£€æµ‹ continue_execution æ ‡å¿—ï¼ˆTodoList æ°¸ç»­æ‰§è¡Œï¼‰
            // å¦‚æœä»»ä½•å·¥å…·è¿”å› continue_execution: trueï¼Œåˆ™ç»•è¿‡è½®æ¬¡é™åˆ¶ç»§ç»­æ‰§è¡Œ
            let has_continue_execution = tool_results.iter().any(|r| {
                r.output
                    .get("continue_execution")
                    .and_then(|v| v.as_bool())
                    .unwrap_or(false)
            });
            if has_continue_execution {
                log::info!(
                    "[ChatV2::pipeline] Heartbeat detected: continue_execution=true, will bypass recursion limit"
                );
            }

            // ğŸ†• æŒä¹…åŒ– TodoList çŠ¶æ€ï¼ˆæ¶ˆæ¯å†…ç»§ç»­æ‰§è¡Œæ”¯æŒï¼‰
            // æ£€æµ‹æ˜¯å¦æœ‰ todo å·¥å…·è°ƒç”¨ï¼Œå¦‚æœæœ‰åˆ™æŒä¹…åŒ–åˆ°æ•°æ®åº“
            for tool_result in &tool_results {
                if tool_result.tool_name.contains("todo_") {
                    // ä»å†…å­˜è·å–å½“å‰ TodoList çŠ¶æ€å¹¶æŒä¹…åŒ–
                    if let Some(todo_list) =
                        super::tools::todo_executor::get_todo_list(&ctx.session_id)
                    {
                        if let Err(e) = super::tools::todo_executor::persist_todo_list(
                            &self.db,
                            &ctx.session_id,
                            &ctx.assistant_message_id,
                            None, // variant_id æš‚æ—¶ä¸º Noneï¼Œåç»­å¯ä» ctx è·å–
                            &todo_list,
                        ) {
                            log::warn!("[ChatV2::pipeline] Failed to persist TodoList: {}", e);
                        } else {
                            log::debug!(
                                "[ChatV2::pipeline] TodoList persisted: session={}, progress={}/{}",
                                ctx.session_id,
                                todo_list.completed_count(),
                                todo_list.total_count()
                            );
                        }
                    }
                    break; // åªéœ€æŒä¹…åŒ–ä¸€æ¬¡
                }
            }

            // å°†å·¥å…·ç»“æœæ·»åŠ åˆ°ä¸Šä¸‹æ–‡
            // ğŸ”§ æ€ç»´é“¾ä¿®å¤ï¼šä¸ºè¿™ä¸€æ‰¹å·¥å…·ç»“æœä¸­çš„ç¬¬ä¸€ä¸ªé™„åŠ å½“å‰è½®æ¬¡çš„æ€ç»´é“¾
            // ä¸€è½® LLM è°ƒç”¨å¯èƒ½äº§ç”Ÿå¤šä¸ªå·¥å…·è°ƒç”¨ï¼Œä½†åªæœ‰ä¸€ä¸ªæ€ç»´é“¾
            let tool_results_with_reasoning: Vec<_> = tool_results
                .into_iter()
                .enumerate()
                .map(|(i, mut result)| {
                    if i == 0 {
                        // åªæœ‰ç¬¬ä¸€ä¸ªå·¥å…·ç»“æœæºå¸¦è¿™ä¸€è½®çš„æ€ç»´é“¾
                        result.reasoning_content = ctx.pending_reasoning_for_api.clone();
                    }
                    result
                })
                .collect();
            ctx.add_tool_results(tool_results_with_reasoning);

            // ============================================================
            // ğŸ†• P15 ä¿®å¤ï¼šå·¥å…·æ‰§è¡Œåä¸­é—´ä¿å­˜ç‚¹
            // ç¡®ä¿å·¥å…·æ‰§è¡Œç»“æœè¢«æŒä¹…åŒ–ï¼Œé˜²æ­¢åç»­é˜»å¡æ“ä½œï¼ˆå¦‚ç¡çœ ï¼‰æœŸé—´åˆ·æ–°ä¸¢å¤±æ•°æ®
            // ============================================================
            if let Err(e) = self.save_intermediate_results(ctx).await {
                log::warn!(
                    "[ChatV2::pipeline] Failed to save intermediate results after tool execution: {}",
                    e
                );
                // ä¸é˜»å¡æµç¨‹ï¼Œç»§ç»­æ‰§è¡Œ
            } else {
                log::info!(
                    "[ChatV2::pipeline] Intermediate save completed after tool round {}, blocks={}",
                    recursion_depth,
                    ctx.interleaved_block_ids.len()
                );
            }

            // ============================================================
            // ç©ºé—²æœŸæ£€æµ‹ç‚¹ 2ï¼šå·¥å…·æ‰§è¡Œå®Œæˆåæ£€æŸ¥ inbox
            // è®¾è®¡æ–‡æ¡£ 30ï¼šåœ¨å·¥å…·æ‰§è¡Œå®Œæˆåã€ä¸‹ä¸€è½® LLM è°ƒç”¨å‰æ£€æŸ¥
            // ============================================================
            if let Some(workspace_id) = ctx.get_workspace_id() {
                if let Some(ref coordinator) = self.workspace_coordinator {
                    use super::workspace::WorkspaceInjector;

                    let injector = WorkspaceInjector::new(coordinator.clone());
                    let max_injections = 2u32; // å·¥å…·æ‰§è¡Œåæœ€å¤šå¤„ç† 2 æ‰¹æ¶ˆæ¯

                    if let Ok(injection_result) =
                        injector.check_and_inject(workspace_id, &ctx.session_id, max_injections)
                    {
                        if !injection_result.messages.is_empty() {
                            let formatted = WorkspaceInjector::format_injected_messages(
                                &injection_result.messages,
                            );
                            ctx.inject_workspace_messages(formatted);

                            log::info!(
                                "[ChatV2::pipeline] Workspace tool-phase injection: {} messages, depth={}",
                                injection_result.messages.len(),
                                recursion_depth
                            );
                        }
                    }
                }
            }

            if task_completed {
                log::info!(
                    "[ChatV2::pipeline] Task completed detected via attempt_completion, stopping recursive loop at depth={}",
                    recursion_depth
                );

                // æ”¶é›†å½“å‰è½®æ¬¡çš„å—ï¼ˆæ— éœ€å†æ¬¡è°ƒç”¨ LLMï¼‰
                ctx.collect_round_blocks(
                    adapter.get_thinking_block_id(),
                    adapter.get_accumulated_reasoning(),
                    adapter.get_content_block_id(),
                    Some(ctx.final_content.clone()),
                    &ctx.assistant_message_id.clone(),
                );

                // æ¸…é™¤ pending_reasoning
                ctx.pending_reasoning_for_api = None;

                return Ok(());
            }

            // é€’å½’è°ƒç”¨ LLM å¤„ç†å·¥å…·ç»“æœ
            log::debug!(
                "[ChatV2::pipeline] Recursively calling LLM to process tool results, depth={}->{}",
                recursion_depth,
                recursion_depth + 1
            );
            return Box::pin(self.execute_with_tools(
                ctx,
                emitter,
                system_prompt,
                recursion_depth + 1,
            ))
            .await;
        }

        // ============================================================
        // æ— å·¥å…·è°ƒç”¨ï¼Œè¿™æ˜¯æœ€åä¸€è½® LLM è°ƒç”¨
        // æ”¶é›†æœ€ç»ˆçš„ thinking å’Œ content å—
        // ============================================================
        ctx.collect_round_blocks(
            adapter.get_thinking_block_id(),
            adapter.get_accumulated_reasoning(),
            adapter.get_content_block_id(),
            Some(ctx.final_content.clone()),
            &ctx.assistant_message_id.clone(),
        );

        // ğŸ”§ DeepSeek Thinking Modeï¼šæ¸…é™¤ pending_reasoning
        // æ ¹æ® DeepSeek API æ–‡æ¡£ï¼Œæ–°çš„ç”¨æˆ·é—®é¢˜ä¸éœ€è¦å›ä¼ ä¹‹å‰çš„ reasoning_content
        ctx.pending_reasoning_for_api = None;

        log::info!(
            "[ChatV2::pipeline] LLM call completed without tool calls, recursion_depth={}, total interleaved_blocks={}",
            recursion_depth,
            ctx.interleaved_block_ids.len()
        );

        Ok(())
    }

    /// å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå·¥å…·è°ƒç”¨
    ///
    /// ä½¿ç”¨ `futures::future::join_all` å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨ï¼Œ
    /// è¶…æ—¶ç­–ç•¥ç”± ToolExecutorRegistry ç»Ÿä¸€æ§åˆ¶ã€‚
    ///
    /// ## å‚æ•°
    /// - `tool_calls`: å·¥å…·è°ƒç”¨åˆ—è¡¨
    /// - `emitter`: äº‹ä»¶å‘å°„å™¨
    /// - `session_id`: ä¼šè¯ IDï¼ˆç”¨äºå·¥å…·çŠ¶æ€éš”ç¦»ï¼Œå¦‚ TodoListï¼‰
    /// - `message_id`: æ¶ˆæ¯ IDï¼ˆç”¨äºå…³è”å—ï¼‰
    /// - `canvas_note_id`: Canvas ç¬”è®° IDï¼Œç”¨äº Canvas å·¥å…·é»˜è®¤å€¼
    /// - `skill_allowed_tools`: ğŸ†• P1-C Skill å·¥å…·ç™½åå•ï¼ˆå¦‚æœè®¾ç½®ï¼Œåªå…è®¸æ‰§è¡Œç™½åå•ä¸­çš„å·¥å…·ï¼‰
    ///
    /// ## è¿”å›
    /// å·¥å…·è°ƒç”¨ç»“æœåˆ—è¡¨
    /// å¯¹å·¥å…·è°ƒç”¨åˆ—è¡¨è¿›è¡Œä¾èµ–æ„ŸçŸ¥æ’åº
    ///
    /// è§„åˆ™ï¼ˆæŒ‰ä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰ï¼š
    /// 1. chatanki: run/start â†’ control â†’ status/analyze â†’ wait â†’ export/sync
    /// 2. pptx/xlsx/docx: _create å¿…é¡»åœ¨ _read/_extract/_get/_replace/_edit/_to_spec ä¹‹å‰
    /// 3. åŒä¼˜å…ˆçº§å†…ä¿æŒåŸå§‹é¡ºåºï¼ˆstable sortï¼‰
    fn ordered_tool_calls_for_execution(&self, tool_calls: &[ToolCall]) -> Vec<ToolCall> {
        /// å‰¥ç¦»å·¥å…·åå‰ç¼€ï¼Œè¿”å›çŸ­å
        fn strip_tool_prefix(tool_name: &str) -> &str {
            // builtin-xxx, mcp_xxx, mcp.tools.xxx, namespace.xxx
            tool_name
                .strip_prefix(BUILTIN_NAMESPACE)
                .or_else(|| tool_name.strip_prefix("mcp_"))
                .or_else(|| tool_name.strip_prefix("mcp.tools."))
                .unwrap_or(tool_name)
        }

        /// ChatAnki å·¥å…·ä¼˜å…ˆçº§
        fn chatanki_priority(short_name: &str) -> Option<u8> {
            if !short_name.starts_with("chatanki_") {
                return None;
            }
            let p = match short_name {
                "chatanki_run" | "chatanki_start" => 0,
                "chatanki_control" => 1,
                "chatanki_status"
                | "chatanki_list_templates"
                | "chatanki_analyze"
                | "chatanki_check_anki_connect" => 2,
                "chatanki_wait" => 3,
                "chatanki_export" | "chatanki_sync" => 4,
                _ => 2,
            };
            Some(p)
        }

        /// æ–‡æ¡£å·¥å…·ä¼˜å…ˆçº§ï¼ˆpptx/xlsx/docxï¼‰
        /// _create = 0, å…¶ä½™ = 1, ä¸åŒ¹é… = None
        fn document_tool_priority(short_name: &str) -> Option<u8> {
            // æ£€æµ‹æ˜¯å¦å±äºæ–‡æ¡£å·¥å…·æ—
            let prefixes = ["pptx_", "xlsx_", "docx_"];
            let matched_prefix = prefixes.iter().find(|p| short_name.starts_with(**p));
            let prefix = match matched_prefix {
                Some(p) => *p,
                None => return None,
            };

            let action = &short_name[prefix.len()..];
            let p = match action {
                "create" => 0,                       // åˆ›å»ºæ–‡ä»¶ â€” å¿…é¡»æœ€å…ˆ
                "read_structured" | "get_metadata"   // åªè¯»æ“ä½œ
                | "extract_tables" => 1,
                "edit_cells" | "replace_text" => 2,  // å†™æ“ä½œï¼ˆä¾èµ–æ–‡ä»¶å­˜åœ¨ï¼‰
                "to_spec" => 3,                      // è½¬æ¢æ“ä½œï¼ˆä¾èµ–æ–‡ä»¶å­˜åœ¨ï¼‰
                _ => 1,                              // æœªçŸ¥åŠ¨ä½œï¼ŒæŒ‰åªè¯»å¯¹å¾…
            };
            Some(p)
        }

        /// ç»¼åˆä¼˜å…ˆçº§ï¼š(group_priority, action_priority)
        /// group 0 = chatanki, 1 = document, 99 = other
        fn tool_priority(tool_name: &str) -> (u8, u8) {
            let short = strip_tool_prefix(tool_name);
            if let Some(p) = chatanki_priority(short) {
                return (0, p);
            }
            if let Some(p) = document_tool_priority(short) {
                return (1, p);
            }
            (99, 0)
        }

        // å¿«é€Ÿè·¯å¾„ï¼šå¦‚æœæ²¡æœ‰éœ€è¦æ’åºçš„å·¥å…·ï¼Œç›´æ¥è¿”å›åŸå§‹é¡ºåº
        let needs_sort = tool_calls.iter().any(|call| {
            let short = strip_tool_prefix(&call.name);
            chatanki_priority(short).is_some() || document_tool_priority(short).is_some()
        });
        if !needs_sort {
            return tool_calls.to_vec();
        }

        let mut indexed_calls: Vec<(usize, ToolCall)> =
            tool_calls.iter().cloned().enumerate().collect();
        // stable sort: å…ˆæŒ‰ tool_priorityï¼ŒåŒä¼˜å…ˆçº§ä¿æŒåŸå§‹é¡ºåºï¼ˆidxï¼‰
        indexed_calls.sort_by_key(|(idx, call)| {
            let (group, action) = tool_priority(&call.name);
            (group, action, *idx)
        });

        let reordered: Vec<ToolCall> =
            indexed_calls.into_iter().map(|(_, call)| call).collect();

        // æ—¥å¿—ï¼šå¦‚æœé¡ºåºå‘ç”Ÿå˜åŒ–ï¼Œè®°å½•é‡æ’ç»“æœ
        if reordered
            .iter()
            .zip(tool_calls.iter())
            .any(|(a, b)| a.id != b.id)
        {
            let names: Vec<&str> = reordered.iter().map(|c| c.name.as_str()).collect();
            log::info!(
                "[ChatV2::pipeline] Tool calls reordered for dependency safety: {:?}",
                names
            );
        }

        reordered
    }

    async fn execute_tool_calls(
        &self,
        tool_calls: &[ToolCall],
        emitter: &Arc<ChatV2EventEmitter>,
        session_id: &str,
        message_id: &str,
        canvas_note_id: &Option<String>,
        skill_allowed_tools: &Option<Vec<String>>,
        skill_contents: &Option<std::collections::HashMap<String, String>>,
        active_skill_ids: &Option<Vec<String>>,
        cancellation_token: Option<&CancellationToken>,
        rag_top_k: Option<u32>,
        rag_enable_reranking: Option<bool>,
    ) -> ChatV2Result<Vec<ToolResultInfo>> {
        let ordered_tool_calls = self.ordered_tool_calls_for_execution(tool_calls);
        log::debug!(
            "[ChatV2::pipeline] Executing {} tool calls sequentially",
            ordered_tool_calls.len()
        );

        // ğŸ”§ 2026-02-16: è¿½è¸ªæœ¬æ‰¹æ¬¡ _create å·¥å…·è¿”å›çš„ file_idï¼Œç”¨äºä¿®æ­£ä¾èµ–å·¥å…·ä¸­
        // LLM å‡­ç©ºæé€ çš„ resource_idï¼ˆLLM åœ¨åŒä¸€æ‰¹æ¬¡ç”Ÿæˆ create + read/edit æ—¶ï¼Œ
        // æ— æ³•æå‰çŸ¥é“ create è¿”å›çš„å®é™… file_idï¼‰
        // key: æ–‡æ¡£ç±»å‹å‰ç¼€ ("xlsx" / "pptx" / "docx")
        // value: create å·¥å…·è¿”å›çš„å®é™… file_id
        let mut created_file_ids: std::collections::HashMap<String, String> =
            std::collections::HashMap::new();

        // é¡ºåºæ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œé¿å…éå¹‚ç­‰å·¥å…·å¹¶å‘å¯¼è‡´çš„æ•°æ®ç«æ€
        let mut tool_results = Vec::new();
        for tc in ordered_tool_calls.iter() {
            // æ£€æµ‹æˆªæ–­æ ‡è®°ï¼šLLM è¾“å‡ºè¢« max_tokens æˆªæ–­å¯¼è‡´å·¥å…·è°ƒç”¨ JSON ä¸å®Œæ•´
            // æ­¤æ—¶ä¸æ‰§è¡Œå·¥å…·ï¼Œç›´æ¥è¿”å›é”™è¯¯ tool_result è®© LLM ç¼©å°è¾“å‡ºé‡è¯•
            if tc
                .arguments
                .get("_truncation_error")
                .and_then(|v| v.as_bool())
                .unwrap_or(false)
            {
                let error_msg = tc
                    .arguments
                    .get("_error_message")
                    .and_then(|v| v.as_str())
                    .unwrap_or("å·¥å…·è°ƒç”¨å‚æ•°è¢«æˆªæ–­");
                let args_len = tc
                    .arguments
                    .get("_args_len")
                    .and_then(|v| v.as_u64())
                    .unwrap_or(0);

                log::warn!(
                    "[ChatV2::pipeline] å·¥å…·è°ƒç”¨ JSON è¢«æˆªæ–­ï¼Œè·³è¿‡æ‰§è¡Œå¹¶åé¦ˆ LLM é‡è¯•: tool={}, args_len={}",
                    tc.name,
                    args_len
                );

                // ğŸ†• P1 ä¿®å¤ï¼šç”Ÿæˆ block_id å¹¶å‘å°„å‰ç«¯äº‹ä»¶ï¼Œè®©ç”¨æˆ·çœ‹åˆ°æˆªæ–­é”™è¯¯
                let block_id = MessageBlock::generate_id();
                let truncation_display_msg = format!(
                    "å·¥å…·è°ƒç”¨ {} çš„å‚æ•°å› è¾“å‡ºé•¿åº¦è¶…é™è¢«æˆªæ–­ï¼ˆå·²ç”Ÿæˆ {} å­—ç¬¦ï¼‰ï¼Œå·¥å…·æœªæ‰§è¡Œï¼Œæ­£åœ¨è‡ªåŠ¨é‡è¯•ã€‚",
                    tc.name, args_len
                );

                // å‘å°„ tool_call start äº‹ä»¶ï¼ˆåˆ›å»ºå‰ç«¯å—ï¼‰
                emitter.emit_tool_call_start(
                    message_id,
                    &block_id,
                    &tc.name,
                    json!({ "_truncated": true, "_args_len": args_len }),
                    Some(&tc.id),
                    None, // variant_id
                );

                // å‘å°„ tool_call error äº‹ä»¶ï¼ˆæ ‡è®°å—ä¸ºé”™è¯¯çŠ¶æ€ï¼‰
                emitter.emit_error(
                    event_types::TOOL_CALL,
                    &block_id,
                    &truncation_display_msg,
                    None, // variant_id
                );

                let retry_hint = format!(
                    "CRITICAL ERROR: Tool call '{}' FAILED â€” your output was truncated at {} characters because it exceeded the max_tokens limit. The JSON arguments were incomplete and the tool was NOT executed.\n\n\
                    YOU MUST retry with significantly smaller arguments. Mandatory rules:\n\
                    1. Reduce the total argument size to under 50% of the previous attempt.\n\
                    2. For mindmap_create: create only the skeleton (top-level branches + minimal children), then use edit_nodes to add details incrementally.\n\
                    3. For any tool: remove verbose text, avoid deeply nested structures, keep JSON compact.\n\
                    4. If the content is inherently large, split it into multiple smaller tool calls.\n\n\
                    Do NOT repeat the same call with the same size â€” it will fail again.",
                    tc.name, args_len
                );

                tool_results.push(ToolResultInfo {
                    tool_call_id: Some(tc.id.clone()),
                    block_id: Some(block_id),
                    tool_name: tc.name.clone(),
                    input: tc.arguments.clone(),
                    output: json!({ "error": error_msg }),
                    success: false,
                    error: Some(retry_hint),
                    duration_ms: None,
                    reasoning_content: None,
                });
                continue;
            }

            // ğŸ”§ 2026-02-16: ä¿®æ­£ä¾èµ–å·¥å…·çš„ resource_id
            // å½“ LLM åœ¨åŒä¸€æ‰¹æ¬¡ç”Ÿæˆ create + ä¾èµ–å·¥å…·æ—¶ï¼Œä¾èµ–å·¥å…·çš„ resource_id
            // æ˜¯ LLM æé€ çš„ï¼ˆå› ä¸º create è¿˜æ²¡è¿”å›çœŸå® IDï¼‰ã€‚
            // è¿™é‡Œæ£€æµ‹å¹¶æ›¿æ¢ä¸ºæœ¬æ‰¹æ¬¡ create è¿”å›çš„å®é™… file_idã€‚
            let tc_to_execute = self.fixup_document_tool_resource_id(tc, &created_file_ids);
            let tc_ref = tc_to_execute.as_ref().unwrap_or(tc);

            match self
                .execute_single_tool(
                    tc_ref,
                    emitter,
                    session_id,
                    message_id,
                    canvas_note_id,
                    skill_allowed_tools,
                    skill_contents,
                    active_skill_ids,
                    cancellation_token.cloned(),
                    rag_top_k,
                    rag_enable_reranking,
                )
                .await
            {
                Ok(info) => {
                    // ğŸ”§ æ•è· _create å·¥å…·è¿”å›çš„ file_idï¼Œä¾›åç»­ä¾èµ–å·¥å…·ä½¿ç”¨
                    if info.success {
                        self.capture_created_file_id(&tc_ref.name, &info.output, &mut created_file_ids);
                    }
                    tool_results.push(info);
                }
                Err(e) => {
                    log::error!(
                        "[ChatV2::pipeline] Unexpected tool call error for {}: {}",
                        tc.name,
                        e
                    );
                    tool_results.push(ToolResultInfo {
                        tool_call_id: Some(tc.id.clone()),
                        block_id: None,
                        tool_name: tc.name.clone(),
                        input: tc.arguments.clone(),
                        output: json!(null),
                        success: false,
                        error: Some(e.to_string()),
                        duration_ms: None,
                        reasoning_content: None,
                    });
                }
            }
        }

        Ok(tool_results)
    }

    /// ğŸ”§ 2026-02-16: ä¿®æ­£ä¾èµ–å·¥å…·çš„ resource_id
    ///
    /// å½“ LLM åœ¨åŒä¸€æ‰¹æ¬¡åŒæ—¶ç”Ÿæˆ `_create` å’Œ `_read/_edit` ç­‰ä¾èµ–å·¥å…·æ—¶ï¼Œ
    /// ä¾èµ–å·¥å…·çš„ `resource_id` æ˜¯ LLM å‡­ç©ºæé€ çš„ï¼ˆå› ä¸º create å°šæœªè¿”å›çœŸå® IDï¼‰ã€‚
    /// æ­¤æ–¹æ³•æ£€æµ‹è¿™ç§æƒ…å†µå¹¶æ›¿æ¢ä¸ºæœ¬æ‰¹æ¬¡ _create å·¥å…·è¿”å›çš„å®é™… file_idã€‚
    ///
    /// æ›¿æ¢æ¡ä»¶ï¼ˆå…¨éƒ¨æ»¡è¶³æ‰æ›¿æ¢ï¼‰ï¼š
    /// 1. å·¥å…·æ˜¯æ–‡æ¡£ç±»å‹çš„é _create å·¥å…·ï¼ˆå¦‚ xlsx_read_structuredï¼‰
    /// 2. å‚æ•°ä¸­æœ‰ resource_id
    /// 3. æœ¬æ‰¹æ¬¡æœ‰å¯¹åº”æ–‡æ¡£ç±»å‹çš„ _create ç»“æœ
    /// 4. å½“å‰ resource_id ä¸ _create è¿”å›çš„ä¸åŒ
    /// 5. å½“å‰ resource_id åœ¨ VFS ä¸­ä¸å­˜åœ¨ï¼ˆç¡®è®¤æ˜¯æé€ çš„ï¼‰
    fn fixup_document_tool_resource_id(
        &self,
        tc: &ToolCall,
        created_file_ids: &std::collections::HashMap<String, String>,
    ) -> Option<ToolCall> {
        if created_file_ids.is_empty() {
            return None;
        }

        // å‰¥ç¦»å‰ç¼€
        let short_name = tc
            .name
            .strip_prefix(super::tools::builtin_retrieval_executor::BUILTIN_NAMESPACE)
            .or_else(|| tc.name.strip_prefix("mcp_"))
            .unwrap_or(&tc.name);

        // æ£€æµ‹æ–‡æ¡£å·¥å…·æ—
        let doc_type = if short_name.starts_with("pptx_") {
            "pptx"
        } else if short_name.starts_with("xlsx_") {
            "xlsx"
        } else if short_name.starts_with("docx_") {
            "docx"
        } else {
            return None;
        };

        // _create å·¥å…·æœ¬èº«ä¸éœ€è¦ fixup
        let action = &short_name[doc_type.len() + 1..]; // skip "xlsx_"
        if action == "create" {
            return None;
        }

        // è·å–å‚æ•°ä¸­çš„ resource_id
        let resource_id = tc.arguments.get("resource_id").and_then(|v| v.as_str())?;

        // è·å–æœ¬æ‰¹æ¬¡ _create è¿”å›çš„å®é™… file_id
        let actual_id = created_file_ids.get(doc_type)?;

        // å¦‚æœå·²ç»ä¸€è‡´ï¼Œæ— éœ€æ›¿æ¢
        if resource_id == actual_id.as_str() {
            return None;
        }

        // æ£€æŸ¥åŸå§‹ resource_id æ˜¯å¦åœ¨ VFS ä¸­å­˜åœ¨
        // å¦‚æœå­˜åœ¨ï¼Œè¯´æ˜ LLM å¼•ç”¨çš„æ˜¯ä¹‹å‰çš„æ–‡ä»¶ï¼Œä¸åº”æ›¿æ¢
        if let Some(ref vfs_db) = self.vfs_db {
            use crate::vfs::repos::VfsFileRepo;
            if let Ok(conn) = vfs_db.get_conn_safe() {
                if VfsFileRepo::get_file_with_conn(&conn, resource_id)
                    .ok()
                    .flatten()
                    .is_some()
                {
                    return None; // åŸå§‹ ID æœ‰æ•ˆï¼Œä¸æ›¿æ¢
                }
            }
        }

        // æ›¿æ¢ resource_id
        let mut fixed_tc = tc.clone();
        if let Some(obj) = fixed_tc.arguments.as_object_mut() {
            obj.insert(
                "resource_id".to_string(),
                serde_json::Value::String(actual_id.clone()),
            );
        }

        log::info!(
            "[ChatV2::pipeline] ğŸ”§ èµ„æºIDä¿®æ­£: {} çš„ resource_id '{}' â†’ '{}' (åŒæ‰¹æ¬¡ {}_create è¿”å›)",
            tc.name, resource_id, actual_id, doc_type
        );

        Some(fixed_tc)
    }

    /// ğŸ”§ 2026-02-16: æ•è· _create å·¥å…·è¿”å›çš„ file_id
    fn capture_created_file_id(
        &self,
        tool_name: &str,
        output: &serde_json::Value,
        created_file_ids: &mut std::collections::HashMap<String, String>,
    ) {
        let short_name = tool_name
            .strip_prefix(super::tools::builtin_retrieval_executor::BUILTIN_NAMESPACE)
            .or_else(|| tool_name.strip_prefix("mcp_"))
            .unwrap_or(tool_name);

        let doc_type = if short_name.starts_with("pptx_") {
            "pptx"
        } else if short_name.starts_with("xlsx_") {
            "xlsx"
        } else if short_name.starts_with("docx_") {
            "docx"
        } else {
            return;
        };

        let action = &short_name[doc_type.len() + 1..];
        if action != "create" {
            return;
        }

        // ä»è¾“å‡ºä¸­æå– file_idï¼ˆå¯èƒ½åµŒå¥—åœ¨ result å†…ï¼‰
        let file_id = output
            .get("file_id")
            .and_then(|v| v.as_str())
            .or_else(|| {
                output
                    .get("result")
                    .and_then(|r| r.get("file_id"))
                    .and_then(|v| v.as_str())
            });

        if let Some(id) = file_id {
            log::info!(
                "[ChatV2::pipeline] ğŸ“¦ æ•è· {}_create è¿”å›çš„ file_id: {}",
                doc_type,
                id
            );
            created_file_ids.insert(doc_type.to_string(), id.to_string());
        }
    }

    /// æ‰§è¡Œå•ä¸ªå·¥å…·è°ƒç”¨
    ///
    /// ğŸ†• æ–‡æ¡£ 29 P0-1: å§”æ‰˜ç»™ ToolExecutorRegistry æ‰§è¡Œ
    ///
    /// ## å‚æ•°
    /// - `tool_call`: å·¥å…·è°ƒç”¨
    /// - `emitter`: äº‹ä»¶å‘å°„å™¨
    /// - `session_id`: ä¼šè¯ IDï¼ˆç”¨äºå·¥å…·çŠ¶æ€éš”ç¦»ï¼Œå¦‚ TodoListï¼‰
    /// - `message_id`: æ¶ˆæ¯ ID
    /// - `canvas_note_id`: Canvas ç¬”è®° IDï¼Œç”¨äº Canvas å·¥å…·é»˜è®¤å€¼
    /// - `skill_allowed_tools`: ğŸ†• P1-C Skill å·¥å…·ç™½åå•
    /// - `cancellation_token`: ğŸ†• å–æ¶ˆä»¤ç‰Œï¼Œç”¨äºå·¥å…·æ‰§è¡Œå–æ¶ˆ
    ///
    /// ## è¿”å›
    /// å·¥å…·è°ƒç”¨ç»“æœ
    async fn execute_single_tool(
        &self,
        tool_call: &ToolCall,
        emitter: &Arc<ChatV2EventEmitter>,
        session_id: &str,
        message_id: &str,
        canvas_note_id: &Option<String>,
        skill_allowed_tools: &Option<Vec<String>>,
        skill_contents: &Option<std::collections::HashMap<String, String>>,
        active_skill_ids: &Option<Vec<String>>,
        cancellation_token: Option<CancellationToken>,
        rag_top_k: Option<u32>,
        rag_enable_reranking: Option<bool>,
    ) -> ChatV2Result<ToolResultInfo> {
        let block_id = MessageBlock::generate_id();

        log::debug!(
            "[ChatV2::pipeline] Executing tool via ExecutorRegistry: name={}, id={}",
            tool_call.name,
            tool_call.id
        );

        // ğŸ†• P1-C: Skill allowedTools ç™½åå•æ ¡éªŒ
        // å®‰å…¨é»˜è®¤ï¼šå½“ä¼šè¯ä¸­æœ‰æ¿€æ´»æŠ€èƒ½ä½†ç¼ºå¤± allowedTools æ—¶ï¼Œæ‹’ç»æ‰§è¡Œï¼ˆfail-closedï¼‰
        let has_active_skills = active_skill_ids
            .as_ref()
            .map(|skills| !skills.is_empty())
            .unwrap_or(false);
        let is_load_skills_tool =
            super::tools::SkillsExecutor::is_load_skills_tool(&tool_call.name);

        if !is_load_skills_tool {
            match skill_allowed_tools {
                Some(allowed_tools) if allowed_tools.is_empty() => {
                    log::warn!(
                        "[ChatV2::pipeline] ğŸ›¡ï¸ allowedTools is empty, blocking tool by default: {}",
                        tool_call.name
                    );
                    return Ok(ToolResultInfo {
                        tool_call_id: Some(tool_call.id.clone()),
                        block_id: Some(block_id),
                        tool_name: tool_call.name.clone(),
                        input: tool_call.arguments.clone(),
                        output: json!(null),
                        success: false,
                        error: Some("å½“å‰æŠ€èƒ½æœªå£°æ˜å¯ç”¨å·¥å…·ï¼Œå·²å®‰å…¨æ‹¦æˆª".to_string()),
                        duration_ms: None,
                        reasoning_content: None,
                    });
                }
                Some(allowed_tools) => {
                    let is_allowed = allowed_tools
                        .iter()
                        .any(|allowed| Self::skill_allows_tool(&tool_call.name, allowed));

                    if !is_allowed {
                        log::warn!(
                            "[ChatV2::pipeline] ğŸ›¡ï¸ Tool {} blocked by Skill allowedTools constraint: {:?}",
                            tool_call.name,
                            allowed_tools
                        );
                        return Ok(ToolResultInfo {
                            tool_call_id: Some(tool_call.id.clone()),
                            block_id: Some(block_id),
                            tool_name: tool_call.name.clone(),
                            input: tool_call.arguments.clone(),
                            output: json!(null),
                            success: false,
                            error: Some(format!(
                                "å½“å‰æŠ€èƒ½ä¸å…è®¸ä½¿ç”¨æ­¤å·¥å…·ï¼Œå…è®¸çš„å·¥å…·: {:?}",
                                allowed_tools
                            )),
                            duration_ms: None,
                            reasoning_content: None,
                        });
                    }
                }
                None if has_active_skills => {
                    log::warn!(
                        "[ChatV2::pipeline] ğŸ›¡ï¸ active skills detected but allowedTools missing, blocking tool: {}",
                        tool_call.name
                    );
                    return Ok(ToolResultInfo {
                        tool_call_id: Some(tool_call.id.clone()),
                        block_id: Some(block_id),
                        tool_name: tool_call.name.clone(),
                        input: tool_call.arguments.clone(),
                        output: json!(null),
                        success: false,
                        error: Some("æŠ€èƒ½å·¥å…·ç™½åå•ç¼ºå¤±ï¼Œå·²å®‰å…¨æ‹¦æˆª".to_string()),
                        duration_ms: None,
                        reasoning_content: None,
                    });
                }
                None => {
                    log::info!(
                        "[ChatV2::pipeline] No skill allowedTools constraint for tool: {}",
                        tool_call.name
                    );
                }
            }
        } else {
            log::info!(
                "[ChatV2::pipeline] load_skills bypasses allowedTools gating: {}",
                tool_call.name
            );
        }

        // ğŸ†• æ–‡æ¡£ 29 P1-3ï¼šæ£€æŸ¥å·¥å…·æ•æ„Ÿç­‰çº§ï¼Œå†³å®šæ˜¯å¦éœ€è¦ç”¨æˆ·å®¡æ‰¹
        let sensitivity = self.executor_registry.get_sensitivity(&tool_call.name);

        // ğŸ†• å…¨å±€å…å®¡æ‰¹å¼€å…³å’Œå•å·¥å…·è¦†ç›–ï¼š
        // 1. å…¨å±€å¼€å…³ tool_approval.global_bypass = "true" â†’ æ‰€æœ‰å·¥å…·è·³è¿‡å®¡æ‰¹
        // 2. å•å·¥å…·è¦†ç›– tool_approval.override.{tool_name} = "low" â†’ æ­¤å·¥å…·è·³è¿‡å®¡æ‰¹
        let effective_sensitivity = if let Some(ref db) = self.main_db {
            // æ£€æŸ¥å…¨å±€æ—è·¯å¼€å…³
            let global_bypass = db
                .get_setting("tool_approval.global_bypass")
                .ok()
                .flatten()
                .map(|v| v == "true")
                .unwrap_or(false);

            if global_bypass {
                Some(ToolSensitivity::Low)
            } else {
                // æ£€æŸ¥å•å·¥å…·è¦†ç›–
                let override_key = format!("tool_approval.override.{}", tool_call.name);
                if let Some(override_val) = db.get_setting(&override_key).ok().flatten() {
                    match override_val.as_str() {
                        "low" => Some(ToolSensitivity::Low),
                        "medium" => Some(ToolSensitivity::Medium),
                        "high" => Some(ToolSensitivity::High),
                        _ => sensitivity,
                    }
                } else {
                    sensitivity
                }
            }
        } else {
            sensitivity
        };

        if effective_sensitivity != Some(ToolSensitivity::Low) {
            if let Some(approval_manager) = &self.approval_manager {
                // ğŸ”§ P1-51: ä¼˜å…ˆæ£€æŸ¥æ•°æ®åº“ä¸­çš„æŒä¹…åŒ–å®¡æ‰¹è®¾ç½®
                let persisted_approval: Option<bool> = self.main_db.as_ref().and_then(|db| {
                    let setting_key =
                        approval_scope_setting_key(&tool_call.name, &tool_call.arguments);
                    db.get_setting(&setting_key)
                        .ok()
                        .flatten()
                        .map(|v| v == "allow")
                });

                // ä½¿ç”¨æŒä¹…åŒ–è®¾ç½®æˆ–å†…å­˜ç¼“å­˜
                let remembered = persisted_approval.or_else(|| {
                    approval_manager.check_remembered(&tool_call.name, &tool_call.arguments)
                });

                if let Some(is_allowed) = remembered {
                    log::info!(
                        "[ChatV2::pipeline] Tool {} approval remembered: {} (persisted={})",
                        tool_call.name,
                        is_allowed,
                        persisted_approval.is_some()
                    );
                    if !is_allowed {
                        // ç”¨æˆ·ä¹‹å‰é€‰æ‹©äº†"å§‹ç»ˆæ‹’ç»"
                        return Ok(ToolResultInfo {
                            tool_call_id: Some(tool_call.id.clone()),
                            block_id: Some(block_id),
                            tool_name: tool_call.name.clone(),
                            input: tool_call.arguments.clone(),
                            output: json!(null),
                            success: false,
                            error: Some("ç”¨æˆ·å·²æ‹’ç»æ­¤å·¥å…·æ‰§è¡Œ".to_string()),
                            duration_ms: None,
                            reasoning_content: None,
                        });
                    }
                    // ç”¨æˆ·ä¹‹å‰é€‰æ‹©äº†"å§‹ç»ˆå…è®¸"ï¼Œç»§ç»­æ‰§è¡Œ
                } else {
                    // éœ€è¦è¯·æ±‚ç”¨æˆ·å®¡æ‰¹
                    let actual_sensitivity = sensitivity.unwrap_or(ToolSensitivity::Medium);
                    let approval_outcome = self
                        .request_tool_approval(
                            tool_call,
                            emitter,
                            session_id,
                            message_id,
                            &block_id,
                            &actual_sensitivity,
                            approval_manager,
                        )
                        .await;

                    match approval_outcome {
                        ApprovalOutcome::Approved => {
                            // ç”¨æˆ·åŒæ„ï¼Œç»§ç»­æ‰§è¡Œ
                        }
                        ApprovalOutcome::Rejected => {
                            return Ok(ToolResultInfo {
                                tool_call_id: Some(tool_call.id.clone()),
                                block_id: Some(block_id),
                                tool_name: tool_call.name.clone(),
                                input: tool_call.arguments.clone(),
                                output: json!(null),
                                success: false,
                                error: Some("ç”¨æˆ·æ‹’ç»æ‰§è¡Œæ­¤å·¥å…·".to_string()),
                                duration_ms: None,
                                reasoning_content: None,
                            });
                        }
                        ApprovalOutcome::Timeout => {
                            return Ok(ToolResultInfo {
                                tool_call_id: Some(tool_call.id.clone()),
                                block_id: Some(block_id),
                                tool_name: tool_call.name.clone(),
                                input: tool_call.arguments.clone(),
                                output: json!(null),
                                success: false,
                                error: Some("å·¥å…·å®¡æ‰¹ç­‰å¾…è¶…æ—¶ï¼Œè¯·é‡è¯•".to_string()),
                                duration_ms: None,
                                reasoning_content: None,
                            });
                        }
                        ApprovalOutcome::ChannelClosed => {
                            return Ok(ToolResultInfo {
                                tool_call_id: Some(tool_call.id.clone()),
                                block_id: Some(block_id),
                                tool_name: tool_call.name.clone(),
                                input: tool_call.arguments.clone(),
                                output: json!(null),
                                success: false,
                                error: Some("å·¥å…·å®¡æ‰¹é€šé“å¼‚å¸¸å…³é—­ï¼Œè¯·é‡è¯•".to_string()),
                                duration_ms: None,
                                reasoning_content: None,
                            });
                        }
                    }
                }
            }
        }

        // ğŸ†• æ„å»ºæ‰§è¡Œä¸Šä¸‹æ–‡ï¼ˆæ–‡æ¡£ 29 P0-1ï¼‰
        let window = emitter.window();
        let mut ctx = ExecutionContext::new(
            session_id.to_string(),
            message_id.to_string(),
            block_id.clone(),
            emitter.clone(),
            self.tool_registry.clone(),
            window,
        )
        .with_canvas(canvas_note_id.clone(), self.notes_manager.clone())
        .with_main_db(self.main_db.clone())
        .with_anki_db(self.anki_db.clone())
        .with_vfs_db(self.vfs_db.clone()) // ğŸ†• å­¦ä¹ èµ„æºå·¥å…·éœ€è¦è®¿é—® VFS æ•°æ®åº“
        .with_llm_manager(Some(self.llm_manager.clone())) // ğŸ†• VFS RAG å·¥å…·éœ€è¦ LLM ç®¡ç†å™¨
        .with_chat_v2_db(Some(self.db.clone())) // ğŸ†• å·¥å…·å—é˜²é—ªé€€ä¿å­˜
        .with_question_bank_service(self.question_bank_service.clone()) // ğŸ†• æ™ºèƒ½é¢˜ç›®é›†å·¥å…·
        .with_pdf_processing_service(self.pdf_processing_service.clone()) // ğŸ†• è®ºæ–‡ä¿å­˜è§¦å‘ Pipeline
        .with_rag_config(rag_top_k, rag_enable_reranking);

        // ğŸ†• æ¸è¿›æŠ«éœ²ï¼šä¼ é€’ skill_contents
        ctx.skill_contents = skill_contents.clone();

        // ğŸ†• å–æ¶ˆæ”¯æŒï¼šä¼ é€’å–æ¶ˆä»¤ç‰Œ
        if let Some(token) = cancellation_token {
            ctx = ctx.with_cancellation_token(token);
        }

        // ğŸ†• å§”æ‰˜ç»™ ExecutorRegistry æ‰§è¡Œ
        match self.executor_registry.execute(tool_call, &ctx).await {
            Ok(result) => Ok(result),
            Err(error_msg) => {
                ctx.emitter
                    .emit_error(event_types::TOOL_CALL, &ctx.block_id, &error_msg, None);
                // æ‰§è¡Œå™¨å†…éƒ¨é”™è¯¯ï¼Œæ„é€ å¤±è´¥ç»“æœ
                log::error!(
                    "[ChatV2::pipeline] Executor error for tool {}: {}",
                    tool_call.name,
                    error_msg
                );
                Ok(ToolResultInfo {
                    tool_call_id: Some(tool_call.id.clone()),
                    block_id: Some(block_id),
                    tool_name: tool_call.name.clone(),
                    input: tool_call.arguments.clone(),
                    output: json!(null),
                    success: false,
                    error: Some(error_msg),
                    duration_ms: None,
                    reasoning_content: None,
                })
            }
        }
    }

    /// è¯·æ±‚ç”¨æˆ·å®¡æ‰¹æ•æ„Ÿå·¥å…·
    ///
    /// ğŸ†• æ–‡æ¡£ 29 P1-3ï¼šå‘å°„å®¡æ‰¹äº‹ä»¶å¹¶ç­‰å¾…ç”¨æˆ·å“åº”
    ///
    /// è¿”å› `ApprovalOutcome` ä»¥åŒºåˆ†ç”¨æˆ·åŒæ„ã€æ‹’ç»ã€è¶…æ—¶ã€é€šé“å¼‚å¸¸ç­‰æƒ…å†µã€‚
    async fn request_tool_approval(
        &self,
        tool_call: &ToolCall,
        emitter: &Arc<ChatV2EventEmitter>,
        session_id: &str,
        message_id: &str,
        block_id: &str,
        sensitivity: &ToolSensitivity,
        approval_manager: &Arc<ApprovalManager>,
    ) -> ApprovalOutcome {
        let timeout_seconds = approval_manager.default_timeout();
        let approval_block_id = format!("approval_{}", tool_call.id);

        // æ„å»ºå®¡æ‰¹è¯·æ±‚
        let request = ApprovalRequest {
            session_id: session_id.to_string(),
            tool_call_id: tool_call.id.clone(),
            tool_name: tool_call.name.clone(),
            arguments: tool_call.arguments.clone(),
            sensitivity: match sensitivity {
                ToolSensitivity::Low => "low".to_string(),
                ToolSensitivity::Medium => "medium".to_string(),
                ToolSensitivity::High => "high".to_string(),
            },
            description: ApprovalManager::generate_description(
                &tool_call.name,
                &tool_call.arguments,
            ),
            timeout_seconds,
        };

        // æ³¨å†Œç­‰å¾…
        let rx = approval_manager.register_with_scope(
            session_id,
            &tool_call.id,
            &tool_call.name,
            &tool_call.arguments,
        );

        // å‘å°„å®¡æ‰¹è¯·æ±‚äº‹ä»¶åˆ°å‰ç«¯
        log::info!(
            "[ChatV2::pipeline] Emitting tool approval request: tool={}, sensitivity={:?}",
            tool_call.name,
            sensitivity
        );
        let payload = serde_json::to_value(&request).ok();
        log::debug!(
            "[ChatV2::pipeline] tool approval block mapping: tool_block_id={}, approval_block_id={}",
            block_id,
            approval_block_id
        );
        emitter.emit_start(
            event_types::TOOL_APPROVAL_REQUEST,
            message_id,
            Some(&approval_block_id),
            payload,
            None, // variant_id
        );

        // ç­‰å¾…å“åº”æˆ–è¶…æ—¶
        let timeout_duration = std::time::Duration::from_secs(timeout_seconds as u64);
        match tokio::time::timeout(timeout_duration, rx).await {
            Ok(Ok(response)) => {
                log::info!(
                    "[ChatV2::pipeline] Received approval response: approved={}",
                    response.approved
                );
                let result_payload = serde_json::json!({
                    "toolCallId": tool_call.id,
                    "approved": response.approved,
                    "reason": response.reason,
                });
                emitter.emit_end(
                    event_types::TOOL_APPROVAL_REQUEST,
                    &approval_block_id,
                    Some(result_payload),
                    None,
                );
                if response.approved {
                    ApprovalOutcome::Approved
                } else {
                    ApprovalOutcome::Rejected
                }
            }
            Ok(Err(_)) => {
                // channel è¢«å…³é—­ï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼‰
                log::warn!("[ChatV2::pipeline] Approval channel closed unexpectedly");
                emitter.emit_error(
                    event_types::TOOL_APPROVAL_REQUEST,
                    &approval_block_id,
                    "approval_channel_closed",
                    None,
                );
                approval_manager.cancel_with_session(session_id, &tool_call.id);
                ApprovalOutcome::ChannelClosed
            }
            Err(_) => {
                // è¶…æ—¶
                log::warn!(
                    "[ChatV2::pipeline] Approval timeout for tool: {}",
                    tool_call.name
                );
                approval_manager.cancel_with_session(session_id, &tool_call.id);
                emitter.emit_error(
                    event_types::TOOL_APPROVAL_REQUEST,
                    &approval_block_id,
                    "approval_timeout",
                    None,
                );
                ApprovalOutcome::Timeout
            }
        }
    }

    // ========================================================================
    // Canvas å·¥å…·æ‰§è¡Œï¼ˆå·²åºŸå¼ƒ - ä¿ç•™ç”¨äºå‚è€ƒï¼‰
    // ========================================================================

    /// æ‰§è¡Œ Canvas ç¬”è®°å·¥å…·
    ///
    /// **å·²åºŸå¼ƒ**ï¼šæ­¤æ–¹æ³•å·²è¢« `CanvasToolExecutor` æ›¿ä»£ï¼ˆæ–‡æ¡£ 29 P0-1ï¼‰
    /// ä¿ç•™æ­¤ä»£ç ä»…ç”¨äºå‚è€ƒï¼Œå®é™…æ‰§è¡Œå·²å§”æ‰˜ç»™ `executor_registry`ã€‚
    ///
    /// Canvas å·¥å…·ä½¿ç”¨ NotesManager ç›´æ¥æ“ä½œç¬”è®°ï¼Œä¸èµ° ToolRegistryã€‚
    #[allow(dead_code)]
    ///
    /// ## å‚æ•°
    /// - `tool_call`: å·¥å…·è°ƒç”¨ä¿¡æ¯
    /// - `emitter`: äº‹ä»¶å‘å°„å™¨
    /// - `message_id`: æ¶ˆæ¯ ID
    /// - `block_id`: å— ID
    /// - `start_time`: å¼€å§‹æ—¶é—´
    /// - `canvas_note_id`: Canvas ç¬”è®° IDï¼Œç”¨äºé»˜è®¤å€¼
    async fn execute_canvas_tool(
        &self,
        tool_call: &ToolCall,
        emitter: &Arc<ChatV2EventEmitter>,
        _message_id: &str,
        block_id: &str,
        start_time: Instant,
        canvas_note_id: &Option<String>,
    ) -> ChatV2Result<ToolResultInfo> {
        use super::tools::canvas_tool_names;

        let notes_manager = match &self.notes_manager {
            Some(nm) => nm.clone(),
            None => {
                let error_msg = "Canvas å·¥å…·ä¸å¯ç”¨ï¼šNotesManager æœªåˆå§‹åŒ–";
                emitter.emit_error(event_types::TOOL_CALL, block_id, error_msg, None);
                log::error!("[ChatV2::pipeline] {}", error_msg);
                return Ok(ToolResultInfo {
                    tool_call_id: Some(tool_call.id.clone()),
                    block_id: Some(block_id.to_string()),
                    tool_name: tool_call.name.clone(),
                    input: tool_call.arguments.clone(),
                    output: json!(null),
                    success: false,
                    error: Some(error_msg.to_string()),
                    duration_ms: Some(start_time.elapsed().as_millis() as u64),
                    reasoning_content: None,
                });
            }
        };

        // è§£æå‚æ•°ï¼šä¼˜å…ˆä½¿ç”¨å·¥å…·å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨ canvas_note_id é»˜è®¤å€¼
        let args = &tool_call.arguments;
        let note_id = args
            .get("noteId")
            .or(args.get("note_id"))
            .and_then(|v| v.as_str())
            .map(|s| s.to_string())
            .or_else(|| canvas_note_id.clone())
            .unwrap_or_default();
        if note_id.is_empty() {
            let error_msg = "Canvas å·¥å…·ç¼ºå°‘å¿…éœ€å‚æ•°: noteIdï¼ˆè¯·ç¡®ä¿å·²é€‰æ‹©ç¬”è®°æˆ–åœ¨å·¥å…·å‚æ•°ä¸­æŒ‡å®šï¼‰";
            emitter.emit_error(event_types::TOOL_CALL, block_id, error_msg, None);
            return Ok(ToolResultInfo {
                tool_call_id: Some(tool_call.id.clone()),
                block_id: Some(block_id.to_string()),
                tool_name: tool_call.name.clone(),
                input: tool_call.arguments.clone(),
                output: json!(null),
                success: false,
                error: Some(error_msg.to_string()),
                duration_ms: Some(start_time.elapsed().as_millis() as u64),
                reasoning_content: None,
            });
        }

        // æ‰§è¡Œ Canvas å·¥å…·
        let tool_name = tool_call.name.clone();
        let nm = notes_manager.clone();
        let note_id_owned = note_id;
        let args_clone = args.clone();

        let result: Result<serde_json::Value, String> = tokio::task::spawn_blocking(move || {
            match tool_name.as_str() {
                canvas_tool_names::NOTE_READ => {
                    let section = args_clone.get("section").and_then(|v| v.as_str());
                    match nm.canvas_read_content(&note_id_owned, section) {
                        Ok(content) => Ok(json!({
                            "content": content,
                            "wordCount": content.chars().count(),
                            "isSection": section.is_some(),
                        })),
                        Err(e) => Err(e.to_string()),
                    }
                }
                canvas_tool_names::NOTE_APPEND => {
                    let content = args_clone
                        .get("content")
                        .and_then(|v| v.as_str())
                        .unwrap_or("");
                    let section = args_clone.get("section").and_then(|v| v.as_str());
                    // è¯»å–æ“ä½œå‰å†…å®¹ç”¨äº diff é¢„è§ˆ
                    let before_content = nm
                        .canvas_read_content(&note_id_owned, section)
                        .unwrap_or_default();
                    match nm.canvas_append_content(&note_id_owned, content, section) {
                        Ok(()) => {
                            // è¯»å–æ“ä½œåå†…å®¹
                            let after_content = nm
                                .canvas_read_content(&note_id_owned, section)
                                .unwrap_or_default();
                            Ok(json!({
                                "success": true,
                                "appendedCount": content.chars().count(),
                                "beforePreview": truncate_preview(&before_content, 500),
                                "afterPreview": truncate_preview(&after_content, 500),
                                "addedContent": truncate_preview(content, 300),
                            }))
                        }
                        Err(e) => Err(e.to_string()),
                    }
                }
                canvas_tool_names::NOTE_REPLACE => {
                    let search = args_clone
                        .get("search")
                        .and_then(|v| v.as_str())
                        .unwrap_or("");
                    let replace = args_clone
                        .get("replace")
                        .and_then(|v| v.as_str())
                        .unwrap_or("");
                    let is_regex = args_clone
                        .get("isRegex")
                        .and_then(|v| v.as_bool())
                        .unwrap_or(false);
                    // è¯»å–æ“ä½œå‰å†…å®¹ç”¨äº diff é¢„è§ˆ
                    let before_content = nm
                        .canvas_read_content(&note_id_owned, None)
                        .unwrap_or_default();
                    match nm.canvas_replace_content(&note_id_owned, search, replace, is_regex) {
                        Ok(count) => {
                            // è¯»å–æ“ä½œåå†…å®¹
                            let after_content = nm
                                .canvas_read_content(&note_id_owned, None)
                                .unwrap_or_default();
                            Ok(json!({
                                "success": true,
                                "replaceCount": count,
                                "beforePreview": truncate_preview(&before_content, 500),
                                "afterPreview": truncate_preview(&after_content, 500),
                                "searchPattern": search,
                                "replaceWith": replace,
                            }))
                        }
                        Err(e) => Err(e.to_string()),
                    }
                }
                canvas_tool_names::NOTE_SET => {
                    let content = args_clone
                        .get("content")
                        .and_then(|v| v.as_str())
                        .unwrap_or("");
                    // è¯»å–æ“ä½œå‰å†…å®¹ç”¨äº diff é¢„è§ˆ
                    let before_content = nm
                        .canvas_read_content(&note_id_owned, None)
                        .unwrap_or_default();
                    match nm.canvas_set_content(&note_id_owned, content) {
                        Ok(()) => Ok(json!({
                            "success": true,
                            "wordCount": content.chars().count(),
                            "beforePreview": truncate_preview(&before_content, 500),
                            "afterPreview": truncate_preview(content, 500),
                        })),
                        Err(e) => Err(e.to_string()),
                    }
                }
                _ => Err(format!("æœªçŸ¥çš„ Canvas å·¥å…·: {}", tool_name)),
            }
        })
        .await
        .map_err(|e| ChatV2Error::Tool(format!("Canvas å·¥å…·æ‰§è¡Œå¤±è´¥: {}", e)))?;

        let duration_ms = start_time.elapsed().as_millis() as u64;

        // åˆ¤æ–­æ˜¯å¦æ˜¯å†™å…¥æ“ä½œï¼ˆéœ€è¦é€šçŸ¥å‰ç«¯åˆ·æ–°ï¼‰
        let is_write_operation = matches!(
            tool_call.name.as_str(),
            canvas_tool_names::NOTE_APPEND
                | canvas_tool_names::NOTE_REPLACE
                | canvas_tool_names::NOTE_SET
        );

        match result {
            Ok(output) => {
                emitter.emit_end(
                    event_types::TOOL_CALL,
                    block_id,
                    Some(json!({
                        "result": output,
                        "durationMs": duration_ms,
                    })),
                    None,
                );

                // ğŸ”§ ä¿®å¤ï¼šå†™å…¥æ“ä½œæˆåŠŸåå‘é€äº‹ä»¶é€šçŸ¥å‰ç«¯åˆ·æ–°ç¬”è®°
                if is_write_operation {
                    let window = emitter.window();
                    let note_id_for_event = args
                        .get("noteId")
                        .or(args.get("note_id"))
                        .and_then(|v| v.as_str())
                        .map(|s| s.to_string())
                        .or_else(|| canvas_note_id.clone());

                    if let Some(nid) = note_id_for_event {
                        let _ = window.emit(
                            "canvas:note-updated",
                            json!({
                                "noteId": nid,
                                "toolName": tool_call.name,
                            }),
                        );
                        log::info!(
                            "[ChatV2::pipeline] Emitted canvas:note-updated for noteId={}",
                            nid
                        );
                    }
                }

                log::info!(
                    "[ChatV2::pipeline] Canvas tool {} completed successfully in {}ms",
                    tool_call.name,
                    duration_ms
                );

                Ok(ToolResultInfo {
                    tool_call_id: Some(tool_call.id.clone()),
                    block_id: Some(block_id.to_string()),
                    tool_name: tool_call.name.clone(),
                    input: tool_call.arguments.clone(),
                    output,
                    success: true,
                    error: None,
                    duration_ms: Some(duration_ms),
                    reasoning_content: None,
                })
            }
            Err(error_msg) => {
                emitter.emit_error(event_types::TOOL_CALL, block_id, &error_msg, None);

                log::warn!(
                    "[ChatV2::pipeline] Canvas tool {} failed: {} ({}ms)",
                    tool_call.name,
                    error_msg,
                    duration_ms
                );

                Ok(ToolResultInfo {
                    tool_call_id: Some(tool_call.id.clone()),
                    block_id: Some(block_id.to_string()),
                    tool_name: tool_call.name.clone(),
                    input: tool_call.arguments.clone(),
                    output: json!(null),
                    success: false,
                    error: Some(error_msg),
                    duration_ms: Some(duration_ms),
                    reasoning_content: None,
                })
            }
        }
    }

    // ========================================================================
    // Token ä¼°ç®—é€»è¾‘ï¼ˆPrompt 4ï¼‰
    // ========================================================================

    /// è·å–æˆ–ä¼°ç®—æœ¬è½® LLM è°ƒç”¨çš„ Token ä½¿ç”¨é‡
    ///
    /// ä¼˜å…ˆä½¿ç”¨ API è¿”å›çš„ usageï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä¼°ç®—ã€‚
    ///
    /// ## å‚æ•°
    /// - `adapter`: LLM é€‚é…å™¨ï¼ŒåŒ…å« API è¿”å›çš„ usage
    /// - `messages`: è¾“å…¥æ¶ˆæ¯åˆ—è¡¨
    /// - `completion_text`: è¾“å‡ºæ–‡æœ¬
    /// - `system_prompt`: ç³»ç»Ÿæç¤º
    /// - `model_id`: æ¨¡å‹ IDï¼ˆç”¨äºé€‰æ‹© tiktoken ç¼–ç å™¨ï¼‰
    ///
    /// ## è¿”å›
    /// TokenUsage ç»“æ„ä½“
    fn get_or_estimate_usage(
        &self,
        adapter: &ChatV2LLMAdapter,
        messages: &[LegacyChatMessage],
        completion_text: &str,
        system_prompt: &str,
        model_id: Option<&str>,
    ) -> TokenUsage {
        // 1. ä¼˜å…ˆä½¿ç”¨ API è¿”å›çš„ usage
        if let Some(api_usage) = adapter.get_api_usage() {
            log::debug!(
                "[ChatV2::pipeline] Using API usage: prompt={}, completion={}",
                api_usage.prompt_tokens,
                api_usage.completion_tokens
            );
            return api_usage;
        }

        // 2. API ä¸å¯ç”¨æ—¶ï¼Œä½¿ç”¨ä¼°ç®—
        log::debug!("[ChatV2::pipeline] API usage not available, using estimation");

        let prompt_tokens = self.estimate_prompt_tokens(messages, system_prompt, model_id);
        let completion_tokens = self.estimate_completion_tokens(completion_text, model_id);

        // åˆ¤æ–­æ˜¯å¦ä½¿ç”¨äº†ç²¾ç¡®ä¼°ç®—ï¼ˆtiktokenï¼‰
        #[cfg(feature = "tokenizer_tiktoken")]
        let precise = true;
        #[cfg(not(feature = "tokenizer_tiktoken"))]
        let precise = false;

        TokenUsage::from_estimate(prompt_tokens, completion_tokens, precise)
    }

    /// ä¼°ç®—è¾“å…¥ Token æ•°é‡
    ///
    /// å°† system_prompt + æ‰€æœ‰æ¶ˆæ¯çš„å†…å®¹æ‹¼æ¥åä¼°ç®— token æ•°é‡ã€‚
    ///
    /// ## å‚æ•°
    /// - `messages`: æ¶ˆæ¯åˆ—è¡¨
    /// - `system_prompt`: ç³»ç»Ÿæç¤º
    /// - `model_id`: æ¨¡å‹ IDï¼ˆç”¨äºé€‰æ‹© tiktoken ç¼–ç å™¨ï¼‰
    ///
    /// ## è¿”å›
    /// ä¼°ç®—çš„ prompt token æ•°é‡
    fn estimate_prompt_tokens(
        &self,
        messages: &[LegacyChatMessage],
        system_prompt: &str,
        model_id: Option<&str>,
    ) -> u32 {
        use crate::utils::token_budget::estimate_tokens_with_model;

        // æ„å»ºå®Œæ•´çš„ prompt æ–‡æœ¬
        let mut full_prompt = String::new();

        // æ·»åŠ ç³»ç»Ÿæç¤º
        if !system_prompt.is_empty() {
            full_prompt.push_str(system_prompt);
            full_prompt.push('\n');
        }

        // æ·»åŠ æ‰€æœ‰æ¶ˆæ¯å†…å®¹
        for msg in messages {
            // æ¶ˆæ¯è§’è‰²æ ‡è®°ï¼ˆç²—ç•¥ä¼°è®¡ 4 tokensï¼‰
            full_prompt.push_str(&msg.role);
            full_prompt.push_str(": ");
            full_prompt.push_str(&msg.content);
            full_prompt.push('\n');

            // å¦‚æœæœ‰ thinking å†…å®¹ä¹Ÿè®¡å…¥
            if let Some(ref thinking) = msg.thinking_content {
                full_prompt.push_str(thinking);
                full_prompt.push('\n');
            }

            // å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œè®¡å…¥å‚æ•°
            if let Some(ref tool_call) = msg.tool_call {
                full_prompt.push_str(&tool_call.args_json.to_string());
                full_prompt.push('\n');
            }

            // å¦‚æœæœ‰å·¥å…·ç»“æœï¼Œè®¡å…¥è¾“å‡º
            if let Some(ref tool_result) = msg.tool_result {
                if let Some(ref data) = tool_result.data_json {
                    full_prompt.push_str(&data.to_string());
                    full_prompt.push('\n');
                }
            }
        }

        // ä½¿ç”¨ token_budget æ¨¡å—çš„ä¼°ç®—å‡½æ•°
        let tokens = estimate_tokens_with_model(&full_prompt, model_id) as u32;

        // æ·»åŠ æ¶ˆæ¯æ ¼å¼å¼€é”€ï¼ˆæ¯æ¡æ¶ˆæ¯çº¦ 4 tokensï¼‰
        let message_overhead = (messages.len() as u32) * 4;

        tokens + message_overhead
    }

    /// ä¼°ç®—è¾“å‡º Token æ•°é‡
    ///
    /// ## å‚æ•°
    /// - `completion_text`: è¾“å‡ºæ–‡æœ¬
    /// - `model_id`: æ¨¡å‹ IDï¼ˆç”¨äºé€‰æ‹© tiktoken ç¼–ç å™¨ï¼‰
    ///
    /// ## è¿”å›
    /// ä¼°ç®—çš„ completion token æ•°é‡
    fn estimate_completion_tokens(&self, completion_text: &str, model_id: Option<&str>) -> u32 {
        use crate::utils::token_budget::estimate_tokens_with_model;

        if completion_text.is_empty() {
            return 0;
        }

        estimate_tokens_with_model(completion_text, model_id) as u32
    }

    // ========================================================================
    // ç»Ÿä¸€ä¸Šä¸‹æ–‡æ³¨å…¥ç³»ç»Ÿæ–¹æ³•
    // ========================================================================

    /// åˆ›å»ºæ£€ç´¢èµ„æº
    ///
    /// å°†æ£€ç´¢ç»“æœè½¬æ¢ä¸ºèµ„æºå¼•ç”¨ï¼Œè°ƒç”¨ ResourceRepo åˆ›å»ºå®é™…èµ„æºã€‚
    /// ç»Ÿä¸€æ¶æ„ä¿®å¤ï¼ˆ2025-12-06ï¼‰ï¼šä½¿ç”¨ resources.db è€Œé chat_v2.db
    ///
    /// ## çº¦æŸï¼ˆæ¥è‡ªæ–‡æ¡£ 17ï¼‰
    /// - æ£€ç´¢ç»“æœåˆ›å»ºèµ„æºå¹¶å¡«å…… retrievalRefs
    /// - ä½¿ç”¨å†…å®¹å“ˆå¸Œå»é‡
    ///
    /// ## å‚æ•°
    /// - `sources`: æ£€ç´¢åˆ°çš„æ¶ˆæ¯æ¥æº
    ///
    /// ## è¿”å›
    /// æ£€ç´¢èµ„æºçš„ ContextRef åˆ—è¡¨
    async fn create_retrieval_resources(&self, sources: &MessageSources) -> Vec<ContextRef> {
        use crate::vfs::types::{VfsResourceMetadata, VfsResourceType};

        let mut refs = Vec::new();

        // ğŸ†• è·å– VFS æ•°æ®åº“è¿æ¥
        let vfs_db = match &self.vfs_db {
            Some(db) => db,
            None => {
                log::warn!(
                    "[ChatV2::pipeline] vfs_db not available, skipping retrieval resource creation"
                );
                return refs;
            }
        };

        let conn = match vfs_db.get_conn_safe() {
            Ok(conn) => conn,
            Err(e) => {
                log::error!("[ChatV2::pipeline] Failed to get vfs.db connection: {}", e);
                return refs;
            }
        };

        // è¾…åŠ©å®ï¼šå¤„ç†å•ä¸ªæ¥æºåˆ—è¡¨
        macro_rules! process_sources {
            ($source_list:expr, $source_type:expr) => {
                if let Some(ref source_list) = $source_list {
                    for (idx, source) in source_list.iter().enumerate() {
                        // æ„å»ºå†…å®¹ç”¨äºå­˜å‚¨ï¼ˆJSON æ ¼å¼ï¼‰
                        let content = serde_json::json!({
                            "source_type": $source_type,
                            "title": source.title,
                            "snippet": source.snippet,
                            "url": source.url,
                        }).to_string();

                        // æ„å»ºå…ƒæ•°æ®ï¼ˆä½¿ç”¨ VFS çš„ç±»å‹ï¼‰
                        let metadata = VfsResourceMetadata {
                            title: source.title.clone(),
                            source: Some($source_type.to_string()),
                            ..Default::default()
                        };

                        // ğŸ†• è°ƒç”¨ VfsResourceRepo åˆ›å»ºæˆ–å¤ç”¨èµ„æºï¼ˆå†™å…¥ vfs.dbï¼‰
                        match VfsResourceRepo::create_or_reuse_with_conn(
                            &conn,
                            VfsResourceType::Retrieval,
                            &content,
                            source.url.as_deref(), // source_id: ä½¿ç”¨ URL
                            None, // source_table
                            Some(&metadata),
                        ) {
                            Ok(result) => {
                                refs.push(ContextRef::new(
                                    result.resource_id.clone(),
                                    result.hash.clone(),
                                    format!("retrieval_{}", $source_type),
                                ));

                                log::trace!(
                                    "[ChatV2::pipeline] Created retrieval resource in vfs.db: type={}, idx={}, id={}, is_new={}",
                                    $source_type,
                                    idx,
                                    result.resource_id,
                                    result.is_new
                                );
                            }
                            Err(e) => {
                                log::warn!(
                                    "[ChatV2::pipeline] Failed to create retrieval resource: type={}, idx={}, error={}",
                                    $source_type,
                                    idx,
                                    e
                                );
                            }
                        }
                    }
                }
            };
        }

        // å¤„ç†å„ç±»æ£€ç´¢æ¥æº
        process_sources!(sources.rag, "rag");
        process_sources!(sources.memory, "memory");
        process_sources!(sources.graph, "graph");
        process_sources!(sources.web_search, "web");

        log::debug!(
            "[ChatV2::pipeline] Created {} retrieval resources in vfs.db",
            refs.len()
        );

        refs
    }

    /// å¢åŠ èµ„æºå¼•ç”¨è®¡æ•°
    ///
    /// æ¶ˆæ¯ä¿å­˜åè°ƒç”¨ï¼Œå¢åŠ æ‰€æœ‰å…³è”èµ„æºçš„å¼•ç”¨è®¡æ•°ã€‚
    /// ğŸ†• VFS ç»Ÿä¸€å­˜å‚¨ï¼ˆ2025-12-07ï¼‰ï¼šä½¿ç”¨ vfs.db
    ///
    /// ## çº¦æŸï¼ˆæ¥è‡ªæ–‡æ¡£ 17ï¼‰
    /// - æ¶ˆæ¯ä¿å­˜åè°ƒç”¨ incrementRef
    async fn increment_resource_refs(&self, resource_ids: &[&str]) {
        if resource_ids.is_empty() {
            return;
        }

        // ğŸ†• è·å– VFS æ•°æ®åº“è¿æ¥
        let vfs_db = match &self.vfs_db {
            Some(db) => db,
            None => {
                log::warn!(
                    "[ChatV2::pipeline] vfs_db not available, skipping increment_resource_refs"
                );
                return;
            }
        };

        let conn = match vfs_db.get_conn_safe() {
            Ok(conn) => conn,
            Err(e) => {
                log::error!("[ChatV2::pipeline] Failed to get vfs.db connection for increment_resource_refs: {}", e);
                return;
            }
        };

        // éå†æ‰€æœ‰èµ„æº IDï¼Œè°ƒç”¨ VfsResourceRepo å¢åŠ å¼•ç”¨è®¡æ•°
        for id in resource_ids {
            if let Err(e) = VfsResourceRepo::increment_ref_with_conn(&conn, id) {
                // å¼•ç”¨è®¡æ•°å¤±è´¥ä¸é˜»å¡æµç¨‹ï¼Œä»…è®°å½•è­¦å‘Š
                log::warn!(
                    "[ChatV2::pipeline] Failed to increment ref for resource {}: {}",
                    id,
                    e
                );
            }
        }

        log::debug!(
            "[ChatV2::pipeline] Incremented refs for {} resources in vfs.db: {:?}",
            resource_ids.len(),
            resource_ids.iter().take(3).collect::<Vec<_>>()
        );
    }

    /// å‡å°‘èµ„æºå¼•ç”¨è®¡æ•°
    ///
    /// æ¶ˆæ¯åˆ é™¤æ—¶è°ƒç”¨ï¼Œå‡å°‘æ‰€æœ‰å…³è”èµ„æºçš„å¼•ç”¨è®¡æ•°ã€‚
    /// ğŸ†• VFS ç»Ÿä¸€å­˜å‚¨ï¼ˆ2025-12-07ï¼‰ï¼šä½¿ç”¨ vfs.db
    ///
    /// ## çº¦æŸï¼ˆæ¥è‡ªæ–‡æ¡£ 17ï¼‰
    /// - æ¶ˆæ¯åˆ é™¤æ—¶è°ƒç”¨ decrementRef
    #[allow(dead_code)]
    async fn decrement_resource_refs(&self, resource_ids: &[&str]) {
        if resource_ids.is_empty() {
            return;
        }

        // ğŸ†• è·å– VFS æ•°æ®åº“è¿æ¥
        let vfs_db = match &self.vfs_db {
            Some(db) => db,
            None => {
                log::warn!(
                    "[ChatV2::pipeline] vfs_db not available, skipping decrement_resource_refs"
                );
                return;
            }
        };

        let conn = match vfs_db.get_conn_safe() {
            Ok(conn) => conn,
            Err(e) => {
                log::error!("[ChatV2::pipeline] Failed to get vfs.db connection for decrement_resource_refs: {}", e);
                return;
            }
        };

        // éå†æ‰€æœ‰èµ„æº IDï¼Œè°ƒç”¨ VfsResourceRepo å‡å°‘å¼•ç”¨è®¡æ•°
        for id in resource_ids {
            if let Err(e) = VfsResourceRepo::decrement_ref_with_conn(&conn, id) {
                // å¼•ç”¨è®¡æ•°å¤±è´¥ä¸é˜»å¡æµç¨‹ï¼Œä»…è®°å½•è­¦å‘Š
                log::warn!(
                    "[ChatV2::pipeline] Failed to decrement ref for resource {}: {}",
                    id,
                    e
                );
            }
        }

        log::debug!(
            "[ChatV2::pipeline] Decremented refs for {} resources in vfs.db: {:?}",
            resource_ids.len(),
            resource_ids.iter().take(3).collect::<Vec<_>>()
        );
    }

    /// ğŸ†• P0é˜²é—ªé€€ï¼šç”¨æˆ·æ¶ˆæ¯å³æ—¶ä¿å­˜
    ///
    /// åœ¨ Pipeline æ‰§è¡Œå‰ç«‹å³ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼Œç¡®ä¿ç”¨æˆ·è¾“å…¥ä¸ä¼šå› é—ªé€€ä¸¢å¤±ã€‚
    /// ä½¿ç”¨ INSERT OR REPLACE è¯­ä¹‰ï¼Œä¸ save_results å…¼å®¹ï¼ˆä¸ä¼šé‡å¤æ’å…¥ï¼‰ã€‚
    ///
    /// ## è°ƒç”¨æ—¶æœº
    /// åœ¨ execute() ä¸­ï¼Œemit_stream_start ä¹‹åã€execute_internal ä¹‹å‰è°ƒç”¨ã€‚
    ///
    /// ## ä¸ save_results çš„å…³ç³»
    /// - æœ¬æ–¹æ³•å…ˆä¿å­˜ç”¨æˆ·æ¶ˆæ¯
    /// - save_results ä½¿ç”¨ INSERT OR REPLACEï¼Œä¼šè¦†ç›–æœ¬æ–¹æ³•ä¿å­˜çš„æ•°æ®
    /// - å¦‚æœ Pipeline æ­£å¸¸å®Œæˆï¼Œsave_results ä¼šä¿å­˜å®Œæ•´æ•°æ®
    /// - å¦‚æœé—ªé€€ï¼Œè‡³å°‘ç”¨æˆ·æ¶ˆæ¯å·²ä¿å­˜
    async fn save_user_message_immediately(&self, ctx: &PipelineContext) -> ChatV2Result<()> {
        let conn = self.db.get_conn_safe()?;
        let now_ms = chrono::Utc::now().timestamp_millis();

        // ä½¿ç”¨ç»Ÿä¸€çš„ç”¨æˆ·æ¶ˆæ¯æ„å»ºå™¨
        let user_msg_params =
            UserMessageParams::new(ctx.session_id.clone(), ctx.user_content.clone())
                .with_id(ctx.user_message_id.clone())
                .with_attachments(ctx.attachments.clone())
                .with_context_snapshot(ctx.context_snapshot.clone())
                .with_timestamp(now_ms);

        let user_msg_result = build_user_message(user_msg_params);

        // ä½¿ç”¨ INSERT OR REPLACE ä¿å­˜ï¼ˆä¸ save_results å…¼å®¹ï¼‰
        ChatV2Repo::create_message_with_conn(&conn, &user_msg_result.message)?;
        ChatV2Repo::create_block_with_conn(&conn, &user_msg_result.block)?;

        Ok(())
    }

    /// ğŸ†• P15 ä¿®å¤ï¼šä¸­é—´ä¿å­˜ç‚¹
    ///
    /// åœ¨å·¥å…·æ‰§è¡Œåä¿å­˜å½“å‰å·²ç”Ÿæˆçš„æ‰€æœ‰å—ï¼Œç¡®ä¿ï¼š
    /// 1. ç”¨æˆ·åˆ·æ–°é¡µé¢æ—¶ä¸ä¼šä¸¢å¤±å·²æ‰§è¡Œçš„å·¥å…·ç»“æœ
    /// 2. é˜»å¡æ“ä½œï¼ˆå¦‚ coordinator_sleepï¼‰æœŸé—´æ•°æ®å·²æŒä¹…åŒ–
    ///
    /// ## ä¸ save_results çš„å…³ç³»
    /// - æœ¬æ–¹æ³•åœ¨æµç¨‹ä¸­é—´è°ƒç”¨ï¼Œä¿å­˜éƒ¨åˆ†ç»“æœ
    /// - save_results åœ¨æµç¨‹ç»“æŸæ—¶è°ƒç”¨ï¼Œä¿å­˜å®Œæ•´ç»“æœ
    /// - ä¸¤è€…éƒ½ä½¿ç”¨ INSERT OR REPLACEï¼Œä¸ä¼šå†²çª
    async fn save_intermediate_results(&self, ctx: &PipelineContext) -> ChatV2Result<()> {
        // å¦‚æœæ²¡æœ‰å—éœ€è¦ä¿å­˜ï¼Œç›´æ¥è¿”å›
        if ctx.interleaved_blocks.is_empty() {
            return Ok(());
        }

        let conn = self.db.get_conn_safe()?;
        let now_ms = chrono::Utc::now().timestamp_millis();

        // ğŸ”§ P23 ä¿®å¤ï¼šä¸­é—´ä¿å­˜ä¹Ÿè¦ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        // å¦åˆ™åˆ·æ–°åå­ä»£ç†ä¼šè¯åªæœ‰åŠ©æ‰‹æ¶ˆæ¯ï¼Œæ²¡æœ‰ç”¨æˆ·æ¶ˆæ¯ï¼ˆä»»åŠ¡å†…å®¹ï¼‰
        // æ£€æŸ¥æ˜¯å¦è·³è¿‡ç”¨æˆ·æ¶ˆæ¯ä¿å­˜ï¼ˆç¼–è¾‘é‡å‘åœºæ™¯ï¼‰
        let skip_user_message = ctx.options.skip_user_message_save.unwrap_or(false);
        if !skip_user_message {
            let user_msg_params =
                UserMessageParams::new(ctx.session_id.clone(), ctx.user_content.clone())
                    .with_id(ctx.user_message_id.clone())
                    .with_attachments(ctx.attachments.clone())
                    .with_context_snapshot(ctx.context_snapshot.clone())
                    .with_timestamp(now_ms);

            let user_msg_result = build_user_message(user_msg_params);

            // ä½¿ç”¨ INSERT OR REPLACE ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼ˆä¸ save_results å…¼å®¹ï¼‰
            ChatV2Repo::create_message_with_conn(&conn, &user_msg_result.message)?;
            ChatV2Repo::create_block_with_conn(&conn, &user_msg_result.block)?;
        }

        // 1. ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯ï¼ˆå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºï¼‰
        // ğŸ”§ Preserve `anki_cards` blocks created outside of `ctx.interleaved_blocks`.
        //
        // `ChatV2Repo::create_message_with_conn` uses SQLite `INSERT OR REPLACE`, which is a
        // DELETE+INSERT under the hood. With `chat_v2_blocks.message_id ON DELETE CASCADE`,
        // replacing the assistant message row will delete *all* existing blocks (including
        // ChatAnki-generated `anki_cards` blocks). We query + re-insert them best-effort.
        let preserved_anki_cards_blocks: Vec<MessageBlock> =
            ChatV2Repo::get_message_blocks_with_conn(&conn, &ctx.assistant_message_id)?
                .into_iter()
                .filter(|b| b.block_type == block_types::ANKI_CARDS)
                .collect();

        let interleaved_block_ids: Vec<String> = ctx
            .interleaved_blocks
            .iter()
            .map(|b| b.id.clone())
            .collect();

        // ğŸ”§ ä¿®å¤ï¼šæŒ‰åŸå§‹ block_index åˆå¹¶ anki_cards å—ï¼Œä¿æŒå…¶åŸå§‹ä½ç½®
        // è€Œä¸æ˜¯è¿½åŠ åˆ°æœ«å°¾å¯¼è‡´åˆ·æ–°åä½ç½®å˜åŒ–
        let block_ids: Vec<String> = {
            let interleaved_id_set: std::collections::HashSet<&str> =
                interleaved_block_ids.iter().map(|s| s.as_str()).collect();

            // æ”¶é›†éœ€è¦æ’å…¥çš„ anki_cards å—åŠå…¶åŸå§‹ä½ç½®
            let mut anki_inserts: Vec<(u32, String)> = preserved_anki_cards_blocks
                .iter()
                .filter(|b| !interleaved_id_set.contains(b.id.as_str()))
                .map(|b| (b.block_index, b.id.clone()))
                .collect();
            anki_inserts.sort_by_key(|(idx, _)| *idx);

            // åˆå¹¶ï¼šå°† interleaved å—æŒ‰é¡ºåºç¼–å· (0,1,2,...)ï¼Œ
            // å°† anki_cards å—æŒ‰å…¶åŸå§‹ block_index æ’å…¥å¯¹åº”ä½ç½®
            let mut indexed: Vec<(u32, String)> = interleaved_block_ids
                .iter()
                .enumerate()
                .map(|(i, id)| (i as u32, id.clone()))
                .collect();

            for (orig_idx, id) in &anki_inserts {
                indexed.push((*orig_idx, id.clone()));
            }

            // ç¨³å®šæ’åºï¼šç›¸åŒ block_index æ—¶ä¿æŒåŸæœ‰é¡ºåº
            indexed.sort_by_key(|(idx, _)| *idx);

            // å»é‡
            let mut seen = std::collections::HashSet::<String>::new();
            indexed
                .into_iter()
                .filter_map(|(_, id)| {
                    if seen.insert(id.clone()) {
                        Some(id)
                    } else {
                        None
                    }
                })
                .collect()
        };
        let assistant_msg = ChatMessage {
            id: ctx.assistant_message_id.clone(),
            session_id: ctx.session_id.clone(),
            role: MessageRole::Assistant,
            block_ids: block_ids.clone(),
            timestamp: now_ms,
            persistent_stable_id: None,
            parent_id: None,
            supersedes: None,
            meta: None,
            attachments: None,
            active_variant_id: None,
            variants: None,
            shared_context: None,
        };
        ChatV2Repo::create_message_with_conn(&conn, &assistant_msg)?;

        // 2. ä¿å­˜æ‰€æœ‰å·²ç”Ÿæˆçš„å—
        for (index, block) in ctx.interleaved_blocks.iter().enumerate() {
            let mut block_to_save = block.clone();
            block_to_save.block_index = index as u32;
            ChatV2Repo::create_block_with_conn(&conn, &block_to_save)?;
        }

        // 3. Re-insert preserved `anki_cards` blocks deleted by the assistant message REPLACE.
        //    ğŸ”§ ä¿®å¤ï¼šä¿æŒ anki_cards å—çš„åŸå§‹ block_indexï¼Œä¸å†è¿½åŠ åˆ°æœ«å°¾
        if !preserved_anki_cards_blocks.is_empty() {
            let interleaved_block_id_set: std::collections::HashSet<&str> = ctx
                .interleaved_blocks
                .iter()
                .map(|b| b.id.as_str())
                .collect();

            for preserved in preserved_anki_cards_blocks {
                // If the pipeline already has the same block id, prefer the pipeline version.
                if interleaved_block_id_set.contains(preserved.id.as_str()) {
                    continue;
                }

                // ä¿æŒåŸå§‹ block_index ä¸å˜ï¼Œè¿™æ ·åˆ·æ–°åä½ç½®ä¸ä¼šè·³åˆ°æœ«å°¾
                let block_to_save = preserved;

                if let Err(e) = ChatV2Repo::create_block_with_conn(&conn, &block_to_save) {
                    log::error!(
                        "[ChatV2::pipeline] Failed to re-insert preserved anki_cards block: message_id={}, block_id={}, err={:?}",
                        ctx.assistant_message_id,
                        block_to_save.id,
                        e
                    );
                }
            }
        }

        log::debug!(
            "[ChatV2::pipeline] Intermediate save: message_id={}, blocks={}, user_saved={}",
            ctx.assistant_message_id,
            ctx.interleaved_blocks.len(),
            !skip_user_message
        );

        Ok(())
    }

    /// ä¿å­˜ç»“æœåˆ°æ•°æ®åº“
    ///
    /// ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ã€åŠ©æ‰‹æ¶ˆæ¯åŠå…¶æ‰€æœ‰å—åˆ°æ•°æ®åº“ã€‚
    /// å—çš„ block_index æŒ‰ç”Ÿæˆé¡ºåºè®¾ç½®ã€‚
    ///
    /// ## skip_user_message_save é€‰é¡¹
    /// å½“ `ctx.options.skip_user_message_save` ä¸º true æ—¶ï¼Œè·³è¿‡ç”¨æˆ·æ¶ˆæ¯çš„åˆ›å»ºã€‚
    /// ç”¨äºç¼–è¾‘é‡å‘åœºæ™¯ï¼šç”¨æˆ·æ¶ˆæ¯å·²åœ¨ Handler ä¸­æ›´æ–°ï¼Œæ— éœ€ Pipeline é‡å¤åˆ›å»ºã€‚
    async fn save_results(&self, ctx: &PipelineContext) -> ChatV2Result<()> {
        log::debug!(
            "[ChatV2::pipeline] Saving results for session={}",
            ctx.session_id
        );

        // è·å–æ•°æ®åº“è¿æ¥
        let conn = self.db.get_conn_safe()?;

        // ğŸ†• P1ä¿®å¤ï¼šä½¿ç”¨æ˜¾å¼äº‹åŠ¡åŒ…è£¹æ‰€æœ‰æ•°æ®åº“æ“ä½œï¼Œç¡®ä¿åŸå­æ€§
        // ä½¿ç”¨ BEGIN IMMEDIATE é¿å…å†™é”ç­‰å¾…ï¼ˆä¸ VFS repos ä¿æŒä¸€è‡´ï¼‰
        conn.execute("BEGIN IMMEDIATE", []).map_err(|e| {
            log::error!(
                "[ChatV2::pipeline] Failed to begin transaction for save_results: {}",
                e
            );
            ChatV2Error::Database(format!("Failed to begin transaction: {}", e))
        })?;

        let save_result = self.save_results_inner(&conn, ctx);

        match save_result {
            Ok(()) => {
                conn.execute("COMMIT", []).map_err(|e| {
                    log::error!("[ChatV2::pipeline] Failed to commit transaction: {}", e);
                    ChatV2Error::Database(format!("Failed to commit transaction: {}", e))
                })?;
                log::debug!(
                    "[ChatV2::pipeline] Transaction committed for session={}",
                    ctx.session_id
                );

                // äº‹åŠ¡æäº¤æˆåŠŸåæ‰§è¡Œåå¤„ç†æ“ä½œ
                self.save_results_post_commit(ctx).await;

                Ok(())
            }
            Err(e) => {
                // å›æ»šäº‹åŠ¡
                if let Err(rollback_err) = conn.execute("ROLLBACK", []) {
                    log::error!(
                        "[ChatV2::pipeline] Failed to rollback transaction: {} (original error: {:?})",
                        rollback_err,
                        e
                    );
                } else {
                    log::warn!(
                        "[ChatV2::pipeline] Transaction rolled back for session={}: {:?}",
                        ctx.session_id,
                        e
                    );
                }
                Err(e)
            }
        }
    }

    /// ä¿å­˜ç»“æœçš„å†…éƒ¨å®ç°ï¼ˆåœ¨äº‹åŠ¡å†…æ‰§è¡Œï¼‰
    ///
    /// æ­¤æ–¹æ³•åŒ…å«æ‰€æœ‰å®é™…çš„æ•°æ®åº“æ“ä½œï¼Œç”± `save_results` åœ¨äº‹åŠ¡å†…è°ƒç”¨ã€‚
    /// æ³¨æ„ï¼šæ­¤æ–¹æ³•æ˜¯åŒæ­¥çš„ï¼Œå› ä¸º SQLite æ“ä½œæœ¬èº«æ˜¯åŒæ­¥çš„ï¼Œ
    /// ä¸” PooledConnection ä¸æ˜¯ Syncï¼Œæ— æ³•è·¨ await ç‚¹ä¼ é€’å¼•ç”¨ã€‚
    fn save_results_inner(
        &self,
        conn: &crate::chat_v2::database::ChatV2PooledConnection,
        ctx: &PipelineContext,
    ) -> ChatV2Result<()> {
        // æ£€æŸ¥æ˜¯å¦è·³è¿‡ç”¨æˆ·æ¶ˆæ¯ä¿å­˜ï¼ˆç¼–è¾‘é‡å‘åœºæ™¯ï¼‰
        let skip_user_message = ctx.options.skip_user_message_save.unwrap_or(false);

        // === 1. åˆ›å»ºå¹¶ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼ˆé™¤é skip_user_message_save ä¸º trueï¼‰===
        // ğŸ†• ä½¿ç”¨ç»Ÿä¸€çš„ç”¨æˆ·æ¶ˆæ¯æ„å»ºå™¨ï¼Œç¡®ä¿æ‰€æœ‰è·¯å¾„çš„ä¸€è‡´æ€§
        if !skip_user_message {
            let user_now_ms = chrono::Utc::now().timestamp_millis();
            let user_msg_params =
                UserMessageParams::new(ctx.session_id.clone(), ctx.user_content.clone())
                    .with_id(ctx.user_message_id.clone())
                    .with_attachments(ctx.attachments.clone())
                    .with_context_snapshot(ctx.context_snapshot.clone())
                    .with_timestamp(user_now_ms);

            let user_msg_result = build_user_message(user_msg_params);

            // ä¿å­˜ç”¨æˆ·æ¶ˆæ¯å’Œå—
            ChatV2Repo::create_message_with_conn(&conn, &user_msg_result.message)?;
            ChatV2Repo::create_block_with_conn(&conn, &user_msg_result.block)?;

            log::debug!(
                "[ChatV2::pipeline] Saved user message: id={}, content_len={}",
                ctx.user_message_id,
                ctx.user_content.len()
            );
        } else {
            log::debug!(
                "[ChatV2::pipeline] Skipped user message save (skip_user_message_save=true): id={}",
                ctx.user_message_id
            );
        }

        // === 2. åˆ›å»ºå¹¶ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯ ===
        //
        // å—ä¿å­˜é€»è¾‘ä¼˜å…ˆçº§ï¼š
        // 1. interleaved_blocksï¼ˆInterleaved Thinking æ¨¡å¼ï¼Œæ”¯æŒ thinkingâ†’toolâ†’thinkingâ†’content äº¤æ›¿ï¼‰
        // 2. generated_blocksï¼ˆæ—§é€»è¾‘ï¼Œå…¼å®¹æ€§ä¿ç•™ï¼Œç›®å‰æœªä½¿ç”¨ï¼‰
        // 3. æ‰‹åŠ¨åˆ›å»º thinking/content å—ï¼ˆæ— å·¥å…·è°ƒç”¨çš„ç®€å•åœºæ™¯ï¼‰
        //
        // ğŸ”§ å—é¡ºåºä¿®å¤ï¼šæ£€ç´¢å—æ’å…¥åœ¨ thinking ä¹‹åã€content ä¹‹å‰
        // æ­£ç¡®é¡ºåºï¼šthinking â†’ retrieval â†’ contentï¼ˆä¸å‰ç«¯æµå¼æ¸²æŸ“ä¸€è‡´ï¼‰

        let assistant_now_ms = chrono::Utc::now().timestamp_millis();
        let elapsed_ms = ctx.elapsed_ms() as i64;
        let mut block_ids: Vec<String> = Vec::new();
        let mut blocks: Vec<MessageBlock> = Vec::new();
        let mut block_index = 0u32;

        // ============================================================
        // è¾…åŠ©å®ï¼šåˆ›å»ºæ£€ç´¢å—ï¼Œä½¿ç”¨æµå¼è¿‡ç¨‹ä¸­åˆ›å»ºçš„å— ID
        // ğŸ”§ ä¿®å¤ï¼šæ£€ç´¢å—åº”è¯¥åœ¨ thinking ä¹‹åã€content ä¹‹å‰æ·»åŠ 
        // ============================================================
        macro_rules! add_retrieval_block {
            ($block_ids:expr, $blocks:expr, $block_index:expr, $sources:expr, $block_type:expr) => {
                if let Some(ref sources) = $sources {
                    if !sources.is_empty() {
                        let retrieval_block_id = ctx.streaming_retrieval_block_ids
                            .get(&$block_type.to_string())
                            .cloned()
                            .unwrap_or_else(|| MessageBlock::generate_id());
                        let started_at = assistant_now_ms - elapsed_ms;
                        let block = MessageBlock {
                            id: retrieval_block_id,
                            message_id: ctx.assistant_message_id.clone(),
                            block_type: $block_type.to_string(),
                            status: block_status::SUCCESS.to_string(),
                            content: None,
                            tool_name: None,
                            tool_input: None,
                            tool_output: Some(json!({ "sources": sources })),
                            citations: None,
                            error: None,
                            started_at: Some(started_at),
                            ended_at: Some(assistant_now_ms),
                            // ğŸ”§ æ£€ç´¢å—ä½¿ç”¨ started_at ä½œä¸ºæ’åºä¾æ®
                            first_chunk_at: Some(started_at),
                            block_index: $block_index,
                        };
                        $block_ids.push(block.id.clone());
                        $blocks.push(block);
                        $block_index += 1;
                    }
                }
            };
        }

        // ============================================================
        // ä¼˜å…ˆçº§ 1: Interleaved Thinking æ¨¡å¼ï¼ˆå¤šè½®å·¥å…·è°ƒç”¨ï¼‰
        // ğŸ”§ P3ä¿®å¤ï¼šä¿æŒåŸå§‹äº¤æ›¿é¡ºåºï¼ä¸è¦åˆ†ç¦» thinking å—
        // æ­£ç¡®é¡ºåºï¼šretrieval â†’ thinking â†’ tool â†’ thinking â†’ tool â†’ ...
        // ============================================================
        if ctx.has_interleaved_blocks() {
            log::info!(
                "[ChatV2::pipeline] Using interleaved blocks for save: count={}",
                ctx.interleaved_block_ids.len()
            );

            // ğŸ”§ P3ä¿®å¤ï¼šå…ˆæ·»åŠ æ£€ç´¢å—ï¼ˆæ£€ç´¢åœ¨ LLM è°ƒç”¨ä¹‹å‰å®Œæˆï¼‰
            add_retrieval_block!(
                block_ids,
                blocks,
                block_index,
                ctx.retrieved_sources.rag,
                block_types::RAG
            );
            add_retrieval_block!(
                block_ids,
                blocks,
                block_index,
                ctx.retrieved_sources.memory,
                block_types::MEMORY
            );
            add_retrieval_block!(
                block_ids,
                blocks,
                block_index,
                ctx.retrieved_sources.web_search,
                block_types::WEB_SEARCH
            );

            // ğŸ”§ P3ä¿®å¤ï¼šä¿æŒ interleaved_blocks çš„åŸå§‹äº¤æ›¿é¡ºåº
            // ä¸å†åˆ†ç¦» thinking å—ï¼Œç›´æ¥æŒ‰åŸé¡ºåºæ·»åŠ 
            for mut block in ctx.interleaved_blocks.iter().cloned() {
                block.block_index = block_index;
                block_ids.push(block.id.clone());
                blocks.push(block);
                block_index += 1;
            }
        }
        // ============================================================
        // ä¼˜å…ˆçº§ 2: æ—§çš„ generated_blocks é€»è¾‘ï¼ˆå…¼å®¹æ€§ä¿ç•™ï¼Œç›®å‰æœªä½¿ç”¨ï¼‰
        // æ³¨æ„ï¼šgenerated_blocks å½“å‰å§‹ç»ˆä¸ºç©ºï¼Œæ­¤åˆ†æ”¯ä¿ç•™ç”¨äºæœªæ¥å…¼å®¹
        // ============================================================
        else {
            let assistant_block_ids: Vec<String> =
                ctx.generated_blocks.iter().map(|b| b.id.clone()).collect();

            if !assistant_block_ids.is_empty() {
                // åˆ†ç¦» thinking å—å’Œå…¶ä»–å—
                let thinking_blocks: Vec<_> = ctx
                    .generated_blocks
                    .iter()
                    .filter(|b| b.block_type == block_types::THINKING)
                    .cloned()
                    .collect();
                let other_blocks: Vec<_> = ctx
                    .generated_blocks
                    .iter()
                    .filter(|b| b.block_type != block_types::THINKING)
                    .cloned()
                    .collect();

                // 1. æ·»åŠ  thinking å—
                for mut block in thinking_blocks {
                    block.block_index = block_index;
                    block_ids.push(block.id.clone());
                    blocks.push(block);
                    block_index += 1;
                }

                // 2. æ·»åŠ æ£€ç´¢å—
                add_retrieval_block!(
                    block_ids,
                    blocks,
                    block_index,
                    ctx.retrieved_sources.rag,
                    block_types::RAG
                );
                add_retrieval_block!(
                    block_ids,
                    blocks,
                    block_index,
                    ctx.retrieved_sources.memory,
                    block_types::MEMORY
                );
                add_retrieval_block!(
                    block_ids,
                    blocks,
                    block_index,
                    ctx.retrieved_sources.web_search,
                    block_types::WEB_SEARCH
                );

                // 3. æ·»åŠ å…¶ä»–å—ï¼ˆcontent/toolï¼‰
                for mut block in other_blocks {
                    block.block_index = block_index;
                    block_ids.push(block.id.clone());
                    blocks.push(block);
                    block_index += 1;
                }
            }
            // ============================================================
            // ä¼˜å…ˆçº§ 3: æ‰‹åŠ¨åˆ›å»º thinking/content å—ï¼ˆæ— å·¥å…·è°ƒç”¨çš„ç®€å•åœºæ™¯ï¼‰
            // ğŸ”§ ä¿®å¤ï¼šæ­£ç¡®é¡ºåºä¸º thinking â†’ retrieval â†’ content
            // ğŸ”§ ä¿®å¤ï¼šåªè¦æœ‰ thinking æˆ– content å†…å®¹ï¼Œéƒ½åº”è¯¥ä¿å­˜ï¼ˆå–æ¶ˆæ—¶å¯èƒ½åªæœ‰ thinkingï¼‰
            // ============================================================
            else if !ctx.final_content.is_empty()
                || ctx
                    .final_reasoning
                    .as_ref()
                    .map_or(false, |r| !r.is_empty())
            {
                log::info!(
                    "[ChatV2::pipeline] save_results priority 3: final_content_len={}, final_reasoning={:?}",
                    ctx.final_content.len(),
                    ctx.final_reasoning.as_ref().map(|r| format!("{}chars", r.len()))
                );
                // 1. thinking å—ï¼šä½¿ç”¨æµå¼è¿‡ç¨‹ä¸­åˆ›å»ºçš„å— IDï¼Œç¡®ä¿ä¸å‰ç«¯ä¸€è‡´
                if let Some(ref reasoning) = ctx.final_reasoning {
                    if !reasoning.is_empty() {
                        let thinking_block_id = ctx
                            .streaming_thinking_block_id
                            .clone()
                            .unwrap_or_else(|| MessageBlock::generate_id());
                        let started_at = assistant_now_ms - elapsed_ms;
                        let block = MessageBlock {
                            id: thinking_block_id,
                            message_id: ctx.assistant_message_id.clone(),
                            block_type: block_types::THINKING.to_string(),
                            status: block_status::SUCCESS.to_string(),
                            content: Some(reasoning.clone()),
                            tool_name: None,
                            tool_input: None,
                            tool_output: None,
                            citations: None,
                            error: None,
                            started_at: Some(started_at),
                            ended_at: Some(assistant_now_ms),
                            // ğŸ”§ ä½¿ç”¨ started_at ä½œä¸º first_chunk_atï¼ˆæµå¼æ—¶è®°å½•çš„ï¼‰
                            first_chunk_at: Some(started_at),
                            block_index,
                        };
                        block_ids.push(block.id.clone());
                        blocks.push(block);
                        block_index += 1;
                    }
                }

                // 2. æ£€ç´¢å—ï¼ˆåœ¨ thinking åã€content å‰ï¼‰
                add_retrieval_block!(
                    block_ids,
                    blocks,
                    block_index,
                    ctx.retrieved_sources.rag,
                    block_types::RAG
                );
                add_retrieval_block!(
                    block_ids,
                    blocks,
                    block_index,
                    ctx.retrieved_sources.memory,
                    block_types::MEMORY
                );
                add_retrieval_block!(
                    block_ids,
                    blocks,
                    block_index,
                    ctx.retrieved_sources.web_search,
                    block_types::WEB_SEARCH
                );

                // 3. content å—ï¼šä½¿ç”¨æµå¼è¿‡ç¨‹ä¸­åˆ›å»ºçš„å— IDï¼Œç¡®ä¿ä¸å‰ç«¯ä¸€è‡´
                // ğŸ”§ ä¿®å¤ï¼šåªæœ‰å½“ final_content ä¸ä¸ºç©ºæ—¶æ‰åˆ›å»º content å—ï¼ˆå–æ¶ˆæ—¶å¯èƒ½åªæœ‰ thinkingï¼‰
                if !ctx.final_content.is_empty() {
                    let content_block_id = ctx
                        .streaming_content_block_id
                        .clone()
                        .unwrap_or_else(|| MessageBlock::generate_id());
                    let started_at = assistant_now_ms - elapsed_ms;
                    let block = MessageBlock {
                        id: content_block_id,
                        message_id: ctx.assistant_message_id.clone(),
                        block_type: block_types::CONTENT.to_string(),
                        status: block_status::SUCCESS.to_string(),
                        content: Some(ctx.final_content.clone()),
                        tool_name: None,
                        tool_input: None,
                        tool_output: None,
                        citations: None,
                        error: None,
                        started_at: Some(started_at),
                        ended_at: Some(assistant_now_ms),
                        // ğŸ”§ ä½¿ç”¨ started_at ä½œä¸º first_chunk_at
                        first_chunk_at: Some(started_at),
                        block_index,
                    };
                    block_ids.push(block.id.clone());
                    blocks.push(block);
                    block_index += 1;
                }
            }

            // å·¥å…·è°ƒç”¨å—ï¼ˆä»…åœ¨é interleaved æ¨¡å¼ä¸‹æ·»åŠ ï¼Œå› ä¸º interleaved æ¨¡å¼å·²åŒ…å«ï¼‰
            for tool_result in &ctx.tool_results {
                let tool_block_id = tool_result
                    .block_id
                    .clone()
                    .unwrap_or_else(|| MessageBlock::generate_id());
                let started_at = assistant_now_ms - tool_result.duration_ms.unwrap_or(0) as i64;

                // ğŸ”§ ä¿®å¤ï¼šæ ¹æ®å·¥å…·åç§°åˆ¤æ–­æ­£ç¡®çš„ block_type
                // æ£€ç´¢å·¥å…·ä½¿ç”¨å¯¹åº”çš„æ£€ç´¢å—ç±»å‹ï¼Œè€Œä¸æ˜¯ mcp_tool
                let block_type = Self::tool_name_to_block_type(&tool_result.tool_name);

                let block = MessageBlock {
                    id: tool_block_id,
                    message_id: ctx.assistant_message_id.clone(),
                    block_type,
                    status: if tool_result.success {
                        block_status::SUCCESS.to_string()
                    } else {
                        block_status::ERROR.to_string()
                    },
                    content: None,
                    tool_name: Some(tool_result.tool_name.clone()),
                    tool_input: Some(tool_result.input.clone()),
                    tool_output: Some(tool_result.output.clone()),
                    citations: None,
                    error: if tool_result.success {
                        None
                    } else {
                        tool_result.error.clone()
                    },
                    started_at: Some(started_at),
                    ended_at: Some(assistant_now_ms),
                    // ğŸ”§ å·¥å…·å—ä½¿ç”¨ started_at ä½œä¸ºæ’åºä¾æ®
                    first_chunk_at: Some(started_at),
                    block_index,
                };
                block_ids.push(block.id.clone());
                blocks.push(block);
                block_index += 1;
            }
        }

        // ğŸ”§ Preserve `anki_cards` blocks created outside of pipeline-generated blocks.
        //
        // `ChatV2Repo::create_message_with_conn` uses SQLite `INSERT OR REPLACE` (DELETE+INSERT).
        // With `chat_v2_blocks.message_id ON DELETE CASCADE`, replacing the assistant message row
        // can delete existing blocks (including ChatAnki-generated `anki_cards` blocks).
        let preserved_anki_cards_blocks: Vec<MessageBlock> =
            ChatV2Repo::get_message_blocks_with_conn(&conn, &ctx.assistant_message_id)?
                .into_iter()
                .filter(|b| b.block_type == block_types::ANKI_CARDS)
                .collect();
        let _preserved_anki_cards_block_ids: Vec<String> = preserved_anki_cards_blocks
            .iter()
            .map(|b| b.id.clone())
            .collect();

        // ğŸ”§ P37 ä¿®å¤ï¼šåˆå¹¶æ•°æ®åº“ä¸­å·²æœ‰çš„ block_idsï¼ˆä¿ç•™å‰ç«¯è¿½åŠ çš„å—ï¼‰
        // é—®é¢˜ï¼šå‰ç«¯åœ¨å·¥å…·æ‰§è¡Œååˆ›å»º workspace_status å—å¹¶è¿½åŠ åˆ°æ¶ˆæ¯çš„ block_idsï¼Œ
        //       ä½† save_results ä¼šç”¨ final_block_ids è¦†ç›–æ•´ä¸ªæ¶ˆæ¯ï¼Œå¯¼è‡´å‰ç«¯è¿½åŠ çš„å—ä¸¢å¤±
        // è§£å†³ï¼šå…ˆè¯»å–æ•°æ®åº“ä¸­ç°æœ‰æ¶ˆæ¯çš„ block_idsï¼Œåˆå¹¶å‰ç«¯è¿½åŠ çš„å—
        let final_block_ids = {
            let mut merged_block_ids = block_ids;

            // å°è¯•è¯»å–æ•°æ®åº“ä¸­ç°æœ‰æ¶ˆæ¯çš„ block_ids
            if let Ok(existing_block_ids_json) = conn.query_row::<Option<String>, _, _>(
                "SELECT block_ids_json FROM chat_v2_messages WHERE id = ?1",
                rusqlite::params![&ctx.assistant_message_id],
                |row| row.get(0),
            ) {
                if let Some(json_str) = existing_block_ids_json {
                    if let Ok(existing_block_ids) = serde_json::from_str::<Vec<String>>(&json_str) {
                        // æ‰¾å‡ºå‰ç«¯è¿½åŠ çš„å—ï¼ˆåœ¨æ•°æ®åº“ä¸­ä½†ä¸åœ¨å½“å‰ block_ids ä¸­ï¼‰
                        for existing_id in existing_block_ids {
                            if !merged_block_ids.contains(&existing_id) {
                                log::info!(
                                    "[ChatV2::pipeline] ğŸ”§ P37: Preserving frontend-appended block_id: {}",
                                    existing_id
                                );
                                merged_block_ids.push(existing_id);
                            }
                        }
                    }
                }
            }

            // ğŸ”§ ä¿®å¤ï¼šæŒ‰åŸå§‹ block_index æ’å…¥ anki_cards å—ï¼Œä¿æŒå…¶åŸå§‹ä½ç½®
            // è€Œä¸æ˜¯è¿½åŠ åˆ°æœ«å°¾å¯¼è‡´åˆ·æ–°åä½ç½®å˜åŒ–
            let pipeline_id_set: std::collections::HashSet<&str> =
                merged_block_ids.iter().map(|s| s.as_str()).collect();
            let mut anki_inserts: Vec<(u32, String)> = preserved_anki_cards_blocks
                .iter()
                .filter(|b| !pipeline_id_set.contains(b.id.as_str()))
                .map(|b| (b.block_index, b.id.clone()))
                .collect();
            anki_inserts.sort_by_key(|(idx, _)| *idx);

            for (orig_idx, id) in anki_inserts {
                // å°† anki_cards å—æ’å…¥åˆ°å…¶åŸå§‹ block_index å¯¹åº”çš„ä½ç½®
                let insert_pos = std::cmp::min(orig_idx as usize, merged_block_ids.len());
                if !merged_block_ids.contains(&id) {
                    merged_block_ids.insert(insert_pos, id);
                }
            }

            merged_block_ids
        };
        let blocks_to_save = blocks;
        let _pipeline_block_count = blocks_to_save.len() as u32;
        let pipeline_block_id_set: std::collections::HashSet<String> =
            blocks_to_save.iter().map(|b| b.id.clone()).collect();

        // æ„å»º chatParams å¿«ç…§ï¼ˆä» SendOptions ä¸­æå–ç›¸å…³å‚æ•°ï¼‰
        let chat_params_snapshot = json!({
            "modelId": ctx.options.model_id,
            "temperature": ctx.options.temperature,
            "contextLimit": ctx.options.context_limit,
            "maxTokens": ctx.options.max_tokens,
            "enableThinking": ctx.options.enable_thinking,
            "disableTools": ctx.options.disable_tools,
            "model2OverrideId": ctx.options.model2_override_id,
        });

        // æ„å»ºåŠ©æ‰‹æ¶ˆæ¯å…ƒæ•°æ®
        // ğŸ”§ Bugä¿®å¤ï¼šmodel_id ä½¿ç”¨æ¨¡å‹æ˜¾ç¤ºåç§°ï¼ˆå¦‚ "Qwen/Qwen3-8B"ï¼‰ï¼Œè€Œä¸æ˜¯ API é…ç½® ID
        // è¿™ç¡®ä¿åˆ·æ–°åå‰ç«¯èƒ½æ­£ç¡®æ˜¾ç¤ºæ¨¡å‹åç§°å’Œå›¾æ ‡
        let assistant_meta = MessageMeta {
            model_id: ctx
                .model_display_name
                .clone()
                .or_else(|| {
                    // ğŸ”§ P0-2 ä¿®å¤ï¼šä¼˜å…ˆå°è¯• model2_override_idï¼ˆå®é™…ä½¿ç”¨çš„æ¨¡å‹ï¼‰
                    // è¿‡æ»¤é…ç½® ID æ ¼å¼ï¼Œé¿å…ä¿å­˜å‰ç«¯æ— æ³•è¯†åˆ«çš„å€¼
                    ctx.options.model2_override_id.as_ref()
                        .filter(|id| !is_config_id_format(id))
                        .cloned()
                })
                .or_else(|| {
                    ctx.options.model_id.as_ref()
                        .filter(|id| !is_config_id_format(id))
                        .cloned()
                }),
            chat_params: Some(chat_params_snapshot),
            sources: if ctx.retrieved_sources.rag.is_some()
                || ctx.retrieved_sources.memory.is_some()
                || ctx.retrieved_sources.web_search.is_some()
            {
                Some(ctx.retrieved_sources.clone())
            } else {
                None
            },
            tool_results: if ctx.tool_results.is_empty() {
                None
            } else {
                Some(ctx.tool_results.clone())
            },
            anki_cards: None,
            // ğŸ†• Prompt 5: ä¿å­˜ token ç»Ÿè®¡ï¼ˆå§‹ç»ˆä¿å­˜ï¼Œä¸è·³è¿‡é›¶å€¼ï¼‰
            usage: Some(ctx.token_usage.clone()),
            // ğŸ†• Prompt 8: ä¿å­˜ä¸Šä¸‹æ–‡å¿«ç…§ï¼ˆç»Ÿä¸€ä¸Šä¸‹æ–‡æ³¨å…¥ç³»ç»Ÿï¼‰
            // åªå­˜ ContextRefï¼Œä¸å­˜ formattedBlocks
            context_snapshot: if ctx.context_snapshot.has_refs() {
                Some(ctx.context_snapshot.clone())
            } else {
                None
            },
        };

        let assistant_message = ChatMessage {
            id: ctx.assistant_message_id.clone(),
            session_id: ctx.session_id.clone(),
            role: MessageRole::Assistant,
            block_ids: final_block_ids,
            timestamp: chrono::Utc::now().timestamp_millis(),
            persistent_stable_id: None,
            parent_id: None,
            supersedes: None,
            meta: Some(assistant_meta),
            attachments: None,
            active_variant_id: None,
            variants: None,
            shared_context: None,
        };

        // æ£€æŸ¥æ˜¯å¦è·³è¿‡åŠ©æ‰‹æ¶ˆæ¯ä¿å­˜ï¼ˆé‡è¯•åœºæ™¯ï¼‰
        let skip_assistant_message = ctx.options.skip_assistant_message_save.unwrap_or(false);

        if !skip_assistant_message {
            // æ­£å¸¸åœºæ™¯ï¼šåˆ›å»ºæ–°çš„åŠ©æ‰‹æ¶ˆæ¯
            ChatV2Repo::create_message_with_conn(&conn, &assistant_message)?;
        } else {
            // é‡è¯•åœºæ™¯ï¼šæ›´æ–°å·²æœ‰çš„åŠ©æ‰‹æ¶ˆæ¯ï¼ˆåªæ›´æ–°å—åˆ—è¡¨å’Œå…ƒæ•°æ®ï¼‰
            log::debug!(
                "[ChatV2::pipeline] Updating existing assistant message for retry: id={}",
                ctx.assistant_message_id
            );
            ChatV2Repo::update_message_with_conn(&conn, &assistant_message)?;
        }

        // ä¿å­˜æ‰€æœ‰åŠ©æ‰‹æ¶ˆæ¯å—ï¼ˆæ— è®ºæ˜¯åˆ›å»ºè¿˜æ˜¯æ›´æ–°æ¶ˆæ¯ï¼Œå—éƒ½éœ€è¦ä¿å­˜ï¼‰
        for (index, mut block) in blocks_to_save.into_iter().enumerate() {
            // ç¡®ä¿ block_index æ­£ç¡®è®¾ç½®
            block.block_index = index as u32;
            // ç¡®ä¿ message_id æ­£ç¡®
            block.message_id = ctx.assistant_message_id.clone();
            ChatV2Repo::create_block_with_conn(&conn, &block)?;
        }

        // Re-insert preserved `anki_cards` blocks deleted by the assistant message REPLACE.
        //    ğŸ”§ ä¿®å¤ï¼šä¿æŒ anki_cards å—çš„åŸå§‹ block_indexï¼Œä¸å†è¿½åŠ åˆ°æœ«å°¾
        if !preserved_anki_cards_blocks.is_empty() {
            for preserved in preserved_anki_cards_blocks {
                // If the pipeline already has the same block id, prefer the pipeline version.
                if pipeline_block_id_set.contains(preserved.id.as_str()) {
                    continue;
                }

                // ä¿æŒåŸå§‹ block_index ä¸å˜ï¼Œè¿™æ ·åˆ·æ–°åä½ç½®ä¸ä¼šè·³åˆ°æœ«å°¾
                let mut block_to_save = preserved;
                block_to_save.message_id = ctx.assistant_message_id.clone();

                if let Err(e) = ChatV2Repo::create_block_with_conn(&conn, &block_to_save) {
                    log::error!(
                        "[ChatV2::pipeline] Failed to re-insert preserved anki_cards block: message_id={}, block_id={}, err={:?}",
                        ctx.assistant_message_id,
                        block_to_save.id,
                        e
                    );
                }
            }
        }

        log::info!(
            "[ChatV2::pipeline] Results saved: session={}, user_msg={}, assistant_msg={}, blocks={}, content_len={}",
            ctx.session_id,
            ctx.user_message_id,
            ctx.assistant_message_id,
            ctx.generated_blocks.len(),
            ctx.final_content.len()
        );

        Ok(())
    }

    /// ä¿å­˜ç»“æœåçš„åå¤„ç†æ“ä½œï¼ˆåœ¨äº‹åŠ¡æäº¤åæ‰§è¡Œï¼‰
    ///
    /// æ­¤æ–¹æ³•åœ¨äº‹åŠ¡æˆåŠŸæäº¤åç”± `save_results` è°ƒç”¨ï¼Œ
    /// æ‰§è¡Œä¸éœ€è¦äº‹åŠ¡ä¿æŠ¤çš„åå¤„ç†æ“ä½œã€‚
    async fn save_results_post_commit(&self, ctx: &PipelineContext) {
        // ğŸ†• Prompt 8: æ¶ˆæ¯ä¿å­˜åå¢åŠ èµ„æºå¼•ç”¨è®¡æ•°ï¼ˆç»Ÿä¸€ä¸Šä¸‹æ–‡æ³¨å…¥ç³»ç»Ÿï¼‰
        // çº¦æŸï¼šæ¶ˆæ¯ä¿å­˜åè°ƒç”¨ incrementRef
        // æ³¨æ„ï¼šæ­¤æ“ä½œåœ¨äº‹åŠ¡æäº¤åæ‰§è¡Œï¼Œç¡®ä¿åªæœ‰åœ¨æ•°æ®åº“å†™å…¥æˆåŠŸåæ‰å¢åŠ å¼•ç”¨è®¡æ•°
        if ctx.context_snapshot.has_refs() {
            let resource_ids = ctx.context_snapshot.all_resource_ids();
            self.increment_resource_refs(&resource_ids).await;
            log::debug!(
                "[ChatV2::pipeline] Incremented refs for {} resources after message save",
                resource_ids.len()
            );
        }
    }

    // ========================================================================
    // è‡ªåŠ¨æ‘˜è¦ç”Ÿæˆï¼ˆæ ‡é¢˜ + ç®€ä»‹ï¼‰
    // ========================================================================

    /// æ‘˜è¦ç”Ÿæˆ Promptï¼ˆåŒæ—¶ç”Ÿæˆæ ‡é¢˜å’Œç®€ä»‹ï¼‰
    const SUMMARY_GENERATION_PROMPT: &'static str = r#"è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯å†…å®¹ç”Ÿæˆä¼šè¯æ ‡é¢˜å’Œç®€ä»‹ã€‚

è¦æ±‚ï¼š
1. æ ‡é¢˜ï¼ˆtitleï¼‰ï¼š5-20 ä¸ªå­—ç¬¦ï¼Œæ¦‚æ‹¬å¯¹è¯ä¸»é¢˜
2. ç®€ä»‹ï¼ˆdescriptionï¼‰ï¼š30-80 ä¸ªå­—ç¬¦ï¼Œæè¿°å¯¹è¯çš„ä¸»è¦å†…å®¹å’Œç»“è®º
3. ä½¿ç”¨ä¸­æ–‡
4. ä¸è¦ä½¿ç”¨å¼•å·åŒ…è£¹
5. æŒ‰ JSON æ ¼å¼è¾“å‡ºï¼š{"title": "æ ‡é¢˜", "description": "ç®€ä»‹"}

ç”¨æˆ·é—®é¢˜ï¼š
{user_content}

åŠ©æ‰‹å›å¤ï¼ˆæ‘˜è¦ï¼‰ï¼š
{assistant_content}

è¯·è¾“å‡º JSONï¼š"#;

    /// è‡ªåŠ¨ç”Ÿæˆä¼šè¯æ‘˜è¦ï¼ˆæ ‡é¢˜ + ç®€ä»‹ï¼‰
    ///
    /// åœ¨æ¯è½®å¯¹è¯å®Œæˆåè°ƒç”¨ï¼Œæ ¹æ®å¯¹è¯å†…å®¹ç”Ÿæˆæ ‡é¢˜å’Œç®€ä»‹ã€‚
    /// é€šè¿‡å†…å®¹å“ˆå¸Œé˜²æ­¢é‡å¤ç”Ÿæˆã€‚
    ///
    /// ## å‚æ•°
    /// - `session_id`: ä¼šè¯ ID
    /// - `user_content`: ç”¨æˆ·æ¶ˆæ¯å†…å®¹
    /// - `assistant_content`: åŠ©æ‰‹å›å¤å†…å®¹
    /// - `emitter`: äº‹ä»¶å‘å°„å™¨ï¼ˆç”¨äºé€šçŸ¥å‰ç«¯ï¼‰
    ///
    /// ## è¯´æ˜
    /// - å¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡ä¸»æµç¨‹
    /// - ç”Ÿæˆå¤±è´¥ä¸å½±å“å¯¹è¯åŠŸèƒ½
    /// - æ ‡é¢˜é•¿åº¦é™åˆ¶ä¸º 50 å­—ç¬¦ï¼Œç®€ä»‹é™åˆ¶ä¸º 100 å­—ç¬¦
    pub async fn generate_summary(
        &self,
        session_id: &str,
        user_content: &str,
        assistant_content: &str,
        emitter: Arc<ChatV2EventEmitter>,
    ) {
        log::info!(
            "[ChatV2::pipeline] Generating summary for session={}",
            session_id
        );

        // æˆªå–åŠ©æ‰‹å›å¤çš„å‰ 500 ä¸ªå­—ç¬¦ä½œä¸ºæ‘˜è¦ï¼ˆå®‰å…¨å¤„ç† UTF-8ï¼‰
        let assistant_summary: String = assistant_content.chars().take(500).collect();

        // æ„å»º prompt
        let prompt = Self::SUMMARY_GENERATION_PROMPT
            .replace("{user_content}", user_content)
            .replace("{assistant_content}", &assistant_summary);

        // è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦
        let response = match self.call_llm_for_summary(&prompt).await {
            Ok(r) => r,
            Err(e) => {
                log::warn!("[ChatV2::pipeline] Failed to generate summary: {}", e);
                return;
            }
        };

        // è§£æ JSON å“åº”
        let (title, description) = match Self::parse_summary_response(&response) {
            Some((t, d)) => (t, d),
            None => {
                log::warn!(
                    "[ChatV2::pipeline] Failed to parse summary JSON: {}",
                    response
                );
                // å›é€€ï¼šå°†æ•´ä¸ªå“åº”ä½œä¸ºæ ‡é¢˜ï¼Œç®€ä»‹ç•™ç©º
                let fallback_title = response
                    .trim()
                    .trim_matches('"')
                    .trim_matches('\'')
                    .chars()
                    .take(50)
                    .collect::<String>();
                if fallback_title.is_empty() {
                    return;
                }
                (fallback_title, String::new())
            }
        };

        if title.is_empty() {
            log::warn!("[ChatV2::pipeline] Generated title is empty");
            return;
        }

        log::info!(
            "[ChatV2::pipeline] Generated summary for session={}: title={}, description={}",
            session_id,
            title,
            description
        );

        // è®¡ç®—å†…å®¹å“ˆå¸Œï¼ˆç”¨äºé˜²é‡å¤ç”Ÿæˆï¼‰
        let content_hash = Self::compute_content_hash(user_content, &assistant_summary);

        // æ›´æ–°æ•°æ®åº“
        if let Err(e) = self
            .update_session_summary(session_id, &title, &description, &content_hash)
            .await
        {
            log::error!("[ChatV2::pipeline] Failed to update session summary: {}", e);
            return;
        }

        // å‘é€äº‹ä»¶é€šçŸ¥å‰ç«¯
        emitter.emit_summary_updated(&title, &description);
    }

    /// è§£ææ‘˜è¦ç”Ÿæˆçš„ JSON å“åº”
    fn parse_summary_response(response: &str) -> Option<(String, String)> {
        // å°è¯•è§£æ JSON
        let response = response.trim();

        // å¤„ç†å¯èƒ½çš„ markdown ä»£ç å—åŒ…è£¹
        let json_str = if response.starts_with("```") {
            response
                .trim_start_matches("```json")
                .trim_start_matches("```")
                .trim_end_matches("```")
                .trim()
        } else {
            response
        };

        // è§£æ JSON
        if let Ok(v) = serde_json::from_str::<serde_json::Value>(json_str) {
            let title = v
                .get("title")
                .and_then(|v| v.as_str())
                .unwrap_or("")
                .trim()
                .trim_matches('"')
                .trim_matches('\'')
                .trim_matches('ã€Œ')
                .trim_matches('ã€');

            let description = v
                .get("description")
                .and_then(|v| v.as_str())
                .unwrap_or("")
                .trim();

            // æˆªå–é•¿åº¦
            let title = if title.chars().count() > 50 {
                title.chars().take(50).collect::<String>()
            } else {
                title.to_string()
            };

            let description = if description.chars().count() > 100 {
                description.chars().take(100).collect::<String>()
            } else {
                description.to_string()
            };

            if !title.is_empty() {
                return Some((title, description));
            }
        }

        None
    }

    /// è®¡ç®—å†…å®¹å“ˆå¸Œï¼ˆç”¨äºé˜²é‡å¤ç”Ÿæˆï¼‰
    fn compute_content_hash(user_content: &str, assistant_content: &str) -> String {
        use sha2::{Digest, Sha256};
        let mut hasher = Sha256::new();
        hasher.update(user_content.as_bytes());
        hasher.update(b"|");
        hasher.update(assistant_content.as_bytes());
        let result = hasher.finalize();
        // å–å‰ 16 å­—èŠ‚ä½œä¸ºå“ˆå¸Œ
        hex::encode(&result[..16])
    }

    /// è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦ï¼ˆç®€å•çš„éæµå¼è°ƒç”¨ï¼‰
    ///
    /// ä½¿ç”¨æ ‡é¢˜/æ ‡ç­¾ç”Ÿæˆæ¨¡å‹ï¼ˆå›é€€é“¾ï¼šchat_title_model â†’ model2ï¼‰ã€‚
    ///
    /// ğŸ”§ P1ä¿®å¤ï¼šæ·»åŠ  Pipeline å±‚è¶…æ—¶ä¿æŠ¤
    async fn call_llm_for_summary(&self, prompt: &str) -> ChatV2Result<String> {
        // è°ƒç”¨ LLMï¼ˆéæµå¼ï¼‰ï¼Œä½¿ç”¨æ ‡é¢˜ç”Ÿæˆä¸“ç”¨æ¨¡å‹ï¼Œå¸¦è¶…æ—¶ä¿æŠ¤
        let llm_future = self.llm_manager.call_chat_title_raw_prompt(prompt);

        let response =
            match timeout(Duration::from_secs(LLM_NON_STREAM_TIMEOUT_SECS), llm_future).await {
                Ok(result) => {
                    result.map_err(|e| ChatV2Error::Llm(format!("LLM call failed: {}", e)))?
                }
                Err(_) => {
                    log::error!(
                        "[ChatV2::pipeline] LLM summary call timeout after {}s",
                        LLM_NON_STREAM_TIMEOUT_SECS
                    );
                    return Err(ChatV2Error::Timeout(format!(
                        "LLM summary call timed out after {}s",
                        LLM_NON_STREAM_TIMEOUT_SECS
                    )));
                }
            };

        // æå–å†…å®¹
        let summary = response.assistant_message.trim().to_string();
        Ok(summary)
    }

    /// æ›´æ–°ä¼šè¯æ‘˜è¦ï¼ˆæ ‡é¢˜ + ç®€ä»‹ + å“ˆå¸Œï¼‰
    async fn update_session_summary(
        &self,
        session_id: &str,
        title: &str,
        description: &str,
        summary_hash: &str,
    ) -> ChatV2Result<()> {
        let conn = self.db.get_conn_safe()?;

        // è·å–ä¼šè¯
        let mut session = ChatV2Repo::get_session_with_conn(&conn, session_id)?
            .ok_or_else(|| ChatV2Error::SessionNotFound(session_id.to_string()))?;

        // æ›´æ–°æ‘˜è¦
        session.title = Some(title.to_string());
        session.description = if description.is_empty() {
            None
        } else {
            Some(description.to_string())
        };
        session.summary_hash = Some(summary_hash.to_string());
        session.updated_at = chrono::Utc::now();

        // ä¿å­˜
        ChatV2Repo::update_session_with_conn(&conn, &session)?;

        log::debug!(
            "[ChatV2::pipeline] Session summary updated: session={}, title={}, description={}",
            session_id,
            title,
            description
        );

        Ok(())
    }

    /// æ£€æŸ¥ä¼šè¯æ˜¯å¦éœ€è¦ç”Ÿæˆæ‘˜è¦
    ///
    /// æ¡ä»¶ï¼šå†…å®¹å“ˆå¸Œä¸ä¸Šæ¬¡ç”Ÿæˆæ—¶ä¸åŒ
    async fn should_generate_summary(
        &self,
        session_id: &str,
        user_content: &str,
        assistant_content: &str,
    ) -> bool {
        // è®¡ç®—å½“å‰å†…å®¹å“ˆå¸Œ
        let assistant_summary: String = assistant_content.chars().take(500).collect();
        let current_hash = Self::compute_content_hash(user_content, &assistant_summary);

        // è·å–ä¼šè¯ä¸­ä¿å­˜çš„å“ˆå¸Œ
        let conn = match self.db.get_conn_safe() {
            Ok(c) => c,
            Err(_) => return true, // å‡ºé”™æ—¶å…è®¸ç”Ÿæˆ
        };

        let session = match ChatV2Repo::get_session_with_conn(&conn, session_id) {
            Ok(Some(s)) => s,
            Ok(None) | Err(_) => return true, // ä¼šè¯ä¸å­˜åœ¨æ—¶å…è®¸ç”Ÿæˆ
        };

        // å¦‚æœå“ˆå¸Œç›¸åŒï¼Œä¸éœ€è¦é‡æ–°ç”Ÿæˆ
        match &session.summary_hash {
            Some(hash) if hash == &current_hash => {
                log::debug!(
                    "[ChatV2::pipeline] Skip summary generation, hash unchanged: {}",
                    session_id
                );
                false
            }
            _ => true,
        }
    }

    /// å–æ¶ˆæ­£åœ¨è¿›è¡Œçš„æµå¼ç”Ÿæˆ
    ///
    /// ## å‚æ•°
    /// - `session_id`: ä¼šè¯ ID
    /// - `message_id`: æ¶ˆæ¯ ID
    ///
    /// ## è¯´æ˜
    /// å–æ¶ˆæ“ä½œé€šè¿‡ `CancellationToken` å®ç°ï¼Œéœ€è¦åœ¨ handlers å±‚ç®¡ç† tokenã€‚
    pub fn cancel(&self, session_id: &str, message_id: &str) {
        log::info!(
            "[ChatV2::pipeline] Cancel requested for session={}, message={}",
            session_id,
            message_id
        );
        // å®é™…å–æ¶ˆé€»è¾‘åœ¨ handlers å±‚é€šè¿‡ CancellationToken å®ç°
    }

    // ========================================================================
    // å¤šæ¨¡å‹å¹¶è¡Œå˜ä½“æ‰§è¡Œ (Prompt 5)
    // ========================================================================

    /// æœ€å¤§å˜ä½“æ•°é™åˆ¶ï¼ˆé»˜è®¤å€¼ï¼‰
    const DEFAULT_MAX_VARIANTS: u32 = 10;

    /// å¤šæ¨¡å‹å¹¶è¡Œæ‰§è¡Œå…¥å£
    ///
    /// ## æ‰§è¡Œæµç¨‹
    /// 1. åˆ›å»ºç”¨æˆ·æ¶ˆæ¯å’ŒåŠ©æ‰‹æ¶ˆæ¯
    /// 2. æ‰§è¡Œå…±äº«æ£€ç´¢ â†’ SharedContext
    /// 3. æŒä¹…åŒ– shared_context
    /// 4. ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»º VariantExecutionContext
    /// 5. å‘å°„ stream_start
    /// 6. tokio::spawn + join_all å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å˜ä½“
    /// 7. æ”¶é›†å˜ä½“ç»“æœï¼Œç¡®å®š active_variant_idï¼ˆç¬¬ä¸€ä¸ªæˆåŠŸçš„ï¼‰
    /// 8. æŒä¹…åŒ–å˜ä½“åˆ—è¡¨
    /// 9. å‘å°„ stream_complete
    ///
    /// ## çº¦æŸ
    /// - æ£€ç´¢åªæ‰§è¡Œä¸€æ¬¡
    /// - å¤šå˜ä½“æ¨¡å¼ä¸‹å¼ºåˆ¶ anki_enabled = false
    /// - è¶…è¿‡ max_variants_per_message è¿”å› LimitExceeded é”™è¯¯
    /// - active_variant_id é»˜è®¤è®¾ä¸ºç¬¬ä¸€ä¸ªæˆåŠŸçš„å˜ä½“
    ///
    /// ## å‚æ•°
    /// - `window`: Tauri çª—å£å¥æŸ„
    /// - `request`: å‘é€æ¶ˆæ¯è¯·æ±‚
    /// - `model_ids`: è¦å¹¶è¡Œæ‰§è¡Œçš„æ¨¡å‹ ID åˆ—è¡¨
    /// - `cancel_token`: å–æ¶ˆä»¤ç‰Œ
    ///
    /// ## è¿”å›
    /// åŠ©æ‰‹æ¶ˆæ¯ ID
    /// ğŸ”§ P1ä¿®å¤ï¼šæ·»åŠ  chat_v2_state å‚æ•°ï¼Œç”¨äºæ³¨å†Œæ¯ä¸ªå˜ä½“çš„ cancel token
    pub async fn execute_multi_variant(
        &self,
        window: tauri::Window,
        request: SendMessageRequest,
        model_ids: Vec<String>,
        cancel_token: CancellationToken,
        chat_v2_state: Option<Arc<super::state::ChatV2State>>,
    ) -> ChatV2Result<String> {
        use super::variant_context::{ParallelExecutionManager, VariantExecutionContext};
        use futures::future::join_all;

        let start_time = Instant::now();
        let session_id = request.session_id.clone();
        let user_content = request.content.clone();
        let mut options = request.options.clone().unwrap_or_default();

        // === 0. æ™ºèƒ½ vision_quality è®¡ç®—ï¼ˆä¸å•å˜ä½“è·¯å¾„ä¿æŒä¸€è‡´ï¼‰===
        // å¦‚æœç”¨æˆ·æ²¡æœ‰æ˜¾å¼æŒ‡å®šï¼Œæ ¹æ®å›¾ç‰‡æ•°é‡å’Œæ¥æºè‡ªåŠ¨é€‰æ‹©å‹ç¼©ç­–ç•¥
        if options
            .vision_quality
            .as_deref()
            .filter(|v| !v.is_empty() && *v != "auto")
            .is_none()
        {
            let user_refs = request.user_context_refs.as_deref().unwrap_or(&[]);
            let mut image_count = 0usize;
            let mut has_pdf_or_textbook = false;

            for ctx_ref in user_refs {
                // ç»Ÿè®¡å›¾ç‰‡å—æ•°é‡
                for block in &ctx_ref.formatted_blocks {
                    if matches!(block, super::resource_types::ContentBlock::Image { .. }) {
                        image_count += 1;
                    }
                }
                // æ£€æŸ¥æ˜¯å¦æœ‰ PDF/æ•™ææ¥æº
                let type_id_lower = ctx_ref.type_id.to_lowercase();
                if type_id_lower.contains("pdf")
                    || type_id_lower.contains("textbook")
                    || type_id_lower.contains("file")
                    || ctx_ref.resource_id.starts_with("tb_")
                {
                    has_pdf_or_textbook = true;
                }
            }

            // æ™ºèƒ½ç­–ç•¥
            let auto_quality = if has_pdf_or_textbook || image_count >= 6 {
                "low" // PDF/æ•™æ æˆ–å¤§é‡å›¾ç‰‡ï¼šæœ€å¤§å‹ç¼©
            } else if image_count >= 2 {
                "medium" // ä¸­ç­‰æ•°é‡ï¼šå¹³è¡¡å‹ç¼©
            } else {
                "high" // å•å›¾æˆ–æ— å›¾ï¼šä¿æŒåŸè´¨é‡
            };

            log::info!(
                "[ChatV2::pipeline] Multi-variant vision_quality: auto -> '{}' (images={}, has_pdf_or_textbook={})",
                auto_quality, image_count, has_pdf_or_textbook
            );
            options.vision_quality = Some(auto_quality.to_string());
        }

        // === 1. çº¦æŸæ£€æŸ¥ ===
        // æ£€æŸ¥å˜ä½“æ•°é‡é™åˆ¶
        let max_variants = options
            .max_variants_per_message
            .unwrap_or(Self::DEFAULT_MAX_VARIANTS);
        if model_ids.len() as u32 > max_variants {
            return Err(ChatV2Error::LimitExceeded(format!(
                "Variant count {} exceeds maximum allowed {}",
                model_ids.len(),
                max_variants
            )));
        }

        if model_ids.is_empty() {
            return Err(ChatV2Error::Other("No model IDs provided".to_string()));
        }

        // ğŸ”§ 2025-01-27 å¯¹é½å•å˜ä½“ï¼šå¤šå˜ä½“æ¨¡å¼ç°åœ¨æ”¯æŒ Ankiï¼Œä½¿ç”¨ç”¨æˆ·é…ç½®çš„å€¼
        // options.anki_enabled ä¿æŒç”¨æˆ·é…ç½®ï¼Œä¸å†å¼ºåˆ¶ç¦ç”¨

        // === è·å– API é…ç½®ï¼Œæ„å»º config_id -> model çš„æ˜ å°„ ===
        // å‰ç«¯ä¼ é€’çš„æ˜¯ API é…ç½® IDï¼Œæˆ‘ä»¬éœ€è¦ä»ä¸­æå–çœŸæ­£çš„æ¨¡å‹åç§°ç”¨äºå‰ç«¯æ˜¾ç¤º
        let api_configs = self
            .llm_manager
            .get_api_configs()
            .await
            .map_err(|e| ChatV2Error::Other(format!("Failed to get API configs: {}", e)))?;

        // æ„å»º config_id -> (model, config_id) çš„æ˜ å°„
        // model: ç”¨äºå‰ç«¯æ˜¾ç¤ºï¼ˆå¦‚ "Qwen/Qwen3-8B"ï¼‰
        // config_id: ç”¨äº LLM è°ƒç”¨
        let config_map: std::collections::HashMap<String, (String, String)> = api_configs
            .into_iter()
            .map(|c| (c.id.clone(), (c.model.clone(), c.id)))
            .collect();

        // è§£æ model_idsï¼Œæå–çœŸæ­£çš„æ¨¡å‹åç§°å’Œé…ç½® ID
        let resolved_models: Vec<(String, String)> = model_ids
            .iter()
            .filter_map(|config_id| {
                config_map.get(config_id).cloned().or_else(|| {
                    // ğŸ”§ ä¸‰è½®ä¿®å¤ï¼šå¦‚æœ config_id æ˜¯é…ç½® UUIDï¼Œä¸åº”ä½œä¸ºæ¨¡å‹æ˜¾ç¤ºåç§°
                    if is_config_id_format(config_id) {
                        log::warn!(
                            "[ChatV2::pipeline] Config not found for id and id is a config format, using empty display name: {}",
                            config_id
                        );
                        Some((String::new(), config_id.clone()))
                    } else {
                        log::warn!(
                            "[ChatV2::pipeline] Config not found for id: {}, using as model name",
                            config_id
                        );
                        Some((config_id.clone(), config_id.clone()))
                    }
                })
            })
            .collect();

        log::info!(
            "[ChatV2::pipeline] execute_multi_variant: session={}, models={:?}, content_len={}",
            session_id,
            resolved_models.iter().map(|(m, _)| m).collect::<Vec<_>>(),
            user_content.len()
        );

        // === 2. ä½¿ç”¨è¯·æ±‚ä¸­çš„æ¶ˆæ¯ IDï¼ˆå¦‚æœæä¾›ï¼‰ï¼Œå¦åˆ™ç”Ÿæˆæ–°çš„ ===
        // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨å‰ç«¯ä¼ é€’çš„ IDï¼Œç¡®ä¿å‰åç«¯ä¸€è‡´
        let user_message_id = request
            .user_message_id
            .clone()
            .unwrap_or_else(ChatMessage::generate_id);
        let assistant_message_id = request
            .assistant_message_id
            .clone()
            .unwrap_or_else(ChatMessage::generate_id);

        // === 3. åˆ›å»ºäº‹ä»¶å‘å°„å™¨ ===
        let emitter = Arc::new(ChatV2EventEmitter::new(window.clone(), session_id.clone()));

        // === 4. æ‰§è¡Œå…±äº«æ£€ç´¢ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰===
        let shared_context = self
            .execute_shared_retrievals(&request, &emitter, &assistant_message_id)
            .await?;
        let shared_context = Arc::new(shared_context);

        log::debug!(
            "[ChatV2::pipeline] Shared retrievals completed: has_sources={}",
            shared_context.has_sources()
        );

        // === 5. å‘å°„ stream_start ===
        // å¤šå˜ä½“æ¨¡å¼ä¸åœ¨ stream_start ä¸­ä¼ é€’æ¨¡å‹åç§°ï¼Œæ¯ä¸ªå˜ä½“é€šè¿‡ variant_start äº‹ä»¶ä¼ é€’
        emitter.emit_stream_start(&assistant_message_id, None);

        // ğŸ†• P0é˜²é—ªé€€ï¼šç”¨æˆ·æ¶ˆæ¯å³æ—¶ä¿å­˜ï¼ˆå¤šå˜ä½“æ¨¡å¼ï¼‰
        // åœ¨å˜ä½“æ‰§è¡Œå‰ç«‹å³ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼Œç¡®ä¿ç”¨æˆ·è¾“å…¥ä¸ä¼šå› é—ªé€€ä¸¢å¤±
        if !options.skip_user_message_save.unwrap_or(false) {
            // æ„å»ºä¸´æ—¶ PipelineContext ç”¨äºä¿å­˜ç”¨æˆ·æ¶ˆæ¯
            let temp_request = SendMessageRequest {
                session_id: session_id.clone(),
                content: user_content.clone(),
                user_message_id: Some(user_message_id.clone()),
                assistant_message_id: Some(assistant_message_id.clone()),
                options: Some(options.clone()),
                user_context_refs: request.user_context_refs.clone(),
                path_map: request.path_map.clone(),
                workspace_id: request.workspace_id.clone(),
            };
            let temp_ctx = PipelineContext::new(temp_request);
            if let Err(e) = self.save_user_message_immediately(&temp_ctx).await {
                log::warn!(
                    "[ChatV2::pipeline] Multi-variant: Failed to save user message immediately: {}",
                    e
                );
            } else {
                log::info!(
                    "[ChatV2::pipeline] Multi-variant: User message saved immediately: id={}",
                    user_message_id
                );
            }
        }

        // === 6. åˆ›å»ºå¹¶è¡Œæ‰§è¡Œç®¡ç†å™¨ ===
        let manager = ParallelExecutionManager::with_cancel_token(cancel_token.clone());

        // ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»º VariantExecutionContext
        // ä½¿ç”¨ resolved_models ä¸­çš„ (æ¨¡å‹åç§°, é…ç½®ID) å…ƒç»„
        // - æ¨¡å‹åç§°ï¼šä¼ é€’ç»™å˜ä½“ä¸Šä¸‹æ–‡ï¼Œç”¨äºå‰ç«¯æ˜¾ç¤º
        // - é…ç½®IDï¼šç”¨äº LLM è°ƒç”¨
        let mut variant_contexts: Vec<(Arc<VariantExecutionContext>, String)> =
            Vec::with_capacity(resolved_models.len());
        for (model_name, config_id) in &resolved_models {
            let variant_id = Variant::generate_id();
            let ctx = manager.create_variant(
                variant_id.clone(),
                model_name.clone(), // ä½¿ç”¨æ¨¡å‹åç§°ï¼Œç”¨äºå‰ç«¯æ˜¾ç¤º
                assistant_message_id.clone(),
                Arc::clone(&shared_context),
                Arc::clone(&emitter),
            );

            // ğŸ”§ P2ä¿®å¤ï¼šè®¾ç½® config_idï¼Œç”¨äºé‡è¯•æ—¶æ­£ç¡®é€‰æ‹©æ¨¡å‹
            ctx.set_config_id(config_id.clone());

            // ğŸ”§ P1ä¿®å¤ï¼šä¸ºæ¯ä¸ªå˜ä½“æ³¨å†Œç‹¬ç«‹çš„ cancel token
            // ä½¿ç”¨ session_id:variant_id ä½œä¸º keyï¼Œè¿™æ ·å¯ä»¥ç²¾ç¡®å–æ¶ˆå•ä¸ªå˜ä½“
            if let Some(ref state) = chat_v2_state {
                let cancel_key = format!("{}:{}", session_id, variant_id);
                state.register_existing_token(&cancel_key, ctx.cancel_token().clone());
                log::debug!(
                    "[ChatV2::pipeline] Registered cancel token for variant: {}",
                    cancel_key
                );
            }

            variant_contexts.push((ctx, config_id.clone())); // ä¿å­˜é…ç½®IDç”¨äºLLMè°ƒç”¨
        }

        // === 6.5 é˜²é—ªé€€ï¼šæŒä¹…åŒ–åŠ©æ‰‹æ¶ˆæ¯éª¨æ¶ï¼ˆå« pending å˜ä½“åˆ—è¡¨ï¼‰===
        // åœ¨å˜ä½“æ‰§è¡Œå‰å†™å…¥ DBï¼Œç¡®ä¿åˆ·æ–°/å´©æºƒåä»èƒ½è¯†åˆ«ä¸ºå¤šå˜ä½“æ¶ˆæ¯ã€‚
        // save_multi_variant_results ä½¿ç”¨ INSERT OR REPLACE åœ¨å®Œæˆåè¦†ç›–æ­¤éª¨æ¶ã€‚
        {
            let skeleton_variants: Vec<Variant> = variant_contexts
                .iter()
                .map(|(ctx, _)| {
                    Variant::new_with_id_and_config(
                        ctx.variant_id().to_string(),
                        ctx.model_id().to_string(),
                        ctx.get_config_id().unwrap_or_default(),
                    )
                })
                .collect();

            let first_variant_id = skeleton_variants.first().map(|v| v.id.clone());

            let skeleton_msg = ChatMessage {
                id: assistant_message_id.clone(),
                session_id: session_id.clone(),
                role: MessageRole::Assistant,
                block_ids: Vec::new(),
                timestamp: chrono::Utc::now().timestamp_millis(),
                persistent_stable_id: None,
                parent_id: None,
                supersedes: None,
                meta: Some(MessageMeta {
                    model_id: None,
                    chat_params: Some(serde_json::json!({
                        "multiVariantMode": true,
                    })),
                    sources: None,
                    tool_results: None,
                    anki_cards: None,
                    usage: None,
                    context_snapshot: None,
                }),
                attachments: None,
                active_variant_id: first_variant_id,
                variants: Some(skeleton_variants),
                shared_context: Some((*shared_context).clone()),
            };

            if let Ok(conn) = self.db.get_conn_safe() {
                if let Err(e) = ChatV2Repo::create_message_with_conn(&conn, &skeleton_msg) {
                    log::warn!(
                        "[ChatV2::pipeline] Failed to persist skeleton assistant message (non-fatal): {}",
                        e
                    );
                } else {
                    log::info!(
                        "[ChatV2::pipeline] Persisted skeleton assistant message: id={}, variants={}",
                        assistant_message_id,
                        variant_contexts.len()
                    );
                }
            }
        }

        // === 7. å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å˜ä½“ ===
        let self_clone = self.clone();
        let options_arc = Arc::new(options.clone());
        let user_content_arc = Arc::new(user_content.clone());
        let session_id_arc = Arc::new(session_id.clone());

        // ğŸ”§ P1ä¿®å¤ï¼šä½¿ç”¨ä»»åŠ¡è¿½è¸ªå™¨è¿½è¸ªå¹¶è¡Œä»»åŠ¡
        // åˆ›å»ºå¹¶è¡Œä»»åŠ¡
        let futures: Vec<_> = variant_contexts.iter().map(|(ctx, config_id)| {
            let self_ref = self_clone.clone();
            let ctx_clone = Arc::clone(ctx);
            let config_id_clone = config_id.clone();  // API é…ç½® IDï¼Œç”¨äº LLM è°ƒç”¨
            let options_clone = Arc::clone(&options_arc);
            let user_content_clone = Arc::clone(&user_content_arc);
            let session_id_clone = Arc::clone(&session_id_arc);
            let shared_ctx = Arc::clone(&shared_context);
            // â˜… 2025-12-10 ç»Ÿä¸€æ”¹é€ ï¼šé™„ä»¶ä¸å†é€šè¿‡ request.attachments ä¼ é€’
            let attachments = Vec::new();
            let state_clone = chat_v2_state.clone();

            let future = async move {
                self_ref.execute_single_variant_with_config(
                    ctx_clone,
                    config_id_clone,  // ä¼ é€’ API é…ç½® ID
                    (*options_clone).clone(),
                    (*user_content_clone).clone(),
                    (*session_id_clone).clone(),
                    shared_ctx,
                    attachments,
                ).await
            };

            // ğŸ”§ P1ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ spawn_tracked è¿½è¸ªä»»åŠ¡
            if let Some(ref state) = state_clone {
                state.spawn_tracked(future)
            } else {
                log::warn!("[ChatV2::pipeline] spawn_tracked unavailable, using untracked tokio::spawn for variant task");
                tokio::spawn(future)
            }
        }).collect();

        // ç­‰å¾…æ‰€æœ‰å˜ä½“å®Œæˆ
        let results = join_all(futures).await;

        // å¤„ç†ç»“æœ
        for (i, result) in results.into_iter().enumerate() {
            let (ctx, _) = &variant_contexts[i];
            match result {
                Ok(Ok(())) => {
                    log::info!(
                        "[ChatV2::pipeline] Variant {} completed successfully",
                        ctx.variant_id()
                    );
                }
                Ok(Err(e)) => {
                    log::error!(
                        "[ChatV2::pipeline] Variant {} failed: {}",
                        ctx.variant_id(),
                        e
                    );
                    // é”™è¯¯å·²ç»åœ¨ execute_single_variant_with_config ä¸­å¤„ç†
                }
                Err(e) => {
                    log::error!(
                        "[ChatV2::pipeline] Variant {} task panicked: {}",
                        ctx.variant_id(),
                        e
                    );
                    // æ ‡è®°ä¸ºé”™è¯¯
                    ctx.fail(&format!("Task panicked: {}", e));
                }
            }
        }

        // === 8. ç¡®å®š active_variant_id ===
        let active_variant_id = manager.get_first_success();

        log::info!(
            "[ChatV2::pipeline] Multi-variant execution completed: active_variant={:?}, success={}, error={}",
            active_variant_id,
            manager.success_count(),
            manager.error_count()
        );

        // === 9. æ„å»ºä¸Šä¸‹æ–‡å¿«ç…§ï¼ˆç»Ÿä¸€ä¸Šä¸‹æ–‡æ³¨å…¥ç³»ç»Ÿï¼‰ ===
        let context_snapshot = {
            let mut snapshot = ContextSnapshot::new();

            // 9.1 æ·»åŠ ç”¨æˆ·ä¸Šä¸‹æ–‡å¼•ç”¨
            if let Some(ref user_refs) = request.user_context_refs {
                for send_ref in user_refs {
                    snapshot.add_user_ref(send_ref.to_context_ref());
                }
            }

            // 9.2 ä¸ºæ£€ç´¢ç»“æœåˆ›å»ºèµ„æºï¼ˆå¦‚æœæœ‰ï¼‰
            // æ³¨ï¼šå¤šå˜ä½“æ¨¡å¼ä¸‹æ£€ç´¢ç»“æœå­˜å‚¨åœ¨ shared_context ä¸­
            // è¿™é‡Œæˆ‘ä»¬å°†æ£€ç´¢ç»“æœè½¬æ¢ä¸º retrieval ç±»å‹çš„èµ„æº
            // TODO: å¦‚æœéœ€è¦æ›´ç²¾ç»†çš„æ£€ç´¢èµ„æºç®¡ç†ï¼Œå¯ä»¥åœ¨ execute_shared_retrievals ä¸­ç›´æ¥åˆ›å»ºèµ„æº

            if snapshot.has_refs() {
                log::debug!(
                    "[ChatV2::pipeline] Multi-variant context snapshot: user_refs={}, retrieval_refs={}",
                    snapshot.user_refs.len(),
                    snapshot.retrieval_refs.len()
                );
                Some(snapshot)
            } else {
                None
            }
        };

        // === 10. æŒä¹…åŒ–æ¶ˆæ¯å’Œå˜ä½“ ===
        // æå–çº¯å˜ä½“ä¸Šä¸‹æ–‡åˆ—è¡¨ç”¨äºä¿å­˜
        let contexts_only: Vec<Arc<VariantExecutionContext>> = variant_contexts
            .iter()
            .map(|(ctx, _)| Arc::clone(ctx))
            .collect();
        // â˜… 2025-12-10 ç»Ÿä¸€æ”¹é€ ï¼šé™„ä»¶ä¸å†é€šè¿‡ request.attachments ä¼ é€’
        let empty_attachments: Vec<crate::chat_v2::types::AttachmentInput> = Vec::new();
        self.save_multi_variant_results(
            &session_id,
            &user_message_id,
            &assistant_message_id,
            &user_content,
            &empty_attachments,
            &options,
            &shared_context,
            &contexts_only, // ä¼ å…¥ contexts ä»¥ä¾¿è·å–ç´¯ç§¯çš„å†…å®¹
            active_variant_id.as_deref(),
            context_snapshot, // ğŸ†• ä¼ å…¥ä¸Šä¸‹æ–‡å¿«ç…§
        )
        .await?;

        // === 11. ğŸ”§ P1ä¿®å¤ï¼šæ¸…ç†æ¯ä¸ªå˜ä½“çš„ cancel token ===
        if let Some(ref state) = chat_v2_state {
            for (ctx, _) in &variant_contexts {
                let cancel_key = format!("{}:{}", session_id, ctx.variant_id());
                state.remove_stream(&cancel_key);
            }
            log::debug!(
                "[ChatV2::pipeline] Cleaned up {} variant cancel tokens",
                variant_contexts.len()
            );
        }

        // === 12. å‘å°„ stream_completeï¼ˆå¸¦ token ç»Ÿè®¡ï¼‰ ===
        let duration_ms = start_time.elapsed().as_millis() as u64;
        // å¤šå˜ä½“æ¨¡å¼ä¸‹ Message._meta.usage ä¸º Noneï¼Œæ¯ä¸ªå˜ä½“ç‹¬ç«‹ç»Ÿè®¡
        // TODO: Prompt 9 å®ç°åï¼Œå¯é€‰æ‹©æ€§æ±‡æ€»æ‰€æœ‰å˜ä½“çš„ token ç»Ÿè®¡
        emitter.emit_stream_complete_with_usage(&assistant_message_id, duration_ms, None);

        log::info!(
            "[ChatV2::pipeline] Multi-variant pipeline completed in {}ms",
            duration_ms
        );

        // ğŸ”§ è‡ªåŠ¨ç”Ÿæˆä¼šè¯æ‘˜è¦ï¼ˆå¤šå˜ä½“æ¨¡å¼ï¼‰
        // ä½¿ç”¨ active_variant çš„å†…å®¹æ¥ç”Ÿæˆæ‘˜è¦
        if let Some(active_id) = &active_variant_id {
            if let Some((active_ctx, _)) = variant_contexts
                .iter()
                .find(|(ctx, _)| ctx.variant_id() == active_id.as_str())
            {
                let assistant_content = active_ctx.get_accumulated_content();
                if self
                    .should_generate_summary(&session_id, &user_content, &assistant_content)
                    .await
                {
                    let pipeline = self.clone();
                    let sid = session_id.clone();
                    let emitter_clone = emitter.clone();
                    let user_content_clone = user_content.clone();

                    // ğŸ†• P1ä¿®å¤ï¼šä½¿ç”¨ TaskTracker è¿½è¸ªå¼‚æ­¥ä»»åŠ¡
                    let summary_future = async move {
                        pipeline
                            .generate_summary(
                                &sid,
                                &user_content_clone,
                                &assistant_content,
                                emitter_clone,
                            )
                            .await;
                    };

                    // ğŸ”§ P1ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ spawn_tracked è¿½è¸ªæ‘˜è¦ä»»åŠ¡
                    if let Some(ref state) = chat_v2_state {
                        state.spawn_tracked(summary_future);
                    } else {
                        log::warn!("[ChatV2::pipeline] spawn_tracked unavailable, using untracked tokio::spawn for summary task (multi-variant)");
                        tokio::spawn(summary_future);
                    }
                }
            }
        }

        Ok(assistant_message_id)
    }

    /// æ‰§è¡Œå•ä¸ªå˜ä½“
    ///
    /// åœ¨éš”ç¦»çš„ä¸Šä¸‹æ–‡ä¸­æ‰§è¡Œ LLM è°ƒç”¨ï¼Œæ”¯æŒå·¥å…·é€’å½’ã€‚
    ///
    /// ## å‚æ•°
    /// - `ctx`: å˜ä½“æ‰§è¡Œä¸Šä¸‹æ–‡
    /// - `options`: å‘é€é€‰é¡¹
    /// - `user_content`: ç”¨æˆ·æ¶ˆæ¯å†…å®¹
    /// - `session_id`: ä¼šè¯ ID
    /// - `shared_context`: å…±äº«ä¸Šä¸‹æ–‡ï¼ˆæ£€ç´¢ç»“æœï¼‰
    /// - `attachments`: é™„ä»¶åˆ—è¡¨
    async fn execute_single_variant(
        &self,
        ctx: Arc<super::variant_context::VariantExecutionContext>,
        mut options: SendOptions,
        user_content: String,
        session_id: String,
        shared_context: Arc<SharedContext>,
        attachments: Vec<AttachmentInput>,
    ) -> ChatV2Result<()> {
        // ä½¿ç”¨å˜ä½“çš„æ¨¡å‹ ID
        options.model_id = Some(ctx.model_id().to_string());
        options.model2_override_id = Some(ctx.model_id().to_string());

        // å¼€å§‹æµå¼ç”Ÿæˆ
        ctx.start_streaming();

        // æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
        if ctx.is_cancelled() {
            ctx.cancel();
            return Ok(());
        }

        // æ„å»ºç³»ç»Ÿæç¤ºï¼ˆåŒ…å«å…±äº«çš„æ£€ç´¢ç»“æœï¼‰
        let system_prompt = self
            .build_system_prompt_with_shared_context(&options, &shared_context)
            .await;

        // åŠ è½½èŠå¤©å†å²
        let mut chat_history = self.load_variant_chat_history(&session_id).await?;
        // ğŸ†• 2026-02-22: ä¸ºå·²æ¿€æ´»çš„é»˜è®¤æŠ€èƒ½è‡ªåŠ¨æ³¨å…¥åˆæˆ load_skills å·¥å…·äº¤äº’
        inject_synthetic_load_skills(&mut chat_history, &options);

        // æ„å»ºå½“å‰ç”¨æˆ·æ¶ˆæ¯
        let current_user_message = self.build_variant_user_message(&user_content, &attachments);

        // åˆ›å»º LLM é€‚é…å™¨ï¼ˆä½¿ç”¨å˜ä½“çš„äº‹ä»¶å‘å°„ï¼‰
        let enable_thinking = options.enable_thinking.unwrap_or(true);
        let emitter = Arc::new(VariantLLMAdapter::new(Arc::clone(&ctx), enable_thinking));

        // æ³¨å†Œ LLM æµå¼å›è°ƒ hooks
        // ğŸ”§ P0ä¿®å¤ï¼šæ¯ä¸ªå˜ä½“ä½¿ç”¨å”¯ä¸€çš„ hook é”®ï¼Œé¿å…å¹¶è¡Œæ‰§è¡Œæ—¶äº’ç›¸è¦†ç›–
        // å‰ç«¯ä»ç„¶ç›‘å¬ chat_v2_event_{session_id}ï¼Œå˜ä½“ ID é€šè¿‡ VariantLLMAdapter åœ¨äº‹ä»¶ payload ä¸­æºå¸¦
        let stream_event = format!("chat_v2_event_{}_{}", session_id, ctx.variant_id());
        self.llm_manager
            .register_stream_hooks(&stream_event, emitter.clone())
            .await;

        // æ„å»ºæ¶ˆæ¯å†å²
        let mut messages = chat_history;
        messages.push(current_user_message);

        // æ„å»º LLM ä¸Šä¸‹æ–‡
        let mut llm_context: std::collections::HashMap<String, Value> =
            std::collections::HashMap::new();
        if let Some(ref rag_sources) = shared_context.rag_sources {
            llm_context.insert(
                "prefetched_rag_sources".into(),
                serde_json::to_value(rag_sources).unwrap_or(Value::Null),
            );
        }
        if let Some(ref memory_sources) = shared_context.memory_sources {
            llm_context.insert(
                "prefetched_memory_sources".into(),
                serde_json::to_value(memory_sources).unwrap_or(Value::Null),
            );
        }
        if let Some(ref graph_sources) = shared_context.graph_sources {
            llm_context.insert(
                "prefetched_graph_sources".into(),
                serde_json::to_value(graph_sources).unwrap_or(Value::Null),
            );
        }
        if let Some(ref web_sources) = shared_context.web_search_sources {
            llm_context.insert(
                "prefetched_web_search_sources".into(),
                serde_json::to_value(web_sources).unwrap_or(Value::Null),
            );
        }

        // ğŸ†• å›¾ç‰‡å‹ç¼©ç­–ç•¥ï¼šä» options è·å–æˆ–ä½¿ç”¨é»˜è®¤å€¼
        // å¦‚æœ options.vision_quality æœªè®¾ç½®ï¼Œé»˜è®¤ä½¿ç”¨ "auto" è®© file_manager æ ¹æ®å›¾ç‰‡å¤§å°è‡ªåŠ¨é€‰æ‹©
        let vq = options.vision_quality.as_deref().unwrap_or("auto");
        llm_context.insert("vision_quality".into(), Value::String(vq.to_string()));

        // ğŸ”§ P1ä¿®å¤ï¼šå°† context_limit ä½œä¸º max_input_tokens_override ä¼ é€’ç»™ LLM
        let max_input_tokens_override = options.context_limit.map(|v| v as usize);

        // ğŸ”§ 2025-01-27 å¯¹é½å•å˜ä½“ï¼šå¤šå˜ä½“æ¨¡å¼ç°åœ¨æ”¯æŒå·¥å…·é“¾ï¼Œä½¿ç”¨ options ä¸­çš„é…ç½®
        // æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·å¯ç”¨ï¼ˆä¸ execute_single_variant_with_config ä¿æŒä¸€è‡´ï¼‰
        let has_tools = options
            .mcp_tool_schemas
            .as_ref()
            .map(|s| !s.is_empty())
            .unwrap_or(false);
        let disable_tools = options.disable_tools.unwrap_or(false) || !has_tools;

        // ğŸ”§ 2025-01-27 å¯¹é½å•å˜ä½“ï¼šæ³¨å…¥å·¥å…· schemas åˆ° LLM ä¸Šä¸‹æ–‡
        // æ³¨æ„ï¼šexecute_single_variant ç”¨äºå•æ¬¡å˜ä½“é‡è¯•ï¼Œä¸æ”¯æŒå·¥å…·é€’å½’è°ƒç”¨
        // å¦‚éœ€å®Œæ•´çš„å·¥å…·è°ƒç”¨å¾ªç¯ï¼Œè¯·ä½¿ç”¨ execute_single_variant_with_config
        if !disable_tools {
            if let Some(ref tool_schemas) = options.mcp_tool_schemas {
                let mcp_tool_values: Vec<Value> = tool_schemas
                    .iter()
                    .map(|tool| {
                        let tool_name = if tool.name.starts_with(BUILTIN_NAMESPACE) {
                            tool.name.clone()
                        } else {
                            format!("mcp_{}", tool.name)
                        };
                        json!({
                            "type": "function",
                            "function": {
                                "name": tool_name,
                                "description": tool.description.clone().unwrap_or_default(),
                                "parameters": tool.input_schema.clone().unwrap_or(json!({}))
                            }
                        })
                    })
                    .collect();

                if !mcp_tool_values.is_empty() {
                    llm_context.insert("tools".into(), Value::Array(mcp_tool_values.clone()));
                    log::info!(
                        "[ChatV2::VariantPipeline] execute_single_variant: variant={} injected {} tools",
                        ctx.variant_id(),
                        mcp_tool_values.len()
                    );
                }
            }
        }

        // è°ƒç”¨ LLM
        // ğŸ”§ P1ä¿®å¤ï¼šæ·»åŠ  Pipeline å±‚è¶…æ—¶ä¿æŠ¤
        let llm_future = self.llm_manager.call_unified_model_2_stream(
            &llm_context,
            &messages,
            "",
            true,
            enable_thinking,
            Some("chat_v2_variant"),
            ctx.emitter().window(),
            &stream_event,
            None,
            disable_tools,
            max_input_tokens_override,
            options.model_id.clone(),
            options.temperature,
            Some(system_prompt),
            options.top_p,
            options.frequency_penalty,
            options.presence_penalty,
            options.max_tokens,
        );

        let call_result =
            match timeout(Duration::from_secs(LLM_STREAM_TIMEOUT_SECS), llm_future).await {
                Ok(result) => result,
                Err(_) => {
                    log::error!(
                        "[ChatV2::VariantPipeline] LLM stream call timeout after {}s, variant={}",
                        LLM_STREAM_TIMEOUT_SECS,
                        ctx.variant_id()
                    );
                    self.llm_manager
                        .unregister_stream_hooks(&stream_event)
                        .await;
                    ctx.fail(&format!(
                        "LLM stream call timed out after {}s",
                        LLM_STREAM_TIMEOUT_SECS
                    ));
                    return Err(ChatV2Error::Timeout(format!(
                        "LLM stream call timed out after {}s",
                        LLM_STREAM_TIMEOUT_SECS
                    )));
                }
            };

        // æ³¨é”€ hooks
        self.llm_manager
            .unregister_stream_hooks(&stream_event)
            .await;

        // å¤„ç†ç»“æœ
        match call_result {
            Ok(output) => {
                if output.cancelled {
                    ctx.cancel();
                } else {
                    ctx.complete();
                }
                Ok(())
            }
            Err(e) => {
                ctx.fail(&e.to_string());
                Err(ChatV2Error::Llm(e.to_string()))
            }
        }
    }

    async fn execute_single_variant_with_config(
        &self,
        ctx: Arc<super::variant_context::VariantExecutionContext>,
        config_id: String,
        mut options: SendOptions,
        user_content: String,
        session_id: String,
        shared_context: Arc<SharedContext>,
        attachments: Vec<AttachmentInput>,
    ) -> ChatV2Result<()> {
        const MAX_TOOL_ROUNDS: u32 = 10;

        options.model_id = Some(config_id.clone());
        options.model2_override_id = Some(config_id.clone());

        ctx.start_streaming();

        if ctx.is_cancelled() {
            ctx.cancel();
            return Ok(());
        }

        let system_prompt = self
            .build_system_prompt_with_shared_context(&options, &shared_context)
            .await;
        let mut chat_history = self.load_variant_chat_history(&session_id).await?;
        // ğŸ†• 2026-02-22: ä¸ºå·²æ¿€æ´»çš„é»˜è®¤æŠ€èƒ½è‡ªåŠ¨æ³¨å…¥åˆæˆ load_skills å·¥å…·äº¤äº’
        inject_synthetic_load_skills(&mut chat_history, &options);
        let current_user_message = self.build_variant_user_message(&user_content, &attachments);

        let enable_thinking = options.enable_thinking.unwrap_or(true);
        let max_input_tokens_override = options.context_limit.map(|v| v as usize);
        let has_tools = options
            .mcp_tool_schemas
            .as_ref()
            .map(|s| !s.is_empty())
            .unwrap_or(false);
        let disable_tools = options.disable_tools.unwrap_or(false) || !has_tools;

        let mut messages = chat_history;
        messages.push(current_user_message);

        let adapter = Arc::new(VariantLLMAdapter::new(Arc::clone(&ctx), enable_thinking));
        let stream_event = format!("chat_v2_event_{}_{}", session_id, ctx.variant_id());
        self.llm_manager
            .register_stream_hooks(&stream_event, adapter.clone())
            .await;

        let mut llm_context: std::collections::HashMap<String, Value> =
            std::collections::HashMap::new();
        if let Some(ref rag_sources) = shared_context.rag_sources {
            llm_context.insert(
                "prefetched_rag_sources".into(),
                serde_json::to_value(rag_sources).unwrap_or(Value::Null),
            );
        }
        if let Some(ref memory_sources) = shared_context.memory_sources {
            llm_context.insert(
                "prefetched_memory_sources".into(),
                serde_json::to_value(memory_sources).unwrap_or(Value::Null),
            );
        }
        if let Some(ref graph_sources) = shared_context.graph_sources {
            llm_context.insert(
                "prefetched_graph_sources".into(),
                serde_json::to_value(graph_sources).unwrap_or(Value::Null),
            );
        }
        if let Some(ref web_sources) = shared_context.web_search_sources {
            llm_context.insert(
                "prefetched_web_search_sources".into(),
                serde_json::to_value(web_sources).unwrap_or(Value::Null),
            );
        }

        // ğŸ†• å›¾ç‰‡å‹ç¼©ç­–ç•¥ï¼šä» options è·å–æˆ–ä½¿ç”¨é»˜è®¤å€¼
        let vq = options.vision_quality.as_deref().unwrap_or("auto");
        llm_context.insert("vision_quality".into(), Value::String(vq.to_string()));

        if !disable_tools {
            if let Some(ref tool_schemas) = options.mcp_tool_schemas {
                let mcp_tool_values: Vec<Value> = tool_schemas
                    .iter()
                    .map(|tool| {
                        let tool_name = if tool.name.starts_with(BUILTIN_NAMESPACE) {
                            tool.name.clone()
                        } else {
                            format!("mcp_{}", tool.name)
                        };
                        json!({
                            "type": "function",
                            "function": {
                                "name": tool_name,
                                "description": tool.description.clone().unwrap_or_default(),
                                "parameters": tool.input_schema.clone().unwrap_or(json!({}))
                            }
                        })
                    })
                    .collect();

                if !mcp_tool_values.is_empty() {
                    llm_context.insert("tools".into(), Value::Array(mcp_tool_values.clone()));
                    log::info!(
                        "[ChatV2::VariantPipeline] variant={} injected {} tools",
                        ctx.variant_id(),
                        mcp_tool_values.len()
                    );
                }
            }
        }

        let emitter_arc = ctx.emitter_arc();
        let canvas_note_id = options.canvas_note_id.clone();
        let skill_allowed_tools = options.skill_allowed_tools.clone();
        let skill_contents = options.skill_contents.clone();
        let active_skill_ids = options.active_skill_ids.clone();
        let variant_session_key = format!("{}:{}", session_id, ctx.variant_id());

        let mut tool_round = 0u32;
        loop {
            if ctx.is_cancelled() {
                ctx.cancel();
                break;
            }

            // ğŸ”§ P1ä¿®å¤ï¼šæ·»åŠ  Pipeline å±‚è¶…æ—¶ä¿æŠ¤
            let llm_future = self.llm_manager.call_unified_model_2_stream(
                &llm_context,
                &messages,
                "",
                true,
                enable_thinking,
                Some("chat_v2_variant"),
                ctx.emitter().window(),
                &stream_event,
                None,
                disable_tools,
                max_input_tokens_override,
                options.model_id.clone(),
                options.temperature,
                Some(system_prompt.clone()),
                options.top_p,
                options.frequency_penalty,
                options.presence_penalty,
                options.max_tokens,
            );

            // ä½¿ç”¨ tokio::select! æ”¯æŒå–æ¶ˆï¼ˆä¸å•å˜ä½“ pipeline å¯¹é½ï¼‰
            let call_result = tokio::select! {
                result = timeout(
                    Duration::from_secs(LLM_STREAM_TIMEOUT_SECS),
                    llm_future,
                ) => {
                    match result {
                        Ok(r) => Some(r),
                        Err(_) => {
                            log::error!(
                                "[ChatV2::VariantPipeline] LLM stream call timeout after {}s, variant={}, round={}",
                                LLM_STREAM_TIMEOUT_SECS,
                                ctx.variant_id(),
                                tool_round
                            );
                            self.llm_manager
                                .unregister_stream_hooks(&stream_event)
                                .await;
                            ctx.fail(&format!(
                                "LLM stream call timed out after {}s",
                                LLM_STREAM_TIMEOUT_SECS
                            ));
                            return Err(ChatV2Error::Timeout(format!(
                                "LLM stream call timed out after {}s",
                                LLM_STREAM_TIMEOUT_SECS
                            )));
                        }
                    }
                }
                _ = ctx.cancel_token().cancelled() => {
                    log::info!(
                        "[ChatV2::VariantPipeline] LLM call cancelled via token, variant={}, round={}",
                        ctx.variant_id(),
                        tool_round
                    );
                    // åŒæ—¶é€šçŸ¥ LLM å±‚åœæ­¢ HTTP æµ
                    self.llm_manager.request_cancel_stream(&stream_event).await;
                    None
                }
            };

            match call_result {
                None => {
                    // cancel_token è§¦å‘çš„å–æ¶ˆ
                    ctx.cancel();
                    break;
                }
                Some(Ok(output)) => {
                    if output.cancelled {
                        ctx.cancel();
                        break;
                    }
                }
                Some(Err(e)) => {
                    self.llm_manager
                        .unregister_stream_hooks(&stream_event)
                        .await;
                    ctx.fail(&e.to_string());
                    return Err(ChatV2Error::Llm(e.to_string()));
                }
            }

            let tool_calls = adapter.take_tool_calls();
            if tool_calls.is_empty() {
                adapter.finalize_all();
                ctx.complete();
                break;
            }

            log::info!(
                "[ChatV2::VariantPipeline] variant={} round={} has {} tool calls",
                ctx.variant_id(),
                tool_round,
                tool_calls.len()
            );

            let current_reasoning = adapter.get_accumulated_reasoning();
            adapter.finalize_all();
            ctx.set_pending_reasoning(current_reasoning.clone());

            // ğŸ†• å–æ¶ˆæ”¯æŒï¼šä¼ é€’å–æ¶ˆä»¤ç‰Œç»™å·¥å…·æ‰§è¡Œå™¨
            let cancel_token = Some(ctx.cancel_token());
            let rag_top_k = options.rag_top_k;
            let rag_enable_reranking = options.rag_enable_reranking;
            let tool_results = self
                .execute_tool_calls(
                    &tool_calls,
                    &emitter_arc,
                    &variant_session_key,
                    ctx.message_id(),
                    &canvas_note_id,
                    &skill_allowed_tools,
                    &skill_contents,
                    &active_skill_ids,
                    cancel_token,
                    rag_top_k,
                    rag_enable_reranking,
                )
                .await?;

            let success_count = tool_results.iter().filter(|r| r.success).count();
            log::info!(
                "[ChatV2::VariantPipeline] variant={} tool execution: {}/{} succeeded",
                ctx.variant_id(),
                success_count,
                tool_results.len()
            );

            for tc in &tool_calls {
                let tool_call = crate::models::ToolCall {
                    id: tc.id.clone(),
                    tool_name: tc.name.clone(),
                    args_json: tc.arguments.clone(),
                };
                messages.push(LegacyChatMessage {
                    role: "assistant".to_string(),
                    content: String::new(),
                    timestamp: chrono::Utc::now(),
                    thinking_content: current_reasoning.clone(),
                    thought_signature: None,
                    rag_sources: None,
                    memory_sources: None,
                    graph_sources: None,
                    web_search_sources: None,
                    image_paths: None,
                    image_base64: None,
                    doc_attachments: None,
                    multimodal_content: None,
                    tool_call: Some(tool_call),
                    tool_result: None,
                    overrides: None,
                    relations: None,
                    persistent_stable_id: None,
                    metadata: None,
                });
            }

            for result in &tool_results {
                let result_content = if result.success {
                    serde_json::to_string(&result.output).unwrap_or_else(|_| "{}".to_string())
                } else {
                    format!(
                        "Error: {}",
                        result.error.as_deref().unwrap_or("Unknown error")
                    )
                };

                let tool_result = crate::models::ToolResult {
                    call_id: result.tool_call_id.clone().unwrap_or_default(),
                    ok: result.success,
                    error: result.error.clone(),
                    error_details: None,
                    data_json: Some(result.output.clone()),
                    usage: None,
                    citations: None,
                };
                messages.push(LegacyChatMessage {
                    role: "tool".to_string(),
                    content: result_content,
                    timestamp: chrono::Utc::now(),
                    thinking_content: None,
                    thought_signature: None,
                    rag_sources: None,
                    memory_sources: None,
                    graph_sources: None,
                    web_search_sources: None,
                    image_paths: None,
                    image_base64: None,
                    doc_attachments: None,
                    multimodal_content: None,
                    tool_call: None,
                    tool_result: Some(tool_result),
                    overrides: None,
                    relations: None,
                    persistent_stable_id: None,
                    metadata: None,
                });

                ctx.add_tool_result(result.clone());
            }

            let task_completed = tool_results.iter().any(|r| {
                r.output
                    .get("task_completed")
                    .and_then(|v| v.as_bool())
                    .unwrap_or(false)
            });
            if task_completed {
                log::info!(
                    "[ChatV2::VariantPipeline] variant={} task_completed detected, stopping",
                    ctx.variant_id()
                );
                ctx.complete();
                break;
            }

            tool_round += 1;
            ctx.increment_tool_round();

            if tool_round >= MAX_TOOL_ROUNDS {
                log::warn!(
                    "[ChatV2::VariantPipeline] variant={} reached max tool rounds ({})",
                    ctx.variant_id(),
                    MAX_TOOL_ROUNDS
                );
                ctx.complete();
                break;
            }

            adapter.reset_for_new_round();
        }

        self.llm_manager
            .unregister_stream_hooks(&stream_event)
            .await;
        Ok(())
    }

    /// å…±äº«æ£€ç´¢é˜¶æ®µï¼ˆå·²åºŸå¼ƒé¢„è°ƒç”¨æ¨¡å¼ï¼‰
    ///
    /// ğŸ”§ 2026-01-11 é‡æ„ï¼šå½»åº•ç§»é™¤é¢„è°ƒç”¨æ£€ç´¢ï¼Œå®Œå…¨é‡‡ç”¨å·¥å…·åŒ–æ¨¡å¼
    ///
    /// åŸé¢„è°ƒç”¨æ¨¡å¼ï¼ˆå·²åºŸå¼ƒï¼‰ï¼š
    /// - åœ¨å¤šå˜ä½“ LLM è°ƒç”¨å‰æ‰§è¡Œ RAG/å›¾è°±/è®°å¿†/ç½‘ç»œæœç´¢
    /// - ç»“æœæ³¨å…¥åˆ°å…±äº«çš„ç³»ç»Ÿæç¤ºä¸­
    ///
    /// æ–°å·¥å…·åŒ–æ¨¡å¼ï¼ˆå½“å‰ï¼‰ï¼š
    /// - æ£€ç´¢å·¥å…·ä½œä¸º MCP å·¥å…·æ³¨å…¥åˆ° LLM
    /// - æ¯ä¸ªå˜ä½“çš„ LLM æ ¹æ®ç”¨æˆ·é—®é¢˜ä¸»åŠ¨å†³å®šæ˜¯å¦è°ƒç”¨æ£€ç´¢å·¥å…·
    /// - å¤šå˜ä½“æ¨¡å¼ä¸‹ï¼Œæ¯ä¸ªå˜ä½“ç‹¬ç«‹è°ƒç”¨æ£€ç´¢ï¼ˆæŒ‰éœ€ï¼‰
    ///
    /// ## å‚æ•°
    /// - `request`: å‘é€æ¶ˆæ¯è¯·æ±‚
    /// - `_emitter`: äº‹ä»¶å‘å°„å™¨ï¼ˆä¸å†ä½¿ç”¨ï¼‰
    /// - `_message_id`: æ¶ˆæ¯ IDï¼ˆä¸å†ä½¿ç”¨ï¼‰
    ///
    /// ## è¿”å›
    /// ç©ºçš„ SharedContextï¼ˆå·¥å…·åŒ–æ¨¡å¼ä¸‹ç”± LLM æŒ‰éœ€è°ƒç”¨æ£€ç´¢ï¼‰
    #[allow(unused_variables)]
    async fn execute_shared_retrievals(
        &self,
        request: &SendMessageRequest,
        _emitter: &Arc<ChatV2EventEmitter>,
        _message_id: &str,
    ) -> ChatV2Result<SharedContext> {
        // ğŸ”§ å·¥å…·åŒ–æ¨¡å¼ï¼šè·³è¿‡æ‰€æœ‰é¢„è°ƒç”¨æ£€ç´¢
        // å¤šå˜ä½“æ¨¡å¼ä¸‹ï¼Œæ¯ä¸ªå˜ä½“çš„ LLM å¯ç‹¬ç«‹é€šè¿‡ tool_calls è°ƒç”¨å†…ç½®æ£€ç´¢å·¥å…·
        log::info!(
            "[ChatV2::pipeline] Tool-based retrieval mode (multi-variant): skipping shared pre-call retrievals for session={}",
            request.session_id
        );
        Ok(SharedContext::default())
    }

    /// æ„å»ºå¸¦å…±äº«ä¸Šä¸‹æ–‡çš„ç³»ç»Ÿæç¤º
    ///
    /// ä½¿ç”¨ prompt_builder æ¨¡å—ç»Ÿä¸€æ ¼å¼åŒ–ï¼Œç”¨äºå¤šå˜ä½“å¹¶è¡Œæ‰§è¡Œåœºæ™¯ï¼Œ
    /// å…±äº«æ£€ç´¢ç»“æœæ³¨å…¥åˆ°æ‰€æœ‰å˜ä½“çš„ system prompt ä¸­ã€‚
    /// å¦‚æœæœ‰ Canvas ç¬”è®°ï¼Œä¹Ÿä¼šä¸€å¹¶æ³¨å…¥ã€‚
    async fn build_system_prompt_with_shared_context(
        &self,
        options: &SendOptions,
        shared_context: &SharedContext,
    ) -> String {
        // æ„å»º Canvas ç¬”è®°ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        let canvas_note = self.build_canvas_note_info_from_options(options).await;
        prompt_builder::build_system_prompt_with_shared_context(
            options,
            shared_context,
            canvas_note,
        )
    }

    /// æ ¹æ® SendOptions æ„å»º Canvas ç¬”è®°ä¿¡æ¯
    async fn build_canvas_note_info_from_options(
        &self,
        options: &SendOptions,
    ) -> Option<prompt_builder::CanvasNoteInfo> {
        let note_id = options.canvas_note_id.as_ref()?;
        let notes_mgr = self.notes_manager.as_ref()?;
        match notes_mgr.get_note(note_id) {
            Ok(note) => {
                let word_count = note.content_md.chars().count();
                log::info!(
                    "[ChatV2::pipeline] Canvas mode (variant): loaded note '{}' ({} chars, is_long={})",
                    note.title,
                    word_count,
                    word_count >= 3000
                );
                Some(prompt_builder::CanvasNoteInfo::new(
                    note_id.clone(),
                    note.title,
                    note.content_md,
                ))
            }
            Err(e) => {
                log::warn!(
                    "[ChatV2::pipeline] Canvas mode (variant): failed to read note {}: {}",
                    note_id,
                    e
                );
                None
            }
        }
    }

    /// åŠ è½½å˜ä½“çš„èŠå¤©å†å²ï¼ˆV2 å¢å¼ºç‰ˆï¼‰
    ///
    /// å¯¹é½å•å˜ä½“ `load_chat_history()` çš„å®Œæ•´èƒ½åŠ›ï¼š
    /// - ä½¿ç”¨ DEFAULT_MAX_HISTORY_MESSAGES é™åˆ¶æ¶ˆæ¯æ•°
    /// - æå–æ‰€æœ‰ content å—å¹¶æ‹¼æ¥ï¼ˆä¸åªæ˜¯ç¬¬ä¸€ä¸ªï¼‰
    /// - æå– thinking å—å†…å®¹
    /// - æå– mcp_tool å—çš„å·¥å…·è°ƒç”¨ä¿¡æ¯
    /// - è§£æ context_snapshotï¼ˆå¦‚æœæœ‰ vfs_db è¿æ¥ï¼‰
    /// - ä»é™„ä»¶ä¸­æå–å›¾ç‰‡ base64 å’Œæ–‡æ¡£é™„ä»¶
    async fn load_variant_chat_history(
        &self,
        session_id: &str,
    ) -> ChatV2Result<Vec<LegacyChatMessage>> {
        log::debug!(
            "[ChatV2::pipeline] Loading variant chat history for session={}",
            session_id
        );

        let conn = self.db.get_conn_safe()?;

        // ğŸ†• è·å– VFS æ•°æ®åº“è¿æ¥ï¼ˆç”¨äºè§£æå†å²æ¶ˆæ¯ä¸­çš„ context_snapshotï¼‰
        let vfs_conn_opt = self.vfs_db.as_ref().and_then(|vfs_db| {
            match vfs_db.get_conn_safe() {
                Ok(vfs_conn) => Some(vfs_conn),
                Err(e) => {
                    log::warn!("[ChatV2::pipeline] Failed to get vfs.db connection for variant history context_snapshot: {}", e);
                    None
                }
            }
        });
        let vfs_blobs_dir = self
            .vfs_db
            .as_ref()
            .map(|vfs_db| vfs_db.blobs_dir().to_path_buf());

        let messages = ChatV2Repo::get_session_messages_with_conn(&conn, session_id)?;

        if messages.is_empty() {
            log::debug!(
                "[ChatV2::pipeline] No variant chat history found for session={}",
                session_id
            );
            return Ok(Vec::new());
        }

        // ğŸ”§ ä½¿ç”¨å›ºå®šçš„æ¶ˆæ¯æ¡æ•°é™åˆ¶ï¼ˆå¯¹é½å•å˜ä½“ï¼‰
        let max_messages = DEFAULT_MAX_HISTORY_MESSAGES;
        let messages_to_load: Vec<_> = if messages.len() > max_messages {
            // å–æœ€æ–°çš„ max_messages æ¡æ¶ˆæ¯
            messages
                .into_iter()
                .rev()
                .take(max_messages)
                .rev()
                .collect()
        } else {
            messages
        };

        log::debug!(
            "[ChatV2::pipeline] Loading {} variant messages (max_messages={})",
            messages_to_load.len(),
            max_messages
        );

        let mut chat_history = Vec::new();
        for message in messages_to_load {
            let blocks = ChatV2Repo::get_message_blocks_with_conn(&conn, &message.id)?;

            // ğŸ”§ æå–æ‰€æœ‰ content ç±»å‹å—çš„å†…å®¹å¹¶æ‹¼æ¥ï¼ˆä¸åªæ˜¯ç¬¬ä¸€ä¸ªï¼‰
            let content: String = blocks
                .iter()
                .filter(|b| b.block_type == block_types::CONTENT)
                .filter_map(|b| b.content.as_ref())
                .cloned()
                .collect::<Vec<_>>()
                .join("");

            // ğŸ†• æå– thinking ç±»å‹å—çš„å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
            let thinking_content: Option<String> = {
                let thinking: String = blocks
                    .iter()
                    .filter(|b| b.block_type == block_types::THINKING)
                    .filter_map(|b| b.content.as_ref())
                    .cloned()
                    .collect::<Vec<_>>()
                    .join("");
                if thinking.is_empty() {
                    None
                } else {
                    Some(thinking)
                }
            };

            // ğŸ†• æå– mcp_tool ç±»å‹å—çš„å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼ˆæŒ‰ block_index æ’åºï¼‰
            let mut tool_blocks: Vec<_> = blocks
                .iter()
                .filter(|b| b.block_type == block_types::MCP_TOOL)
                .collect();
            tool_blocks.sort_by_key(|b| b.block_index);

            // ğŸ†• å¯¹äºç”¨æˆ·æ¶ˆæ¯ï¼Œè§£æ context_snapshot.user_refs å¹¶å°†å†…å®¹è¿½åŠ åˆ° content
            let (content, vfs_image_base64) = if message.role == MessageRole::User {
                if let (Some(ref vfs_conn), Some(ref blobs_dir)) = (&vfs_conn_opt, &vfs_blobs_dir) {
                    self.resolve_history_context_snapshot_v2(
                        &content,
                        &message,
                        &**vfs_conn,
                        blobs_dir,
                    )
                } else {
                    (content, Vec::new())
                }
            } else {
                (content, Vec::new())
            };

            let role = match message.role {
                MessageRole::User => "user",
                MessageRole::Assistant => "assistant",
            };

            // ğŸ†• å¦‚æœæ˜¯ assistant æ¶ˆæ¯ä¸”æœ‰å·¥å…·è°ƒç”¨ï¼Œå…ˆæ·»åŠ å·¥å…·è°ƒç”¨æ¶ˆæ¯
            if role == "assistant" && !tool_blocks.is_empty() {
                for (idx, tool_block) in tool_blocks.iter().enumerate() {
                    // ç”Ÿæˆ tool_call_idï¼ˆä½¿ç”¨å— ID æˆ–ç”Ÿæˆæ–°çš„ï¼‰
                    let tool_call_id = format!("tc_{}", tool_block.id.replace("blk_", ""));

                    // æå–å·¥å…·åç§°å’Œè¾“å…¥
                    let tool_name = tool_block.tool_name.clone().unwrap_or_default();
                    let tool_input = tool_block
                        .tool_input
                        .clone()
                        .unwrap_or(serde_json::Value::Null);
                    let tool_output = tool_block
                        .tool_output
                        .clone()
                        .unwrap_or(serde_json::Value::Null);
                    let tool_success = tool_block.status == block_status::SUCCESS;
                    let tool_error = tool_block.error.clone();

                    // 1. æ·»åŠ  assistant æ¶ˆæ¯ï¼ˆåŒ…å« tool_callï¼‰
                    let tool_call = crate::models::ToolCall {
                        id: tool_call_id.clone(),
                        tool_name: tool_name.clone(),
                        args_json: tool_input,
                    };
                    let assistant_tool_msg = LegacyChatMessage {
                        role: "assistant".to_string(),
                        content: String::new(),
                        timestamp: chrono::Utc::now(),
                        thinking_content: None,
                        thought_signature: None,
                        rag_sources: None,
                        memory_sources: None,
                        graph_sources: None,
                        web_search_sources: None,
                        image_paths: None,
                        image_base64: None,
                        doc_attachments: None,
                        multimodal_content: None,
                        tool_call: Some(tool_call),
                        tool_result: None,
                        overrides: None,
                        relations: None,
                        persistent_stable_id: None,
                        metadata: None,
                    };
                    chat_history.push(assistant_tool_msg);

                    // 2. æ·»åŠ  tool æ¶ˆæ¯ï¼ˆåŒ…å« tool_resultï¼‰
                    let tool_result = crate::models::ToolResult {
                        call_id: tool_call_id,
                        ok: tool_success,
                        error: tool_error,
                        error_details: None,
                        data_json: Some(tool_output.clone()),
                        usage: None,
                        citations: None,
                    };
                    let tool_msg = LegacyChatMessage {
                        role: "tool".to_string(),
                        content: serde_json::to_string(&tool_output).unwrap_or_default(),
                        timestamp: chrono::Utc::now(),
                        thinking_content: None,
                        thought_signature: None,
                        rag_sources: None,
                        memory_sources: None,
                        graph_sources: None,
                        web_search_sources: None,
                        image_paths: None,
                        image_base64: None,
                        doc_attachments: None,
                        multimodal_content: None,
                        tool_call: None,
                        tool_result: Some(tool_result),
                        overrides: None,
                        relations: None,
                        persistent_stable_id: None,
                        metadata: None,
                    };
                    chat_history.push(tool_msg);

                    log::debug!(
                        "[ChatV2::pipeline] Loaded variant tool call from history: tool={}, block_id={}, index={}",
                        tool_name,
                        tool_block.id,
                        idx
                    );
                }
            }

            // è·³è¿‡ç©ºå†…å®¹æ¶ˆæ¯ï¼ˆä½†å·¥å…·è°ƒç”¨æ¶ˆæ¯å·²ç»æ·»åŠ ï¼‰
            if content.is_empty() {
                continue;
            }

            // ğŸ†• ä»é™„ä»¶ä¸­æå–å›¾ç‰‡ base64ï¼ˆä»…ç”¨æˆ·æ¶ˆæ¯æœ‰é™„ä»¶ï¼‰
            // åˆå¹¶æ—§é™„ä»¶å›¾ç‰‡å’Œ VFS å›¾ç‰‡
            let mut all_images: Vec<String> = message
                .attachments
                .as_ref()
                .map(|attachments| {
                    attachments
                        .iter()
                        .filter(|a| a.r#type == "image")
                        .filter_map(|a| {
                            // preview_url æ ¼å¼ä¸º "data:image/xxx;base64,{base64_content}"
                            a.preview_url
                                .as_ref()
                                .and_then(|url| url.split(',').nth(1).map(|s| s.to_string()))
                        })
                        .collect::<Vec<_>>()
                })
                .unwrap_or_default();

            // è¿½åŠ ä» VFS context_snapshot è§£æçš„å›¾ç‰‡
            all_images.extend(vfs_image_base64);

            let image_base64: Option<Vec<String>> = if all_images.is_empty() {
                None
            } else {
                Some(all_images)
            };

            // ğŸ†• ä»é™„ä»¶ä¸­æå–æ–‡æ¡£é™„ä»¶ï¼ˆåŒæ—¶æ”¯æŒæ–‡æœ¬å’ŒäºŒè¿›åˆ¶æ–‡æ¡£ï¼‰
            let doc_attachments: Option<Vec<crate::models::DocumentAttachment>> = message.attachments
                .as_ref()
                .map(|attachments| {
                    attachments.iter()
                        .filter(|a| a.r#type == "document")
                        .map(|a| {
                            // åˆ¤æ–­æ˜¯å¦ä¸ºæ–‡æœ¬ç±»å‹
                            let is_text_type = a.mime_type.starts_with("text/") ||
                                               a.mime_type == "application/json" ||
                                               a.mime_type == "application/xml" ||
                                               a.mime_type == "application/javascript";

                            let mut text_content: Option<String> = None;
                            let mut base64_content: Option<String> = None;

                            // ä» preview_url æå–å†…å®¹
                            if let Some(ref url) = a.preview_url {
                                if url.starts_with("data:") {
                                    if let Some(data_part) = url.split(',').nth(1) {
                                        if is_text_type {
                                            // æ–‡æœ¬ç±»å‹ï¼šè§£ç  base64 ä¸ºæ–‡æœ¬
                                            use base64::Engine;
                                            text_content = base64::engine::general_purpose::STANDARD
                                                .decode(data_part)
                                                .ok()
                                                .and_then(|bytes| String::from_utf8(bytes).ok());
                                        } else {
                                            // äºŒè¿›åˆ¶ç±»å‹ï¼ˆå¦‚ docx/PDFï¼‰ï¼šå…ˆä¿å­˜ base64
                                            base64_content = Some(data_part.to_string());

                                            // å°è¯•ä½¿ç”¨ DocumentParser è§£æäºŒè¿›åˆ¶æ–‡æ¡£
                                            let parser = crate::document_parser::DocumentParser::new();
                                            match parser.extract_text_from_base64(&a.name, data_part) {
                                                Ok(text) => {
                                                    log::debug!("[ChatV2::pipeline] Extracted {} chars from variant history document: {}", text.len(), a.name);
                                                    text_content = Some(text);
                                                }
                                                Err(e) => {
                                                    log::debug!("[ChatV2::pipeline] Could not parse variant history document {}: {}", a.name, e);
                                                }
                                            }
                                        }
                                    }
                                }
                            }

                            crate::models::DocumentAttachment {
                                name: a.name.clone(),
                                mime_type: a.mime_type.clone(),
                                size_bytes: a.size as usize,
                                text_content,
                                base64_content,
                            }
                        })
                        .collect::<Vec<_>>()
                })
                .filter(|v| !v.is_empty());

            let legacy_message = LegacyChatMessage {
                role: role.to_string(),
                content: content.clone(),
                timestamp: chrono::Utc::now(),
                thinking_content,
                thought_signature: None,
                rag_sources: None,
                memory_sources: None,
                graph_sources: None,
                web_search_sources: None,
                image_paths: None,
                image_base64,
                doc_attachments,
                multimodal_content: None,
                tool_call: None,
                tool_result: None,
                overrides: None,
                relations: None,
                persistent_stable_id: message.persistent_stable_id.clone(),
                metadata: None,
            };

            chat_history.push(legacy_message);
        }

        log::info!(
            "[ChatV2::pipeline] Loaded {} variant messages from history for session={}",
            chat_history.len(),
            session_id
        );

        // ğŸ†• éªŒè¯å·¥å…·è°ƒç”¨é“¾å®Œæ•´æ€§
        validate_tool_chain(&chat_history);

        Ok(chat_history)
    }

    /// æ„å»ºå˜ä½“ç”¨æˆ·æ¶ˆæ¯
    fn build_variant_user_message(
        &self,
        user_content: &str,
        attachments: &[AttachmentInput],
    ) -> LegacyChatMessage {
        let image_base64: Option<Vec<String>> = {
            let images: Vec<String> = attachments
                .iter()
                .filter(|a| a.mime_type.starts_with("image/"))
                .filter_map(|a| a.base64_content.clone())
                .collect();
            if images.is_empty() {
                None
            } else {
                Some(images)
            }
        };

        let doc_attachments: Option<Vec<crate::models::DocumentAttachment>> = {
            let docs: Vec<crate::models::DocumentAttachment> = attachments
                .iter()
                .filter(|a| {
                    !a.mime_type.starts_with("image/")
                        && !a.mime_type.starts_with("audio/")
                        && !a.mime_type.starts_with("video/")
                })
                .map(|a| {
                    // ğŸ”§ P0ä¿®å¤ï¼šå¦‚æœæ²¡æœ‰ text_content ä½†æœ‰ base64_contentï¼Œå°è¯•ä½¿ç”¨ DocumentParser è§£æ
                    let text_content = if a.text_content.is_some() {
                        a.text_content.clone()
                    } else if let Some(ref base64) = a.base64_content {
                        // å°è¯•ä½¿ç”¨ DocumentParser è§£æäºŒè¿›åˆ¶æ–‡æ¡£ï¼ˆdocx/pdf ç­‰ï¼‰
                        let parser = crate::document_parser::DocumentParser::new();
                        match parser.extract_text_from_base64(&a.name, base64) {
                            Ok(text) => {
                                log::info!(
                                    "[ChatV2::pipeline] Extracted {} chars from document: {}",
                                    text.len(),
                                    a.name
                                );
                                Some(text)
                            }
                            Err(e) => {
                                log::warn!(
                                    "[ChatV2::pipeline] Failed to parse document {}: {}",
                                    a.name,
                                    e
                                );
                                None
                            }
                        }
                    } else {
                        None
                    };

                    crate::models::DocumentAttachment {
                        name: a.name.clone(),
                        mime_type: a.mime_type.clone(),
                        size_bytes: a
                            .base64_content
                            .as_ref()
                            .map(|c| (c.len() * 3) / 4)
                            .unwrap_or(0),
                        text_content,
                        base64_content: a.base64_content.clone(),
                    }
                })
                .collect();
            if docs.is_empty() {
                None
            } else {
                Some(docs)
            }
        };

        LegacyChatMessage {
            role: "user".to_string(),
            content: user_content.to_string(),
            timestamp: chrono::Utc::now(),
            thinking_content: None,
            thought_signature: None,
            rag_sources: None,
            memory_sources: None,
            graph_sources: None,
            web_search_sources: None,
            image_paths: None,
            image_base64,
            doc_attachments,
            multimodal_content: None,
            tool_call: None,
            tool_result: None,
            overrides: None,
            relations: None,
            persistent_stable_id: None,
            metadata: None,
        }
    }

    /// æ‰§è¡Œæ‰¹é‡å˜ä½“é‡è¯•
    ///
    /// å¤ç”¨åŸæœ‰ SharedContextï¼Œå¹¶è¡Œæ‰§è¡Œå¤šä¸ªå˜ä½“çš„é‡è¯•ã€‚
    /// ä½¿ç”¨å•ä¸€äº‹ä»¶å‘å°„å™¨ä»¥ä¿è¯åºåˆ—å·å…¨å±€é€’å¢ã€‚
    pub async fn execute_variants_retry_batch(
        &self,
        window: Window,
        session_id: String,
        message_id: String,
        variants: Vec<VariantRetrySpec>,
        user_content: String,
        user_attachments: Vec<AttachmentInput>,
        shared_context: SharedContext,
        options: SendOptions,
        cancel_token: CancellationToken,
        chat_v2_state: Option<Arc<super::state::ChatV2State>>,
    ) -> ChatV2Result<()> {
        use super::variant_context::{ParallelExecutionManager, VariantExecutionContext};
        use futures::future::join_all;

        log::info!(
            "[ChatV2::pipeline] execute_variants_retry_batch: session={}, message={}, variants={}",
            session_id,
            message_id,
            variants.len()
        );

        if variants.is_empty() {
            return Err(ChatV2Error::Validation(
                "No variant IDs provided for batch retry".to_string(),
            ));
        }

        // å•ä¸€äº‹ä»¶å‘å°„å™¨ï¼Œç¡®ä¿ sequenceId å…¨å±€é€’å¢
        let emitter = Arc::new(super::events::ChatV2EventEmitter::new(
            window.clone(),
            session_id.clone(),
        ));

        let shared_context_arc = Arc::new(shared_context);

        // åˆ›å»ºå¹¶è¡Œæ‰§è¡Œç®¡ç†å™¨ï¼ˆå¤šå˜ä½“é‡è¯•ï¼‰
        let manager = ParallelExecutionManager::with_cancel_token(cancel_token.clone());

        let mut variant_contexts: Vec<(Arc<VariantExecutionContext>, String)> =
            Vec::with_capacity(variants.len());

        for spec in &variants {
            let ctx = manager.create_variant(
                spec.variant_id.clone(),
                spec.model_id.clone(),
                message_id.clone(),
                Arc::clone(&shared_context_arc),
                Arc::clone(&emitter),
            );
            ctx.set_config_id(spec.config_id.clone());

            // æ³¨å†Œæ¯ä¸ªå˜ä½“çš„ cancel tokenï¼ˆç”¨äºæŒ‰ variant å–æ¶ˆï¼‰
            if let Some(ref state) = chat_v2_state {
                let cancel_key = format!("{}:{}", session_id, spec.variant_id);
                state.register_existing_token(&cancel_key, ctx.cancel_token().clone());
                log::debug!(
                    "[ChatV2::pipeline] Registered cancel token for retry variant: {}",
                    cancel_key
                );
            }

            variant_contexts.push((ctx, spec.config_id.clone()));
        }

        // ğŸ”§ P1ä¿®å¤ï¼šå¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å˜ä½“ï¼ˆä½¿ç”¨ä»»åŠ¡è¿½è¸ªå™¨ï¼‰
        let self_clone = self.clone();
        let options_arc = Arc::new(options.clone());
        let user_content_arc = Arc::new(user_content.clone());
        let session_id_arc = Arc::new(session_id.clone());
        let attachments_arc = Arc::new(user_attachments.clone());

        let futures: Vec<_> = variant_contexts
            .iter()
            .map(|(ctx, config_id)| {
                let self_ref = self_clone.clone();
                let ctx_clone = Arc::clone(ctx);
                let config_id_clone = config_id.clone();
                let options_clone = Arc::clone(&options_arc);
                let user_content_clone = Arc::clone(&user_content_arc);
                let session_id_clone = Arc::clone(&session_id_arc);
                let attachments_clone = Arc::clone(&attachments_arc);
                let shared_ctx = Arc::clone(&shared_context_arc);
                let state_clone = chat_v2_state.clone();

                let future = async move {
                    self_ref
                        .execute_single_variant_with_config(
                            ctx_clone,
                            config_id_clone,
                            (*options_clone).clone(),
                            (*user_content_clone).clone(),
                            (*session_id_clone).clone(),
                            shared_ctx,
                            (*attachments_clone).clone(),
                        )
                        .await
                };

                // ğŸ”§ P1ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ spawn_tracked è¿½è¸ªä»»åŠ¡
                if let Some(ref state) = state_clone {
                    state.spawn_tracked(future)
                } else {
                    log::warn!("[ChatV2::pipeline] spawn_tracked unavailable, using untracked tokio::spawn for retry variant task");
                    tokio::spawn(future)
                }
            })
            .collect();

        let results = join_all(futures).await;

        for (i, result) in results.into_iter().enumerate() {
            let (ctx, _) = &variant_contexts[i];
            match result {
                Ok(Ok(())) => {
                    log::info!(
                        "[ChatV2::pipeline] Retry variant {} completed successfully",
                        ctx.variant_id()
                    );
                }
                Ok(Err(e)) => {
                    log::error!(
                        "[ChatV2::pipeline] Retry variant {} failed: {}",
                        ctx.variant_id(),
                        e
                    );
                    // é”™è¯¯å·²åœ¨ execute_single_variant_with_config ä¸­å¤„ç†
                }
                Err(e) => {
                    log::error!(
                        "[ChatV2::pipeline] Retry variant {} task panicked: {}",
                        ctx.variant_id(),
                        e
                    );
                    ctx.fail(&format!("Task panicked: {}", e));
                }
            }
        }

        // æŒä¹…åŒ–æ¯ä¸ªå˜ä½“
        let mut update_error: Option<ChatV2Error> = None;
        for (ctx, _) in &variant_contexts {
            if let Err(e) = self.update_variant_after_retry(&message_id, ctx).await {
                log::error!(
                    "[ChatV2::pipeline] Failed to update retry variant {}: {}",
                    ctx.variant_id(),
                    e
                );
                if update_error.is_none() {
                    update_error = Some(e);
                }
            }
        }

        // æ¸…ç† cancel token
        if let Some(ref state) = chat_v2_state {
            for (ctx, _) in &variant_contexts {
                let cancel_key = format!("{}:{}", session_id, ctx.variant_id());
                state.remove_stream(&cancel_key);
            }
        }

        if let Some(err) = update_error {
            return Err(err);
        }

        Ok(())
    }

    /// æ‰§è¡Œå˜ä½“é‡è¯•
    ///
    /// é‡æ–°æ‰§è¡ŒæŒ‡å®šå˜ä½“çš„ LLM è°ƒç”¨ï¼Œå¤ç”¨åŸæœ‰çš„ SharedContextï¼ˆæ£€ç´¢ç»“æœï¼‰ã€‚
    ///
    /// ## å‚æ•°
    /// - `window`: Tauri çª—å£ï¼Œç”¨äºäº‹ä»¶å‘å°„
    /// - `session_id`: ä¼šè¯ ID
    /// - `message_id`: åŠ©æ‰‹æ¶ˆæ¯ ID
    /// - `variant_id`: è¦é‡è¯•çš„å˜ä½“ ID
    /// - `model_id`: æ¨¡å‹ IDï¼ˆå¯èƒ½å·²è¢« model_override è¦†ç›–ï¼‰
    /// - `user_content`: åŸå§‹ç”¨æˆ·æ¶ˆæ¯å†…å®¹
    /// - `user_attachments`: åŸå§‹ç”¨æˆ·é™„ä»¶
    /// - `shared_context`: å…±äº«ä¸Šä¸‹æ–‡ï¼ˆæ£€ç´¢ç»“æœï¼Œä»åŸæ¶ˆæ¯æ¢å¤ï¼‰
    /// - `options`: å‘é€é€‰é¡¹
    /// - `cancel_token`: å–æ¶ˆä»¤ç‰Œ
    ///
    /// ## è¿”å›
    /// æˆåŠŸå®Œæˆåè¿”å› Ok(())
    pub async fn execute_variant_retry(
        &self,
        window: Window,
        session_id: String,
        message_id: String,
        variant_id: String,
        model_id: String,
        user_content: String,
        user_attachments: Vec<AttachmentInput>,
        shared_context: SharedContext,
        options: SendOptions,
        cancel_token: CancellationToken,
    ) -> ChatV2Result<()> {
        log::info!(
            "[ChatV2::pipeline] execute_variant_retry: session={}, message={}, variant={}, model={}",
            session_id,
            message_id,
            variant_id,
            model_id
        );

        // åˆ›å»ºäº‹ä»¶å‘å°„å™¨
        let emitter = Arc::new(super::events::ChatV2EventEmitter::new(
            window.clone(),
            session_id.clone(),
        ));

        // åˆ›å»ºå…±äº«ä¸Šä¸‹æ–‡çš„ Arc
        let shared_context_arc = Arc::new(shared_context);

        // ğŸ”§ P1-4 ä¿®å¤ï¼šå°† config_id è§£æä¸ºæ¨¡å‹æ˜¾ç¤ºåç§°
        // model_id å¯èƒ½æ˜¯ API é…ç½® UUIDï¼ˆå¦‚ "builtin-siliconflow"ï¼‰ï¼Œéœ€è¦è§£æä¸ºæ˜¾ç¤ºåç§°ï¼ˆå¦‚ "Qwen/Qwen3-8B"ï¼‰
        // ç”¨äº variant_start äº‹ä»¶å’Œ variant.model_id å­˜å‚¨ï¼Œç¡®ä¿å‰ç«¯èƒ½æ­£ç¡®æ˜¾ç¤ºä¾›åº”å•†å›¾æ ‡
        let display_model_id = match self.llm_manager.get_api_configs().await {
            Ok(configs) => {
                configs
                    .iter()
                    .find(|c| c.id == model_id)
                    .map(|c| c.model.clone())
                    .or_else(|| {
                        // é€šè¿‡ model åç§°åŒ¹é…ï¼ˆconfig_id æœ¬èº«å¯èƒ½å°±æ˜¯æ¨¡å‹åï¼‰
                        configs.iter().find(|c| c.model == model_id).map(|c| c.model.clone())
                    })
                    .unwrap_or_else(|| {
                        // æ— æ³•ä» configs è§£ææ—¶ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºé…ç½® ID æ ¼å¼
                        if is_config_id_format(&model_id) {
                            log::warn!(
                                "[ChatV2::pipeline] variant retry: config_id is not a display name: {}",
                                model_id
                            );
                            // å›é€€åˆ°ç©ºå­—ç¬¦ä¸²ï¼Œå‰ç«¯ä¼šæ˜¾ç¤º generic å›¾æ ‡
                            // ä¼˜äºæ˜¾ç¤ºæ— æ³•è¯†åˆ«çš„ UUID
                            String::new()
                        } else {
                            model_id.clone()
                        }
                    })
            }
            Err(_) => model_id.clone(),
        };

        // åˆ›å»ºå¹¶è¡Œæ‰§è¡Œç®¡ç†å™¨ï¼ˆå•å˜ä½“ï¼‰
        let manager = super::variant_context::ParallelExecutionManager::with_cancel_token(
            cancel_token.clone(),
        );

        // åˆ›å»ºå˜ä½“æ‰§è¡Œä¸Šä¸‹æ–‡ï¼ˆä½¿ç”¨å·²æœ‰çš„ variant_idï¼‰
        // ä½¿ç”¨ display_model_id ä½œä¸ºå˜ä½“çš„æ¨¡å‹æ ‡è¯†ï¼ˆç”¨äºå‰ç«¯å›¾æ ‡æ˜¾ç¤ºï¼‰
        let ctx = manager.create_variant(
            variant_id.clone(),
            display_model_id,
            message_id.clone(),
            Arc::clone(&shared_context_arc),
            Arc::clone(&emitter),
        );

        // æ‰§è¡Œå˜ä½“ï¼ˆä½¿ç”¨å®Œæ•´å·¥å…·å¾ªç¯è·¯å¾„ï¼Œä¸å¤šå˜ä½“ä¸»æµç¨‹ä¿æŒä¸€è‡´ï¼‰
        // æ³¨æ„ï¼šmodel_idï¼ˆåŸå§‹ config_idï¼‰ä¼ é€’ç»™ execute_single_variant_with_config ç”¨äº LLM è°ƒç”¨
        let result = self
            .execute_single_variant_with_config(
                ctx.clone(),
                model_id.clone(),
                options,
                user_content,
                session_id.clone(),
                shared_context_arc,
                user_attachments,
            )
            .await;

        // å¤„ç†ç»“æœå¹¶æ›´æ–°å˜ä½“çŠ¶æ€
        // ğŸ”§ P0ä¿®å¤ï¼šæ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œéƒ½éœ€è¦æŒä¹…åŒ–å˜ä½“çŠ¶æ€
        match result {
            Ok(()) => {
                // æ›´æ–°å˜ä½“åœ¨æ•°æ®åº“ä¸­çš„çŠ¶æ€å’Œå†…å®¹
                self.update_variant_after_retry(&message_id, &ctx).await?;
                log::info!(
                    "[ChatV2::pipeline] Variant retry completed: variant={}, status={}",
                    variant_id,
                    ctx.status()
                );
                Ok(())
            }
            Err(e) => {
                log::error!(
                    "[ChatV2::pipeline] Variant retry failed: variant={}, error={}",
                    variant_id,
                    e
                );
                // ğŸ”§ P0ä¿®å¤ï¼šå¤±è´¥æ—¶ä¹Ÿéœ€è¦æ›´æ–°å˜ä½“çŠ¶æ€åˆ°æ•°æ®åº“
                // ctx.status() åœ¨ execute_single_variant å¤±è´¥æ—¶ä¼šè¢«è®¾ç½®ä¸º ERROR æˆ– CANCELLED
                if let Err(update_err) = self.update_variant_after_retry(&message_id, &ctx).await {
                    log::error!(
                        "[ChatV2::pipeline] Failed to update variant status after error: {}",
                        update_err
                    );
                }
                Err(e)
            }
        }
    }

    /// æ›´æ–°é‡è¯•åçš„å˜ä½“
    ///
    /// æ›´æ–°å˜ä½“çŠ¶æ€ã€å—å†…å®¹ç­‰åˆ°æ•°æ®åº“
    async fn update_variant_after_retry(
        &self,
        message_id: &str,
        ctx: &Arc<super::variant_context::VariantExecutionContext>,
    ) -> ChatV2Result<()> {
        let conn = self.db.get_conn_safe()?;
        let now_ms = chrono::Utc::now().timestamp_millis();

        // è·å–æ¶ˆæ¯
        let mut message = ChatV2Repo::get_message_with_conn(&conn, message_id)?
            .ok_or_else(|| ChatV2Error::MessageNotFound(message_id.to_string()))?;

        // æ›´æ–°å˜ä½“çŠ¶æ€
        if let Some(ref mut variants) = message.variants {
            if let Some(variant) = variants.iter_mut().find(|v| v.id == ctx.variant_id()) {
                variant.status = ctx.status();
                variant.error = ctx.error();
                variant.block_ids = ctx.block_ids();
                let usage = ctx.get_usage();
                variant.usage = if usage.total_tokens > 0 {
                    Some(usage)
                } else {
                    None
                };
            }
        }

        // ğŸ”§ ä¼˜åŒ–ï¼šé‡è¯•æˆåŠŸåè‡ªåŠ¨è®¾ä¸ºæ¿€æ´»å˜ä½“
        if ctx.status() == variant_status::SUCCESS {
            message.active_variant_id = Some(ctx.variant_id().to_string());
            log::info!(
                "[ChatV2::pipeline] Auto-activated successful retry variant: {}",
                ctx.variant_id()
            );
        }

        // ä¿å­˜ thinking å—ï¼ˆå¦‚æœæœ‰ï¼‰
        if let Some(thinking_block_id) = ctx.get_thinking_block_id() {
            let thinking_content = ctx.get_accumulated_reasoning();
            let thinking_block = MessageBlock {
                id: thinking_block_id.clone(),
                message_id: message_id.to_string(),
                block_type: block_types::THINKING.to_string(),
                status: block_status::SUCCESS.to_string(),
                content: thinking_content,
                tool_name: None,
                tool_input: None,
                tool_output: None,
                citations: None,
                error: None,
                // ğŸ”§ P3ä¿®å¤ï¼šä½¿ç”¨ first_chunk_at ä½œä¸º started_atï¼ˆçœŸæ­£çš„å¼€å§‹æ—¶é—´ï¼‰
                started_at: ctx.get_thinking_first_chunk_at().or(Some(now_ms)),
                ended_at: Some(now_ms),
                // ğŸ”§ ä½¿ç”¨ VariantContext è®°å½•çš„ first_chunk_at æ—¶é—´æˆ³
                first_chunk_at: ctx.get_thinking_first_chunk_at(),
                block_index: 0,
            };
            ChatV2Repo::create_block_with_conn(&conn, &thinking_block)?;

            // æ·»åŠ åˆ°æ¶ˆæ¯çš„ block_ids
            if !message.block_ids.contains(&thinking_block_id) {
                message.block_ids.push(thinking_block_id);
            }
        }

        // ä¿å­˜ content å—
        if let Some(content_block_id) = ctx.get_content_block_id() {
            let content = ctx.get_accumulated_content();
            let content_block = MessageBlock {
                id: content_block_id.clone(),
                message_id: message_id.to_string(),
                block_type: block_types::CONTENT.to_string(),
                // ğŸ”§ P1ä¿®å¤ï¼šæ­£ç¡®å¤„ç† CANCELLED çŠ¶æ€
                status: match ctx.status().as_str() {
                    s if s == variant_status::SUCCESS => block_status::SUCCESS.to_string(),
                    s if s == variant_status::ERROR => block_status::ERROR.to_string(),
                    s if s == variant_status::CANCELLED => block_status::SUCCESS.to_string(), // cancelled ä½†æœ‰å†…å®¹ï¼Œæ ‡è®°ä¸º success
                    _ => block_status::RUNNING.to_string(),
                },
                content: if content.is_empty() {
                    None
                } else {
                    Some(content)
                },
                tool_name: None,
                tool_input: None,
                tool_output: None,
                citations: None,
                error: ctx.error(),
                // ğŸ”§ P3ä¿®å¤ï¼šä½¿ç”¨ first_chunk_at ä½œä¸º started_atï¼ˆçœŸæ­£çš„å¼€å§‹æ—¶é—´ï¼‰
                started_at: ctx.get_content_first_chunk_at().or(Some(now_ms)),
                ended_at: Some(now_ms),
                // ğŸ”§ ä½¿ç”¨ VariantContext è®°å½•çš„ first_chunk_at æ—¶é—´æˆ³
                first_chunk_at: ctx.get_content_first_chunk_at(),
                block_index: 1, // content åœ¨ thinking ä¹‹å
            };
            ChatV2Repo::create_block_with_conn(&conn, &content_block)?;

            // æ·»åŠ åˆ°æ¶ˆæ¯çš„ block_ids
            if !message.block_ids.contains(&content_block_id) {
                message.block_ids.push(content_block_id);
            }
        }

        // æ›´æ–°æ¶ˆæ¯
        ChatV2Repo::update_message_with_conn(&conn, &message)?;

        log::debug!(
            "[ChatV2::pipeline] Updated variant after retry: variant={}, blocks={}",
            ctx.variant_id(),
            ctx.block_ids().len()
        );

        Ok(())
    }

    /// ä¿å­˜å¤šå˜ä½“ç»“æœ
    ///
    /// ä»æ¯ä¸ª VariantExecutionContext è·å–ç´¯ç§¯çš„å†…å®¹ï¼Œåˆ›å»ºå—å¹¶ä¿å­˜ã€‚
    ///
    /// ## ç»Ÿä¸€ä¸Šä¸‹æ–‡æ³¨å…¥ç³»ç»Ÿæ”¯æŒ
    /// - `context_snapshot`: ä¸Šä¸‹æ–‡å¿«ç…§ï¼ˆåªå­˜ ContextRefï¼‰
    async fn save_multi_variant_results(
        &self,
        session_id: &str,
        user_message_id: &str,
        assistant_message_id: &str,
        user_content: &str,
        attachments: &[AttachmentInput],
        options: &SendOptions,
        shared_context: &SharedContext,
        variant_contexts: &[Arc<super::variant_context::VariantExecutionContext>],
        active_variant_id: Option<&str>,
        context_snapshot: Option<ContextSnapshot>,
    ) -> ChatV2Result<()> {
        let conn = self.db.get_conn_safe()?;
        let now_ms = chrono::Utc::now().timestamp_millis();

        // === 1. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ ===
        // ğŸ†• ä½¿ç”¨ç»Ÿä¸€çš„ç”¨æˆ·æ¶ˆæ¯æ„å»ºå™¨ï¼Œç¡®ä¿æ‰€æœ‰è·¯å¾„çš„ä¸€è‡´æ€§
        let mut user_msg_params =
            UserMessageParams::new(session_id.to_string(), user_content.to_string())
                .with_id(user_message_id.to_string())
                .with_attachments(attachments.to_vec())
                .with_timestamp(now_ms);

        if let Some(snapshot) = context_snapshot.clone() {
            user_msg_params = user_msg_params.with_context_snapshot(snapshot);
        }

        let user_msg_result = build_user_message(user_msg_params);

        ChatV2Repo::create_message_with_conn(&conn, &user_msg_result.message)?;
        ChatV2Repo::create_block_with_conn(&conn, &user_msg_result.block)?;

        // === 2. ğŸ”§ P1ä¿®å¤ï¼šä¿å­˜æ£€ç´¢å— ===
        let mut all_block_ids: Vec<String> = Vec::new();
        let mut pending_blocks: Vec<MessageBlock> = Vec::new();
        let mut block_index_counter = 0;

        // 2.1 ä¿å­˜ RAG æ£€ç´¢å—
        if let Some(ref block_id) = shared_context.rag_block_id {
            if shared_context
                .rag_sources
                .as_ref()
                .map_or(false, |v| !v.is_empty())
            {
                let rag_block = MessageBlock {
                    id: block_id.clone(),
                    message_id: assistant_message_id.to_string(),
                    block_type: block_types::RAG.to_string(),
                    status: block_status::SUCCESS.to_string(),
                    content: None,
                    tool_name: None,
                    tool_input: None,
                    tool_output: Some(json!({ "sources": shared_context.rag_sources })),
                    citations: None,
                    error: None,
                    started_at: Some(now_ms),
                    ended_at: Some(now_ms),
                    // ğŸ”§ æ£€ç´¢å—ä½¿ç”¨ now_ms ä½œä¸º first_chunk_at
                    first_chunk_at: Some(now_ms),
                    block_index: block_index_counter,
                };
                pending_blocks.push(rag_block);
                all_block_ids.push(block_id.clone());
                block_index_counter += 1;
            }
        }

        // 2.2 ä¿å­˜ Memory æ£€ç´¢å—
        if let Some(ref block_id) = shared_context.memory_block_id {
            if shared_context
                .memory_sources
                .as_ref()
                .map_or(false, |v| !v.is_empty())
            {
                let memory_block = MessageBlock {
                    id: block_id.clone(),
                    message_id: assistant_message_id.to_string(),
                    block_type: block_types::MEMORY.to_string(),
                    status: block_status::SUCCESS.to_string(),
                    content: None,
                    tool_name: None,
                    tool_input: None,
                    tool_output: Some(json!({ "sources": shared_context.memory_sources })),
                    citations: None,
                    error: None,
                    started_at: Some(now_ms),
                    ended_at: Some(now_ms),
                    // ğŸ”§ æ£€ç´¢å—ä½¿ç”¨ now_ms ä½œä¸º first_chunk_at
                    first_chunk_at: Some(now_ms),
                    block_index: block_index_counter,
                };
                pending_blocks.push(memory_block);
                all_block_ids.push(block_id.clone());
                block_index_counter += 1;
            }
        }

        // 2.4 ä¿å­˜ Web æœç´¢æ£€ç´¢å—
        if let Some(ref block_id) = shared_context.web_search_block_id {
            if shared_context
                .web_search_sources
                .as_ref()
                .map_or(false, |v| !v.is_empty())
            {
                let web_block = MessageBlock {
                    id: block_id.clone(),
                    message_id: assistant_message_id.to_string(),
                    block_type: block_types::WEB_SEARCH.to_string(),
                    status: block_status::SUCCESS.to_string(),
                    content: None,
                    tool_name: None,
                    tool_input: None,
                    tool_output: Some(json!({ "sources": shared_context.web_search_sources })),
                    citations: None,
                    error: None,
                    started_at: Some(now_ms),
                    ended_at: Some(now_ms),
                    // ğŸ”§ æ£€ç´¢å—ä½¿ç”¨ now_ms ä½œä¸º first_chunk_at
                    first_chunk_at: Some(now_ms),
                    block_index: block_index_counter,
                };
                pending_blocks.push(web_block);
                all_block_ids.push(block_id.clone());
                block_index_counter += 1;
            }
        }

        log::debug!(
            "[ChatV2::pipeline] Multi-variant retrieval blocks saved: {} blocks",
            block_index_counter
        );

        // === 3. æ”¶é›†æ‰€æœ‰å˜ä½“å—ä¿¡æ¯ ===
        let mut variants: Vec<Variant> = Vec::with_capacity(variant_contexts.len());

        for ctx in variant_contexts {
            let mut block_index = 0;

            // ä¿å­˜ thinking å—ï¼ˆå¦‚æœæœ‰ï¼‰
            if let Some(thinking_block_id) = ctx.get_thinking_block_id() {
                let thinking_content = ctx.get_accumulated_reasoning();
                let thinking_block = MessageBlock {
                    id: thinking_block_id.clone(),
                    message_id: assistant_message_id.to_string(),
                    block_type: block_types::THINKING.to_string(),
                    status: block_status::SUCCESS.to_string(),
                    content: thinking_content,
                    tool_name: None,
                    tool_input: None,
                    tool_output: None,
                    citations: None,
                    error: None,
                    // ğŸ”§ P3ä¿®å¤ï¼šä½¿ç”¨ first_chunk_at ä½œä¸º started_atï¼ˆçœŸæ­£çš„å¼€å§‹æ—¶é—´ï¼‰
                    started_at: ctx.get_thinking_first_chunk_at().or(Some(now_ms)),
                    ended_at: Some(now_ms),
                    // ğŸ”§ ä½¿ç”¨ VariantContext è®°å½•çš„ first_chunk_at æ—¶é—´æˆ³
                    first_chunk_at: ctx.get_thinking_first_chunk_at(),
                    block_index,
                };
                pending_blocks.push(thinking_block);
                all_block_ids.push(thinking_block_id);
                block_index += 1;
            }

            // æ”¶é›† content å—
            if let Some(content_block_id) = ctx.get_content_block_id() {
                let content = ctx.get_accumulated_content();
                let content_block = MessageBlock {
                    id: content_block_id.clone(),
                    message_id: assistant_message_id.to_string(),
                    block_type: block_types::CONTENT.to_string(),
                    status: if ctx.status() == variant_status::SUCCESS {
                        block_status::SUCCESS.to_string()
                    } else if ctx.status() == variant_status::ERROR {
                        block_status::ERROR.to_string()
                    } else {
                        block_status::RUNNING.to_string()
                    },
                    content: if content.is_empty() {
                        None
                    } else {
                        Some(content)
                    },
                    tool_name: None,
                    tool_input: None,
                    tool_output: None,
                    citations: None,
                    error: ctx.error(),
                    // ğŸ”§ P3ä¿®å¤ï¼šä½¿ç”¨ first_chunk_at ä½œä¸º started_atï¼ˆçœŸæ­£çš„å¼€å§‹æ—¶é—´ï¼‰
                    started_at: ctx.get_content_first_chunk_at().or(Some(now_ms)),
                    ended_at: Some(now_ms),
                    // ğŸ”§ ä½¿ç”¨ VariantContext è®°å½•çš„ first_chunk_at æ—¶é—´æˆ³
                    first_chunk_at: ctx.get_content_first_chunk_at(),
                    block_index,
                };
                pending_blocks.push(content_block);
                all_block_ids.push(content_block_id);
            }

            // åˆ›å»º Variant ç»“æ„
            let variant = ctx.to_variant();
            variants.push(variant);

            log::debug!(
                "[ChatV2::pipeline] Saved blocks for variant {}: status={}",
                ctx.variant_id(),
                ctx.status()
            );
        }

        // === 4. ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯ï¼ˆå¸¦å˜ä½“ä¿¡æ¯ï¼‰===
        let assistant_message = ChatMessage {
            id: assistant_message_id.to_string(),
            session_id: session_id.to_string(),
            role: MessageRole::Assistant,
            block_ids: all_block_ids,
            timestamp: now_ms,
            persistent_stable_id: None,
            parent_id: None,
            supersedes: None,
            meta: Some(MessageMeta {
                model_id: None, // å¤šå˜ä½“æ¨¡å¼ä¸‹ä¸è®¾ç½®å•ä¸€æ¨¡å‹
                chat_params: Some(json!({
                    "temperature": options.temperature,
                    "maxTokens": options.max_tokens,
                    "enableThinking": options.enable_thinking,
                    "multiVariantMode": true,
                })),
                sources: if shared_context.has_sources() {
                    Some(MessageSources {
                        rag: shared_context.rag_sources.clone(),
                        memory: shared_context.memory_sources.clone(),
                        graph: shared_context.graph_sources.clone(),
                        web_search: shared_context.web_search_sources.clone(),
                        multimodal: shared_context.multimodal_sources.clone(),
                    })
                } else {
                    None
                },
                tool_results: None,
                anki_cards: None,
                // å¤šå˜ä½“æ¨¡å¼ä¸‹ usage ä¸º Noneï¼ˆå„å˜ä½“ç‹¬ç«‹è®°å½•ï¼‰
                usage: None,
                // ğŸ†• ç»Ÿä¸€ä¸Šä¸‹æ–‡æ³¨å…¥ç³»ç»Ÿï¼šå¤šå˜ä½“æ¨¡å¼æ”¯æŒ context_snapshot
                context_snapshot: context_snapshot.clone(),
            }),
            attachments: None,
            active_variant_id: active_variant_id.map(|s| s.to_string()),
            variants: Some(variants),
            shared_context: Some(shared_context.clone()),
        };

        ChatV2Repo::create_message_with_conn(&conn, &assistant_message)?;

        // ğŸ†• ç»Ÿä¸€ä¸Šä¸‹æ–‡æ³¨å…¥ç³»ç»Ÿï¼šæ¶ˆæ¯ä¿å­˜åå¢åŠ èµ„æºå¼•ç”¨è®¡æ•°
        // ğŸ†• VFS ç»Ÿä¸€å­˜å‚¨ï¼ˆ2025-12-07ï¼‰ï¼šä½¿ç”¨ vfs.db
        if let Some(ref snapshot) = context_snapshot {
            if snapshot.has_refs() {
                if let Some(ref vfs_db) = self.vfs_db {
                    if let Ok(vfs_conn) = vfs_db.get_conn_safe() {
                        let resource_ids = snapshot.all_resource_ids();
                        // ä½¿ç”¨åŒæ­¥æ–¹æ³•å¢åŠ å¼•ç”¨è®¡æ•°ï¼ˆä½¿ç”¨ç°æœ‰è¿æ¥é¿å…æ­»é”ï¼‰
                        for resource_id in &resource_ids {
                            if let Err(e) =
                                VfsResourceRepo::increment_ref_with_conn(&vfs_conn, resource_id)
                            {
                                log::warn!(
                                    "[ChatV2::pipeline] Failed to increment ref for resource {}: {}",
                                    resource_id, e
                                );
                            }
                        }
                        log::debug!(
                            "[ChatV2::pipeline] Multi-variant: incremented refs for {} resources in vfs.db",
                            resource_ids.len()
                        );
                    } else {
                        log::warn!("[ChatV2::pipeline] Multi-variant: failed to get vfs.db connection for increment refs");
                    }
                } else {
                    log::warn!("[ChatV2::pipeline] Multi-variant: vfs_db not available, skipping increment refs");
                }
            }
        }

        // === 4. ç°åœ¨å¯ä»¥å®‰å…¨åœ°åˆ›å»ºå—äº†ï¼ˆåŠ©æ‰‹æ¶ˆæ¯å·²å­˜åœ¨ï¼‰===
        for block in pending_blocks {
            ChatV2Repo::create_block_with_conn(&conn, &block)?;
        }

        log::info!(
            "[ChatV2::pipeline] Multi-variant results saved: user_msg={}, assistant_msg={}, variants={}",
            user_message_id,
            assistant_message_id,
            variant_contexts.len()
        );

        Ok(())
    }
}

// ============================================================================
// å˜ä½“ LLM é€‚é…å™¨
// ============================================================================

struct VariantLLMAdapter {
    ctx: Arc<super::variant_context::VariantExecutionContext>,
    enable_thinking: bool,
    content_block_initialized: Mutex<bool>,
    thinking_block_initialized: Mutex<bool>,
    finalized_thinking_block_id: Mutex<Option<String>>,
    /// ğŸ”§ <think> æ ‡ç­¾è§£æçŠ¶æ€ï¼šæ˜¯å¦å½“å‰åœ¨ <think> æ ‡ç­¾å†…éƒ¨
    in_think_tag: Mutex<bool>,
    /// ğŸ”§ <think> æ ‡ç­¾è§£æç¼“å†²åŒºï¼šç”¨äºå¤„ç†è·¨ chunk çš„æ ‡ç­¾è¾¹ç•Œ
    think_tag_buffer: Mutex<String>,
}

impl VariantLLMAdapter {
    fn new(
        ctx: Arc<super::variant_context::VariantExecutionContext>,
        enable_thinking: bool,
    ) -> Self {
        Self {
            ctx,
            enable_thinking,
            content_block_initialized: Mutex::new(false),
            thinking_block_initialized: Mutex::new(false),
            finalized_thinking_block_id: Mutex::new(None),
            in_think_tag: Mutex::new(false),
            think_tag_buffer: Mutex::new(String::new()),
        }
    }

    fn finalize_thinking(&self) {
        let mut initialized = self
            .thinking_block_initialized
            .lock()
            .unwrap_or_else(|e| e.into_inner());
        if *initialized {
            if let Some(block_id) = self.ctx.get_thinking_block_id() {
                *self
                    .finalized_thinking_block_id
                    .lock()
                    .unwrap_or_else(|e| e.into_inner()) = Some(block_id.clone());
                self.ctx.emit_end(event_types::THINKING, &block_id, None);
            }
            *initialized = false;
        }
    }

    fn finalize_all(&self) {
        // ğŸ”§ å…ˆå¤„ç†ç¼“å†²åŒºä¸­å‰©ä½™çš„å†…å®¹
        self.flush_think_tag_buffer();
        self.finalize_thinking();
        let content_initialized = *self
            .content_block_initialized
            .lock()
            .unwrap_or_else(|e| e.into_inner());
        if content_initialized {
            if let Some(block_id) = self.ctx.get_content_block_id() {
                self.ctx.emit_end(event_types::CONTENT, &block_id, None);
            }
        }
    }

    /// ğŸ”§ åˆ·æ–° think æ ‡ç­¾ç¼“å†²åŒºä¸­å‰©ä½™çš„å†…å®¹
    fn flush_think_tag_buffer(&self) {
        let mut buffer = self
            .think_tag_buffer
            .lock()
            .unwrap_or_else(|e| e.into_inner());

        if buffer.is_empty() {
            return;
        }

        let remaining = std::mem::take(&mut *buffer);
        let in_think = *self.in_think_tag.lock().unwrap_or_else(|e| e.into_inner());
        drop(buffer);

        if in_think && self.enable_thinking {
            // å‰©ä½™å†…å®¹å±äº thinkingï¼ˆæœªé—­åˆçš„ think æ ‡ç­¾ï¼‰
            log::warn!(
                "[ChatV2::VariantAdapter] Flushing unclosed <think> tag content: {} chars",
                remaining.len()
            );
            self.ctx.append_reasoning(&remaining);
            if let Some(block_id) = self.ctx.get_thinking_block_id() {
                self.ctx
                    .emit_chunk(event_types::THINKING, &block_id, &remaining);
            }
        } else if !remaining.is_empty() {
            // å‰©ä½™å†…å®¹å±äº content
            self.ctx.append_content(&remaining);
            if let Some(block_id) = self.ctx.get_content_block_id() {
                self.ctx
                    .emit_chunk(event_types::CONTENT, &block_id, &remaining);
            }
        }
    }

    /// ğŸ”§ ç¡®ä¿ thinking å—å·²å¯åŠ¨ï¼ˆç”¨äº <think> æ ‡ç­¾è§£æï¼‰
    fn ensure_thinking_started_for_tag(&self) -> Option<String> {
        if !self.enable_thinking {
            return None;
        }

        let mut initialized = self
            .thinking_block_initialized
            .lock()
            .unwrap_or_else(|e| e.into_inner());
        if !*initialized {
            let block_id = MessageBlock::generate_id();
            self.ctx.set_thinking_block_id(&block_id);
            self.ctx.emit_start(event_types::THINKING, &block_id, None);
            *initialized = true;
        }
        drop(initialized);
        self.ctx.get_thinking_block_id()
    }

    /// ğŸ”§ ç¡®ä¿ content å—å·²å¯åŠ¨ï¼ˆç”¨äº <think> æ ‡ç­¾è§£æï¼‰
    fn ensure_content_started_for_tag(&self) -> Option<String> {
        // å…ˆç»“æŸ thinking å—ï¼ˆå¦‚æœæœ‰ï¼‰
        self.finalize_thinking();

        let mut initialized = self
            .content_block_initialized
            .lock()
            .unwrap_or_else(|e| e.into_inner());
        if !*initialized {
            let block_id = MessageBlock::generate_id();
            self.ctx.set_content_block_id(&block_id);
            self.ctx.emit_start(event_types::CONTENT, &block_id, None);
            *initialized = true;
        }
        drop(initialized);
        self.ctx.get_content_block_id()
    }

    /// ğŸ”§ å¤„ç† think æ ‡ç­¾ç¼“å†²åŒºï¼Œå°†å†…å®¹è·¯ç”±åˆ° thinking æˆ– content å—
    ///
    /// æ”¯æŒä¸­è½¬ç«™è¿”å›çš„ `<think>...</think>` æˆ– `<thinking>...</thinking>` æ ¼å¼
    fn process_think_tag_buffer(&self) {
        // å¼€å§‹æ ‡ç­¾æ¨¡å¼ï¼ˆæ”¯æŒ <think> å’Œ <thinking>ï¼‰
        const START_TAGS: &[&str] = &["<thinking>", "<think>"];
        // ç»“æŸæ ‡ç­¾æ¨¡å¼ï¼ˆæ”¯æŒ </think> å’Œ </thinking>ï¼‰
        const END_TAGS: &[&str] = &["</thinking>", "</think>"];

        loop {
            let mut buffer = self
                .think_tag_buffer
                .lock()
                .unwrap_or_else(|e| e.into_inner());
            let in_think = *self.in_think_tag.lock().unwrap_or_else(|e| e.into_inner());

            if buffer.is_empty() {
                return;
            }

            if in_think {
                // å½“å‰åœ¨ <think> æ ‡ç­¾å†…ï¼Œå¯»æ‰¾ç»“æŸæ ‡ç­¾
                let mut found_end = false;
                let mut end_pos = 0;
                let mut tag_len = 0;

                for end_tag in END_TAGS {
                    if let Some(pos) = buffer.find(end_tag) {
                        if !found_end || pos < end_pos {
                            found_end = true;
                            end_pos = pos;
                            tag_len = end_tag.len();
                        }
                    }
                }

                if found_end {
                    // æ‰¾åˆ°ç»“æŸæ ‡ç­¾ï¼Œè¾“å‡º thinking å†…å®¹
                    let thinking_content: String = buffer.drain(..end_pos).collect();
                    // ç§»é™¤ç»“æŸæ ‡ç­¾
                    let _: String = buffer.drain(..tag_len).collect();
                    drop(buffer);

                    if !thinking_content.is_empty() && self.enable_thinking {
                        // ç´¯ç§¯æ¨ç†å†…å®¹
                        self.ctx.append_reasoning(&thinking_content);
                        // å‘å°„ thinking chunk
                        if let Some(block_id) = self.ensure_thinking_started_for_tag() {
                            self.ctx.emit_chunk(
                                event_types::THINKING,
                                &block_id,
                                &thinking_content,
                            );
                        }
                    }

                    // é€€å‡º thinking æ¨¡å¼
                    *self.in_think_tag.lock().unwrap_or_else(|e| e.into_inner()) = false;
                    // ç»§ç»­å¤„ç†å‰©ä½™å†…å®¹
                } else {
                    // æœªæ‰¾åˆ°å®Œæ•´çš„ç»“æŸæ ‡ç­¾ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ½œåœ¨çš„ä¸å®Œæ•´æ ‡ç­¾
                    if ChatV2LLMAdapter::ends_with_potential_think_end(&buffer) {
                        // ä¿ç•™å¯èƒ½çš„ä¸å®Œæ•´æ ‡ç­¾ï¼Œç­‰å¾…æ›´å¤šæ•°æ®
                        return;
                    }
                    // æ²¡æœ‰æ½œåœ¨æ ‡ç­¾ï¼Œè¾“å‡ºæ‰€æœ‰å†…å®¹åˆ° thinking
                    let thinking_content = std::mem::take(&mut *buffer);
                    drop(buffer);

                    if !thinking_content.is_empty() && self.enable_thinking {
                        self.ctx.append_reasoning(&thinking_content);
                        if let Some(block_id) = self.ensure_thinking_started_for_tag() {
                            self.ctx.emit_chunk(
                                event_types::THINKING,
                                &block_id,
                                &thinking_content,
                            );
                        }
                    }
                    return;
                }
            } else {
                // å½“å‰ä¸åœ¨ <think> æ ‡ç­¾å†…ï¼Œå¯»æ‰¾å¼€å§‹æ ‡ç­¾
                let mut found_start = false;
                let mut start_pos = 0;
                let mut tag_len = 0;

                for start_tag in START_TAGS {
                    if let Some(pos) = buffer.find(start_tag) {
                        if !found_start || pos < start_pos {
                            found_start = true;
                            start_pos = pos;
                            tag_len = start_tag.len();
                        }
                    }
                }

                if found_start {
                    // æ‰¾åˆ°å¼€å§‹æ ‡ç­¾ï¼Œå…ˆè¾“å‡ºæ ‡ç­¾å‰çš„ content
                    let content_before: String = buffer.drain(..start_pos).collect();
                    // ç§»é™¤å¼€å§‹æ ‡ç­¾
                    let _: String = buffer.drain(..tag_len).collect();
                    drop(buffer);

                    if !content_before.is_empty() {
                        // ç´¯ç§¯å†…å®¹
                        self.ctx.append_content(&content_before);
                        // å‘å°„ content chunk
                        if let Some(block_id) = self.ensure_content_started_for_tag() {
                            self.ctx
                                .emit_chunk(event_types::CONTENT, &block_id, &content_before);
                        }
                    }

                    // è¿›å…¥ thinking æ¨¡å¼
                    *self.in_think_tag.lock().unwrap_or_else(|e| e.into_inner()) = true;
                    // ç»§ç»­å¤„ç†å‰©ä½™å†…å®¹
                } else {
                    // æœªæ‰¾åˆ°å®Œæ•´çš„å¼€å§‹æ ‡ç­¾ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ½œåœ¨çš„ä¸å®Œæ•´æ ‡ç­¾
                    if ChatV2LLMAdapter::ends_with_potential_think_start(&buffer) {
                        // æ‰¾åˆ°æœ€åä¸€ä¸ª '<' çš„ä½ç½®ï¼Œä¿ç•™å¯èƒ½çš„ä¸å®Œæ•´æ ‡ç­¾
                        if let Some(lt_pos) = buffer.rfind('<') {
                            // è¾“å‡º '<' ä¹‹å‰çš„å†…å®¹
                            let content_before: String = buffer.drain(..lt_pos).collect();
                            drop(buffer);

                            if !content_before.is_empty() {
                                self.ctx.append_content(&content_before);
                                if let Some(block_id) = self.ensure_content_started_for_tag() {
                                    self.ctx.emit_chunk(
                                        event_types::CONTENT,
                                        &block_id,
                                        &content_before,
                                    );
                                }
                            }
                        }
                        return;
                    }
                    // æ²¡æœ‰æ½œåœ¨æ ‡ç­¾ï¼Œè¾“å‡ºæ‰€æœ‰å†…å®¹åˆ° content
                    let content = std::mem::take(&mut *buffer);
                    drop(buffer);

                    if !content.is_empty() {
                        self.ctx.append_content(&content);
                        if let Some(block_id) = self.ensure_content_started_for_tag() {
                            self.ctx
                                .emit_chunk(event_types::CONTENT, &block_id, &content);
                        }
                    }
                    return;
                }
            }
        }
    }

    pub fn get_thinking_block_id(&self) -> Option<String> {
        let finalized = self
            .finalized_thinking_block_id
            .lock()
            .unwrap_or_else(|e| e.into_inner())
            .clone();
        if finalized.is_some() {
            return finalized;
        }
        self.ctx.get_thinking_block_id()
    }

    pub fn get_accumulated_reasoning(&self) -> Option<String> {
        self.ctx.get_accumulated_reasoning()
    }

    pub fn take_tool_calls(&self) -> Vec<ToolCall> {
        self.ctx.take_tool_calls()
    }

    pub fn get_content_block_id(&self) -> Option<String> {
        self.ctx.get_content_block_id()
    }

    pub fn reset_for_new_round(&self) {
        *self
            .content_block_initialized
            .lock()
            .unwrap_or_else(|e| e.into_inner()) = false;
        *self
            .thinking_block_initialized
            .lock()
            .unwrap_or_else(|e| e.into_inner()) = false;
        *self
            .finalized_thinking_block_id
            .lock()
            .unwrap_or_else(|e| e.into_inner()) = None;
        // ğŸ”§ é‡ç½® <think> æ ‡ç­¾è§£æçŠ¶æ€
        *self.in_think_tag.lock().unwrap_or_else(|e| e.into_inner()) = false;
        *self
            .think_tag_buffer
            .lock()
            .unwrap_or_else(|e| e.into_inner()) = String::new();
        self.ctx.reset_for_new_round();
    }
}

impl crate::llm_manager::LLMStreamHooks for VariantLLMAdapter {
    /// ğŸ”§ å¢å¼ºçš„ on_content_chunkï¼šæ”¯æŒ `<think>` æ ‡ç­¾å®æ—¶è§£æ
    ///
    /// æŸäº›ä¸­è½¬ç«™ä¸æ”¯æŒ Anthropic Extended Thinking APIï¼Œè€Œæ˜¯å°†æ€ç»´é“¾ä½œä¸º
    /// `<think>...</think>` æˆ– `<thinking>...</thinking>` æ ‡ç­¾åµŒå…¥åˆ°æ™®é€šå†…å®¹ä¸­ã€‚
    /// æ­¤æ–¹æ³•å®æ—¶è§£æè¿™äº›æ ‡ç­¾ï¼Œå°†å†…å®¹æ­£ç¡®è·¯ç”±åˆ° thinking æˆ– content å—ã€‚
    fn on_content_chunk(&self, text: &str) {
        if text.is_empty() {
            return;
        }

        // ğŸ”§ <think> æ ‡ç­¾è§£æï¼šå°† chunk è¿½åŠ åˆ°ç¼“å†²åŒºå¹¶å¤„ç†
        {
            let mut buffer = self
                .think_tag_buffer
                .lock()
                .unwrap_or_else(|e| e.into_inner());
            buffer.push_str(text);
        }
        self.process_think_tag_buffer();
    }

    fn on_reasoning_chunk(&self, text: &str) {
        if !self.enable_thinking {
            return;
        }

        let mut initialized = self
            .thinking_block_initialized
            .lock()
            .unwrap_or_else(|e| e.into_inner());
        if !*initialized {
            let block_id = MessageBlock::generate_id();
            self.ctx.set_thinking_block_id(&block_id);
            self.ctx.emit_start(event_types::THINKING, &block_id, None);
            *initialized = true;
        }
        drop(initialized);

        if let Some(block_id) = self.ctx.get_thinking_block_id() {
            self.ctx.emit_chunk(event_types::THINKING, &block_id, text);
            self.ctx.append_reasoning(text);
        }
    }

    fn on_tool_call_start(&self, tool_call_id: &str, tool_name: &str) {
        log::info!(
            "[ChatV2::VariantAdapter] Tool call start: variant={}, id={}, name={}",
            self.ctx.variant_id(),
            tool_call_id,
            tool_name
        );

        if ChatV2LLMAdapter::is_builtin_retrieval_tool(tool_name) {
            return;
        }

        self.ctx.emit_tool_call_preparing(tool_call_id, tool_name);
    }

    fn on_tool_call(&self, msg: &LegacyChatMessage) {
        if let Some(ref tool_call) = msg.tool_call {
            self.ctx.add_tool_call(ToolCall {
                id: tool_call.id.clone(),
                name: tool_call.tool_name.clone(),
                arguments: tool_call.args_json.clone(),
            });

            log::info!(
                "[ChatV2::VariantAdapter] Collected tool call: variant={}, id={}, name={}",
                self.ctx.variant_id(),
                tool_call.id,
                tool_call.tool_name
            );
        }
    }

    fn on_tool_result(&self, msg: &LegacyChatMessage) {
        if let Some(ref tool_result) = msg.tool_result {
            log::debug!(
                "[ChatV2::VariantAdapter] on_tool_result: variant={}, call_id={}",
                self.ctx.variant_id(),
                tool_result.call_id
            );
        }
    }

    fn on_usage(&self, usage: &serde_json::Value) {
        let token_usage = parse_api_usage(usage);

        if let Some(u) = token_usage {
            self.ctx.set_usage(u.clone());

            log::info!(
                "[ChatV2::VariantAdapter] variant={} usage: prompt={}, completion={}, total={}, source={:?}",
                self.ctx.variant_id(),
                u.prompt_tokens,
                u.completion_tokens,
                u.total_tokens,
                u.source
            );
        } else {
            log::warn!(
                "[ChatV2::VariantAdapter] variant={} failed to parse usage: {:?}",
                self.ctx.variant_id(),
                usage
            );
        }
    }

    fn on_complete(&self, _final_text: &str, _reasoning: Option<&str>) {
        self.finalize_all();
    }
}

// æµ‹è¯•æ¨¡å—å·²åˆ†ç¦»è‡³ pipeline_tests.rs
