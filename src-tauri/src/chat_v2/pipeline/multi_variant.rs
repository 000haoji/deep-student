use super::*;

impl ChatV2Pipeline {
    // ========================================================================
    // å¤šæ¨¡å‹å¹¶è¡Œå˜ä½“æ‰§è¡Œ (Prompt 5)
    // ========================================================================

    /// æœ€å¤§å˜ä½“æ•°é™åˆ¶ï¼ˆé»˜è®¤å€¼ï¼‰
    const DEFAULT_MAX_VARIANTS: u32 = 10;

    /// å¤šæ¨¡å‹å¹¶è¡Œæ‰§è¡Œå…¥å£
    ///
    /// ## æ‰§è¡Œæµç¨‹
    /// 1. åˆ›å»ºç”¨æˆ·æ¶ˆæ¯å’ŒåŠ©æ‰‹æ¶ˆæ¯
    /// 2. æ‰§è¡Œå…±äº«æ£€ç´¢ â†’ SharedContext
    /// 3. æŒä¹…åŒ– shared_context
    /// 4. ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»º VariantExecutionContext
    /// 5. å‘å°„ stream_start
    /// 6. tokio::spawn + join_all å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å˜ä½“
    /// 7. æ”¶é›†å˜ä½“ç»“æœï¼Œç¡®å®š active_variant_idï¼ˆç¬¬ä¸€ä¸ªæˆåŠŸçš„ï¼‰
    /// 8. æŒä¹…åŒ–å˜ä½“åˆ—è¡¨
    /// 9. å‘å°„ stream_complete
    ///
    /// ## çº¦æŸ
    /// - æ£€ç´¢åªæ‰§è¡Œä¸€æ¬¡
    /// - å¤šå˜ä½“æ¨¡å¼ä¸‹å¼ºåˆ¶ anki_enabled = false
    /// - è¶…è¿‡ max_variants_per_message è¿”å› LimitExceeded é”™è¯¯
    /// - active_variant_id é»˜è®¤è®¾ä¸ºç¬¬ä¸€ä¸ªæˆåŠŸçš„å˜ä½“
    ///
    /// ## å‚æ•°
    /// - `window`: Tauri çª—å£å¥æŸ„
    /// - `request`: å‘é€æ¶ˆæ¯è¯·æ±‚
    /// - `model_ids`: è¦å¹¶è¡Œæ‰§è¡Œçš„æ¨¡å‹ ID åˆ—è¡¨
    /// - `cancel_token`: å–æ¶ˆä»¤ç‰Œ
    ///
    /// ## è¿”å›
    /// åŠ©æ‰‹æ¶ˆæ¯ ID
    /// ğŸ”§ P1ä¿®å¤ï¼šæ·»åŠ  chat_v2_state å‚æ•°ï¼Œç”¨äºæ³¨å†Œæ¯ä¸ªå˜ä½“çš„ cancel token
    pub async fn execute_multi_variant(
        &self,
        window: tauri::Window,
        request: SendMessageRequest,
        model_ids: Vec<String>,
        cancel_token: CancellationToken,
        chat_v2_state: Option<Arc<super::super::state::ChatV2State>>,
    ) -> ChatV2Result<String> {
        use super::super::variant_context::{ParallelExecutionManager, VariantExecutionContext};
        use futures::future::join_all;

        let start_time = Instant::now();
        let session_id = request.session_id.clone();
        let user_content = request.content.clone();
        let mut options = request.options.clone().unwrap_or_default();

        // === 0. æ™ºèƒ½ vision_quality è®¡ç®—ï¼ˆä¸å•å˜ä½“è·¯å¾„ä¿æŒä¸€è‡´ï¼‰===
        // å¦‚æœç”¨æˆ·æ²¡æœ‰æ˜¾å¼æŒ‡å®šï¼Œæ ¹æ®å›¾ç‰‡æ•°é‡å’Œæ¥æºè‡ªåŠ¨é€‰æ‹©å‹ç¼©ç­–ç•¥
        if options
            .vision_quality
            .as_deref()
            .filter(|v| !v.is_empty() && *v != "auto")
            .is_none()
        {
            let user_refs = request.user_context_refs.as_deref().unwrap_or(&[]);
            let mut image_count = 0usize;
            let mut has_pdf_or_textbook = false;

            for ctx_ref in user_refs {
                // ç»Ÿè®¡å›¾ç‰‡å—æ•°é‡
                for block in &ctx_ref.formatted_blocks {
                    if matches!(block, super::super::resource_types::ContentBlock::Image { .. }) {
                        image_count += 1;
                    }
                }
                // æ£€æŸ¥æ˜¯å¦æœ‰ PDF/æ•™ææ¥æº
                let type_id_lower = ctx_ref.type_id.to_lowercase();
                if type_id_lower.contains("pdf")
                    || type_id_lower.contains("textbook")
                    || type_id_lower.contains("file")
                    || ctx_ref.resource_id.starts_with("tb_")
                {
                    has_pdf_or_textbook = true;
                }
            }

            // æ™ºèƒ½ç­–ç•¥
            let auto_quality = if has_pdf_or_textbook || image_count >= 6 {
                "low" // PDF/æ•™æ æˆ–å¤§é‡å›¾ç‰‡ï¼šæœ€å¤§å‹ç¼©
            } else if image_count >= 2 {
                "medium" // ä¸­ç­‰æ•°é‡ï¼šå¹³è¡¡å‹ç¼©
            } else {
                "high" // å•å›¾æˆ–æ— å›¾ï¼šä¿æŒåŸè´¨é‡
            };

            log::info!(
                "[ChatV2::pipeline] Multi-variant vision_quality: auto -> '{}' (images={}, has_pdf_or_textbook={})",
                auto_quality, image_count, has_pdf_or_textbook
            );
            options.vision_quality = Some(auto_quality.to_string());
        }

        // === 1. çº¦æŸæ£€æŸ¥ ===
        // æ£€æŸ¥å˜ä½“æ•°é‡é™åˆ¶
        let max_variants = options
            .max_variants_per_message
            .unwrap_or(Self::DEFAULT_MAX_VARIANTS);
        if model_ids.len() as u32 > max_variants {
            return Err(ChatV2Error::LimitExceeded(format!(
                "Variant count {} exceeds maximum allowed {}",
                model_ids.len(),
                max_variants
            )));
        }

        if model_ids.is_empty() {
            return Err(ChatV2Error::Other("No model IDs provided".to_string()));
        }

        // ğŸ”§ 2025-01-27 å¯¹é½å•å˜ä½“ï¼šå¤šå˜ä½“æ¨¡å¼ç°åœ¨æ”¯æŒ Ankiï¼Œä½¿ç”¨ç”¨æˆ·é…ç½®çš„å€¼
        // options.anki_enabled ä¿æŒç”¨æˆ·é…ç½®ï¼Œä¸å†å¼ºåˆ¶ç¦ç”¨

        // === è·å– API é…ç½®ï¼Œæ„å»º config_id -> model çš„æ˜ å°„ ===
        // å‰ç«¯ä¼ é€’çš„æ˜¯ API é…ç½® IDï¼Œæˆ‘ä»¬éœ€è¦ä»ä¸­æå–çœŸæ­£çš„æ¨¡å‹åç§°ç”¨äºå‰ç«¯æ˜¾ç¤º
        let api_configs = self
            .llm_manager
            .get_api_configs()
            .await
            .map_err(|e| ChatV2Error::Other(format!("Failed to get API configs: {}", e)))?;

        // æ„å»º config_id -> (model, config_id) çš„æ˜ å°„
        // model: ç”¨äºå‰ç«¯æ˜¾ç¤ºï¼ˆå¦‚ "Qwen/Qwen3-8B"ï¼‰
        // config_id: ç”¨äº LLM è°ƒç”¨
        let config_map: std::collections::HashMap<String, (String, String)> = api_configs
            .into_iter()
            .map(|c| (c.id.clone(), (c.model.clone(), c.id)))
            .collect();

        // è§£æ model_idsï¼Œæå–çœŸæ­£çš„æ¨¡å‹åç§°å’Œé…ç½® ID
        let resolved_models: Vec<(String, String)> = model_ids
            .iter()
            .filter_map(|config_id| {
                config_map.get(config_id).cloned().or_else(|| {
                    // ğŸ”§ ä¸‰è½®ä¿®å¤ï¼šå¦‚æœ config_id æ˜¯é…ç½® UUIDï¼Œä¸åº”ä½œä¸ºæ¨¡å‹æ˜¾ç¤ºåç§°
                    if is_config_id_format(config_id) {
                        log::warn!(
                            "[ChatV2::pipeline] Config not found for id and id is a config format, using empty display name: {}",
                            config_id
                        );
                        Some((String::new(), config_id.clone()))
                    } else {
                        log::warn!(
                            "[ChatV2::pipeline] Config not found for id: {}, using as model name",
                            config_id
                        );
                        Some((config_id.clone(), config_id.clone()))
                    }
                })
            })
            .collect();

        log::info!(
            "[ChatV2::pipeline] execute_multi_variant: session={}, models={:?}, content_len={}",
            session_id,
            resolved_models.iter().map(|(m, _)| m).collect::<Vec<_>>(),
            user_content.len()
        );

        // === 2. ä½¿ç”¨è¯·æ±‚ä¸­çš„æ¶ˆæ¯ IDï¼ˆå¦‚æœæä¾›ï¼‰ï¼Œå¦åˆ™ç”Ÿæˆæ–°çš„ ===
        // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨å‰ç«¯ä¼ é€’çš„ IDï¼Œç¡®ä¿å‰åç«¯ä¸€è‡´
        let user_message_id = request
            .user_message_id
            .clone()
            .unwrap_or_else(ChatMessage::generate_id);
        let assistant_message_id = request
            .assistant_message_id
            .clone()
            .unwrap_or_else(ChatMessage::generate_id);

        // === 3. åˆ›å»ºäº‹ä»¶å‘å°„å™¨ ===
        let emitter = Arc::new(ChatV2EventEmitter::new(window.clone(), session_id.clone()));

        // === 4. æ‰§è¡Œå…±äº«æ£€ç´¢ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰===
        let shared_context = self
            .execute_shared_retrievals(&request, &emitter, &assistant_message_id)
            .await?;
        let shared_context = Arc::new(shared_context);

        log::debug!(
            "[ChatV2::pipeline] Shared retrievals completed: has_sources={}",
            shared_context.has_sources()
        );

        // === 5. å‘å°„ stream_start ===
        // å¤šå˜ä½“æ¨¡å¼ä¸åœ¨ stream_start ä¸­ä¼ é€’æ¨¡å‹åç§°ï¼Œæ¯ä¸ªå˜ä½“é€šè¿‡ variant_start äº‹ä»¶ä¼ é€’
        emitter.emit_stream_start(&assistant_message_id, None);

        // ğŸ†• P0é˜²é—ªé€€ï¼šç”¨æˆ·æ¶ˆæ¯å³æ—¶ä¿å­˜ï¼ˆå¤šå˜ä½“æ¨¡å¼ï¼‰
        // åœ¨å˜ä½“æ‰§è¡Œå‰ç«‹å³ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼Œç¡®ä¿ç”¨æˆ·è¾“å…¥ä¸ä¼šå› é—ªé€€ä¸¢å¤±
        if !options.skip_user_message_save.unwrap_or(false) {
            // æ„å»ºä¸´æ—¶ PipelineContext ç”¨äºä¿å­˜ç”¨æˆ·æ¶ˆæ¯
            let temp_request = SendMessageRequest {
                session_id: session_id.clone(),
                content: user_content.clone(),
                user_message_id: Some(user_message_id.clone()),
                assistant_message_id: Some(assistant_message_id.clone()),
                options: Some(options.clone()),
                user_context_refs: request.user_context_refs.clone(),
                path_map: request.path_map.clone(),
                workspace_id: request.workspace_id.clone(),
            };
            let temp_ctx = PipelineContext::new(temp_request);
            if let Err(e) = self.save_user_message_immediately(&temp_ctx).await {
                log::warn!(
                    "[ChatV2::pipeline] Multi-variant: Failed to save user message immediately: {}",
                    e
                );
            } else {
                log::info!(
                    "[ChatV2::pipeline] Multi-variant: User message saved immediately: id={}",
                    user_message_id
                );
            }
        }

        // === 6. åˆ›å»ºå¹¶è¡Œæ‰§è¡Œç®¡ç†å™¨ ===
        let manager = ParallelExecutionManager::with_cancel_token(cancel_token.clone());

        // ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»º VariantExecutionContext
        // ä½¿ç”¨ resolved_models ä¸­çš„ (æ¨¡å‹åç§°, é…ç½®ID) å…ƒç»„
        // - æ¨¡å‹åç§°ï¼šä¼ é€’ç»™å˜ä½“ä¸Šä¸‹æ–‡ï¼Œç”¨äºå‰ç«¯æ˜¾ç¤º
        // - é…ç½®IDï¼šç”¨äº LLM è°ƒç”¨
        let mut variant_contexts: Vec<(Arc<VariantExecutionContext>, String)> =
            Vec::with_capacity(resolved_models.len());
        for (model_name, config_id) in &resolved_models {
            let variant_id = Variant::generate_id();
            let ctx = manager.create_variant(
                variant_id.clone(),
                model_name.clone(), // ä½¿ç”¨æ¨¡å‹åç§°ï¼Œç”¨äºå‰ç«¯æ˜¾ç¤º
                assistant_message_id.clone(),
                Arc::clone(&shared_context),
                Arc::clone(&emitter),
            );

            // ğŸ”§ P2ä¿®å¤ï¼šè®¾ç½® config_idï¼Œç”¨äºé‡è¯•æ—¶æ­£ç¡®é€‰æ‹©æ¨¡å‹
            ctx.set_config_id(config_id.clone());

            // ğŸ”§ P1ä¿®å¤ï¼šä¸ºæ¯ä¸ªå˜ä½“æ³¨å†Œç‹¬ç«‹çš„ cancel token
            // ä½¿ç”¨ session_id:variant_id ä½œä¸º keyï¼Œè¿™æ ·å¯ä»¥ç²¾ç¡®å–æ¶ˆå•ä¸ªå˜ä½“
            if let Some(ref state) = chat_v2_state {
                let cancel_key = format!("{}:{}", session_id, variant_id);
                state.register_existing_token(&cancel_key, ctx.cancel_token().clone());
                log::debug!(
                    "[ChatV2::pipeline] Registered cancel token for variant: {}",
                    cancel_key
                );
            }

            variant_contexts.push((ctx, config_id.clone())); // ä¿å­˜é…ç½®IDç”¨äºLLMè°ƒç”¨
        }

        // === 6.5 é˜²é—ªé€€ï¼šæŒä¹…åŒ–åŠ©æ‰‹æ¶ˆæ¯éª¨æ¶ï¼ˆå« pending å˜ä½“åˆ—è¡¨ï¼‰===
        // åœ¨å˜ä½“æ‰§è¡Œå‰å†™å…¥ DBï¼Œç¡®ä¿åˆ·æ–°/å´©æºƒåä»èƒ½è¯†åˆ«ä¸ºå¤šå˜ä½“æ¶ˆæ¯ã€‚
        // save_multi_variant_results ä½¿ç”¨ INSERT OR REPLACE åœ¨å®Œæˆåè¦†ç›–æ­¤éª¨æ¶ã€‚
        {
            let skeleton_variants: Vec<Variant> = variant_contexts
                .iter()
                .map(|(ctx, _)| {
                    Variant::new_with_id_and_config(
                        ctx.variant_id().to_string(),
                        ctx.model_id().to_string(),
                        ctx.get_config_id().unwrap_or_default(),
                    )
                })
                .collect();

            let first_variant_id = skeleton_variants.first().map(|v| v.id.clone());

            let skeleton_msg = ChatMessage {
                id: assistant_message_id.clone(),
                session_id: session_id.clone(),
                role: MessageRole::Assistant,
                block_ids: Vec::new(),
                timestamp: chrono::Utc::now().timestamp_millis(),
                persistent_stable_id: None,
                parent_id: None,
                supersedes: None,
                meta: Some(MessageMeta {
                    model_id: None,
                    chat_params: Some(serde_json::json!({
                        "multiVariantMode": true,
                    })),
                    sources: None,
                    tool_results: None,
                    anki_cards: None,
                    usage: None,
                    context_snapshot: None,
                }),
                attachments: None,
                active_variant_id: first_variant_id,
                variants: Some(skeleton_variants),
                shared_context: Some((*shared_context).clone()),
            };

            if let Ok(conn) = self.db.get_conn_safe() {
                if let Err(e) = ChatV2Repo::create_message_with_conn(&conn, &skeleton_msg) {
                    log::warn!(
                        "[ChatV2::pipeline] Failed to persist skeleton assistant message (non-fatal): {}",
                        e
                    );
                } else {
                    log::info!(
                        "[ChatV2::pipeline] Persisted skeleton assistant message: id={}, variants={}",
                        assistant_message_id,
                        variant_contexts.len()
                    );
                }
            }
        }

        // === 7. å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å˜ä½“ ===
        let self_clone = self.clone();
        let options_arc = Arc::new(options.clone());
        let user_content_arc = Arc::new(user_content.clone());
        let session_id_arc = Arc::new(session_id.clone());

        // ğŸ”§ P1ä¿®å¤ï¼šä½¿ç”¨ä»»åŠ¡è¿½è¸ªå™¨è¿½è¸ªå¹¶è¡Œä»»åŠ¡
        // åˆ›å»ºå¹¶è¡Œä»»åŠ¡
        let futures: Vec<_> = variant_contexts.iter().map(|(ctx, config_id)| {
            let self_ref = self_clone.clone();
            let ctx_clone = Arc::clone(ctx);
            let config_id_clone = config_id.clone();  // API é…ç½® IDï¼Œç”¨äº LLM è°ƒç”¨
            let options_clone = Arc::clone(&options_arc);
            let user_content_clone = Arc::clone(&user_content_arc);
            let session_id_clone = Arc::clone(&session_id_arc);
            let shared_ctx = Arc::clone(&shared_context);
            // â˜… 2025-12-10 ç»Ÿä¸€æ”¹é€ ï¼šé™„ä»¶ä¸å†é€šè¿‡ request.attachments ä¼ é€’
            let attachments = Vec::new();
            let state_clone = chat_v2_state.clone();

            let future = async move {
                self_ref.execute_single_variant_with_config(
                    ctx_clone,
                    config_id_clone,  // ä¼ é€’ API é…ç½® ID
                    (*options_clone).clone(),
                    (*user_content_clone).clone(),
                    (*session_id_clone).clone(),
                    shared_ctx,
                    attachments,
                ).await
            };

            // ğŸ”§ P1ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ spawn_tracked è¿½è¸ªä»»åŠ¡
            if let Some(ref state) = state_clone {
                state.spawn_tracked(future)
            } else {
                log::warn!("[ChatV2::pipeline] spawn_tracked unavailable, using untracked tokio::spawn for variant task");
                tokio::spawn(future)
            }
        }).collect();

        // ç­‰å¾…æ‰€æœ‰å˜ä½“å®Œæˆ
        let results = join_all(futures).await;

        // å¤„ç†ç»“æœ
        for (i, result) in results.into_iter().enumerate() {
            let (ctx, _) = &variant_contexts[i];
            match result {
                Ok(Ok(())) => {
                    log::info!(
                        "[ChatV2::pipeline] Variant {} completed successfully",
                        ctx.variant_id()
                    );
                }
                Ok(Err(e)) => {
                    log::error!(
                        "[ChatV2::pipeline] Variant {} failed: {}",
                        ctx.variant_id(),
                        e
                    );
                    // é”™è¯¯å·²ç»åœ¨ execute_single_variant_with_config ä¸­å¤„ç†
                }
                Err(e) => {
                    log::error!(
                        "[ChatV2::pipeline] Variant {} task panicked: {}",
                        ctx.variant_id(),
                        e
                    );
                    // æ ‡è®°ä¸ºé”™è¯¯
                    ctx.fail(&format!("Task panicked: {}", e));
                }
            }
        }

        // === 8. ç¡®å®š active_variant_id ===
        let active_variant_id = manager.get_first_success();

        log::info!(
            "[ChatV2::pipeline] Multi-variant execution completed: active_variant={:?}, success={}, error={}",
            active_variant_id,
            manager.success_count(),
            manager.error_count()
        );

        // === 9. æ„å»ºä¸Šä¸‹æ–‡å¿«ç…§ï¼ˆç»Ÿä¸€ä¸Šä¸‹æ–‡æ³¨å…¥ç³»ç»Ÿï¼‰ ===
        let context_snapshot = {
            let mut snapshot = ContextSnapshot::new();

            // 9.1 æ·»åŠ ç”¨æˆ·ä¸Šä¸‹æ–‡å¼•ç”¨
            if let Some(ref user_refs) = request.user_context_refs {
                for send_ref in user_refs {
                    snapshot.add_user_ref(send_ref.to_context_ref());
                }
            }

            // 9.2 ä¸ºæ£€ç´¢ç»“æœåˆ›å»ºèµ„æºï¼ˆå¦‚æœæœ‰ï¼‰
            // æ³¨ï¼šå¤šå˜ä½“æ¨¡å¼ä¸‹æ£€ç´¢ç»“æœå­˜å‚¨åœ¨ shared_context ä¸­
            // è¿™é‡Œæˆ‘ä»¬å°†æ£€ç´¢ç»“æœè½¬æ¢ä¸º retrieval ç±»å‹çš„èµ„æº
            // TODO: å¦‚æœéœ€è¦æ›´ç²¾ç»†çš„æ£€ç´¢èµ„æºç®¡ç†ï¼Œå¯ä»¥åœ¨ execute_shared_retrievals ä¸­ç›´æ¥åˆ›å»ºèµ„æº

            if snapshot.has_refs() {
                log::debug!(
                    "[ChatV2::pipeline] Multi-variant context snapshot: user_refs={}, retrieval_refs={}",
                    snapshot.user_refs.len(),
                    snapshot.retrieval_refs.len()
                );
                Some(snapshot)
            } else {
                None
            }
        };

        // === 10. æŒä¹…åŒ–æ¶ˆæ¯å’Œå˜ä½“ ===
        // æå–çº¯å˜ä½“ä¸Šä¸‹æ–‡åˆ—è¡¨ç”¨äºä¿å­˜
        let contexts_only: Vec<Arc<VariantExecutionContext>> = variant_contexts
            .iter()
            .map(|(ctx, _)| Arc::clone(ctx))
            .collect();
        // â˜… 2025-12-10 ç»Ÿä¸€æ”¹é€ ï¼šé™„ä»¶ä¸å†é€šè¿‡ request.attachments ä¼ é€’
        let empty_attachments: Vec<crate::chat_v2::types::AttachmentInput> = Vec::new();
        let save_result = self.save_multi_variant_results(
            &session_id,
            &user_message_id,
            &assistant_message_id,
            &user_content,
            &empty_attachments,
            &options,
            &shared_context,
            &contexts_only,
            active_variant_id.as_deref(),
            context_snapshot,
        )
        .await;

        // === 11. æ¸…ç†æ¯ä¸ªå˜ä½“çš„ cancel tokenï¼ˆæ— è®ºä¿å­˜æˆè´¥éƒ½å¿…é¡»æ‰§è¡Œï¼‰===
        if let Some(ref state) = chat_v2_state {
            for (ctx, _) in &variant_contexts {
                let cancel_key = format!("{}:{}", session_id, ctx.variant_id());
                state.remove_stream(&cancel_key);
            }
            log::debug!(
                "[ChatV2::pipeline] Cleaned up {} variant cancel tokens",
                variant_contexts.len()
            );
        }

        save_result?;

        // === 12. å‘å°„ stream_completeï¼ˆå¸¦ token ç»Ÿè®¡ï¼‰ ===
        let duration_ms = start_time.elapsed().as_millis() as u64;
        // å¤šå˜ä½“æ¨¡å¼ä¸‹ Message._meta.usage ä¸º Noneï¼Œæ¯ä¸ªå˜ä½“ç‹¬ç«‹ç»Ÿè®¡
        // TODO: Prompt 9 å®ç°åï¼Œå¯é€‰æ‹©æ€§æ±‡æ€»æ‰€æœ‰å˜ä½“çš„ token ç»Ÿè®¡
        emitter.emit_stream_complete_with_usage(&assistant_message_id, duration_ms, None);

        log::info!(
            "[ChatV2::pipeline] Multi-variant pipeline completed in {}ms",
            duration_ms
        );

        // ğŸ”§ è‡ªåŠ¨ç”Ÿæˆä¼šè¯æ‘˜è¦ï¼ˆå¤šå˜ä½“æ¨¡å¼ï¼‰
        // ä½¿ç”¨ active_variant çš„å†…å®¹æ¥ç”Ÿæˆæ‘˜è¦
        if let Some(active_id) = &active_variant_id {
            if let Some((active_ctx, _)) = variant_contexts
                .iter()
                .find(|(ctx, _)| ctx.variant_id() == active_id.as_str())
            {
                let assistant_content = active_ctx.get_accumulated_content();
                if self
                    .should_generate_summary(&session_id, &user_content, &assistant_content)
                    .await
                {
                    let pipeline = self.clone();
                    let sid = session_id.clone();
                    let emitter_clone = emitter.clone();
                    let user_content_clone = user_content.clone();

                    // ğŸ†• P1ä¿®å¤ï¼šä½¿ç”¨ TaskTracker è¿½è¸ªå¼‚æ­¥ä»»åŠ¡
                    let summary_future = async move {
                        pipeline
                            .generate_summary(
                                &sid,
                                &user_content_clone,
                                &assistant_content,
                                emitter_clone,
                            )
                            .await;
                    };

                    // ğŸ”§ P1ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ spawn_tracked è¿½è¸ªæ‘˜è¦ä»»åŠ¡
                    if let Some(ref state) = chat_v2_state {
                        state.spawn_tracked(summary_future);
                    } else {
                        log::warn!("[ChatV2::pipeline] spawn_tracked unavailable, using untracked tokio::spawn for summary task (multi-variant)");
                        tokio::spawn(summary_future);
                    }
                }
            }
        }

        Ok(assistant_message_id)
    }

    /// æ‰§è¡Œå•ä¸ªå˜ä½“
    ///
    /// åœ¨éš”ç¦»çš„ä¸Šä¸‹æ–‡ä¸­æ‰§è¡Œ LLM è°ƒç”¨ï¼Œæ”¯æŒå·¥å…·é€’å½’ã€‚
    ///
    /// ## å‚æ•°
    /// - `ctx`: å˜ä½“æ‰§è¡Œä¸Šä¸‹æ–‡
    /// - `options`: å‘é€é€‰é¡¹
    /// - `user_content`: ç”¨æˆ·æ¶ˆæ¯å†…å®¹
    /// - `session_id`: ä¼šè¯ ID
    /// - `shared_context`: å…±äº«ä¸Šä¸‹æ–‡ï¼ˆæ£€ç´¢ç»“æœï¼‰
    /// - `attachments`: é™„ä»¶åˆ—è¡¨
    async fn execute_single_variant(
        &self,
        ctx: Arc<super::super::variant_context::VariantExecutionContext>,
        mut options: SendOptions,
        user_content: String,
        session_id: String,
        shared_context: Arc<SharedContext>,
        attachments: Vec<AttachmentInput>,
    ) -> ChatV2Result<()> {
        // ä½¿ç”¨å˜ä½“çš„æ¨¡å‹ ID
        options.model_id = Some(ctx.model_id().to_string());
        options.model2_override_id = Some(ctx.model_id().to_string());

        // å¼€å§‹æµå¼ç”Ÿæˆ
        ctx.start_streaming();

        // æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
        if ctx.is_cancelled() {
            ctx.cancel();
            return Ok(());
        }

        // æ„å»ºç³»ç»Ÿæç¤ºï¼ˆåŒ…å«å…±äº«çš„æ£€ç´¢ç»“æœï¼‰
        let system_prompt = self
            .build_system_prompt_with_shared_context(&options, &shared_context)
            .await;

        // åŠ è½½èŠå¤©å†å²
        let mut chat_history = self.load_variant_chat_history(&session_id).await?;
        // ğŸ†• 2026-02-22: ä¸ºå·²æ¿€æ´»çš„é»˜è®¤æŠ€èƒ½è‡ªåŠ¨æ³¨å…¥åˆæˆ load_skills å·¥å…·äº¤äº’
        inject_synthetic_load_skills(&mut chat_history, &options);

        // æ„å»ºå½“å‰ç”¨æˆ·æ¶ˆæ¯
        let current_user_message = self.build_variant_user_message(&user_content, &attachments);

        // åˆ›å»º LLM é€‚é…å™¨ï¼ˆä½¿ç”¨å˜ä½“çš„äº‹ä»¶å‘å°„ï¼‰
        let enable_thinking = options.enable_thinking.unwrap_or(true);
        let emitter = Arc::new(VariantLLMAdapter::new(Arc::clone(&ctx), enable_thinking));

        // æ³¨å†Œ LLM æµå¼å›è°ƒ hooks
        // ğŸ”§ P0ä¿®å¤ï¼šæ¯ä¸ªå˜ä½“ä½¿ç”¨å”¯ä¸€çš„ hook é”®ï¼Œé¿å…å¹¶è¡Œæ‰§è¡Œæ—¶äº’ç›¸è¦†ç›–
        // å‰ç«¯ä»ç„¶ç›‘å¬ chat_v2_event_{session_id}ï¼Œå˜ä½“ ID é€šè¿‡ VariantLLMAdapter åœ¨äº‹ä»¶ payload ä¸­æºå¸¦
        let stream_event = format!("chat_v2_event_{}_{}", session_id, ctx.variant_id());
        self.llm_manager
            .register_stream_hooks(&stream_event, emitter.clone())
            .await;

        // æ„å»ºæ¶ˆæ¯å†å²
        let mut messages = chat_history;
        messages.push(current_user_message);

        // æ„å»º LLM ä¸Šä¸‹æ–‡
        let mut llm_context: std::collections::HashMap<String, Value> =
            std::collections::HashMap::new();
        if let Some(ref rag_sources) = shared_context.rag_sources {
            llm_context.insert(
                "prefetched_rag_sources".into(),
                serde_json::to_value(rag_sources).unwrap_or(Value::Null),
            );
        }
        if let Some(ref memory_sources) = shared_context.memory_sources {
            llm_context.insert(
                "prefetched_memory_sources".into(),
                serde_json::to_value(memory_sources).unwrap_or(Value::Null),
            );
        }
        if let Some(ref graph_sources) = shared_context.graph_sources {
            llm_context.insert(
                "prefetched_graph_sources".into(),
                serde_json::to_value(graph_sources).unwrap_or(Value::Null),
            );
        }
        if let Some(ref web_sources) = shared_context.web_search_sources {
            llm_context.insert(
                "prefetched_web_search_sources".into(),
                serde_json::to_value(web_sources).unwrap_or(Value::Null),
            );
        }

        // ğŸ†• å›¾ç‰‡å‹ç¼©ç­–ç•¥ï¼šä» options è·å–æˆ–ä½¿ç”¨é»˜è®¤å€¼
        // å¦‚æœ options.vision_quality æœªè®¾ç½®ï¼Œé»˜è®¤ä½¿ç”¨ "auto" è®© file_manager æ ¹æ®å›¾ç‰‡å¤§å°è‡ªåŠ¨é€‰æ‹©
        let vq = options.vision_quality.as_deref().unwrap_or("auto");
        llm_context.insert("vision_quality".into(), Value::String(vq.to_string()));

        // ğŸ”§ P1ä¿®å¤ï¼šå°† context_limit ä½œä¸º max_input_tokens_override ä¼ é€’ç»™ LLM
        let max_input_tokens_override = options.context_limit.map(|v| v as usize);

        // ğŸ”§ 2025-01-27 å¯¹é½å•å˜ä½“ï¼šå¤šå˜ä½“æ¨¡å¼ç°åœ¨æ”¯æŒå·¥å…·é“¾ï¼Œä½¿ç”¨ options ä¸­çš„é…ç½®
        // æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·å¯ç”¨ï¼ˆä¸ execute_single_variant_with_config ä¿æŒä¸€è‡´ï¼‰
        let has_tools = options
            .mcp_tool_schemas
            .as_ref()
            .map(|s| !s.is_empty())
            .unwrap_or(false);
        let disable_tools = options.disable_tools.unwrap_or(false) || !has_tools;

        // ğŸ”§ 2025-01-27 å¯¹é½å•å˜ä½“ï¼šæ³¨å…¥å·¥å…· schemas åˆ° LLM ä¸Šä¸‹æ–‡
        // æ³¨æ„ï¼šexecute_single_variant ç”¨äºå•æ¬¡å˜ä½“é‡è¯•ï¼Œä¸æ”¯æŒå·¥å…·é€’å½’è°ƒç”¨
        // å¦‚éœ€å®Œæ•´çš„å·¥å…·è°ƒç”¨å¾ªç¯ï¼Œè¯·ä½¿ç”¨ execute_single_variant_with_config
        if !disable_tools {
            if let Some(ref tool_schemas) = options.mcp_tool_schemas {
                let mcp_tool_values: Vec<Value> = tool_schemas
                    .iter()
                    .map(|tool| {
                        let raw_tool_name = if tool.name.starts_with(BUILTIN_NAMESPACE) {
                            tool.name.clone()
                        } else {
                            format!("mcp_{}", tool.name)
                        };
                        let api_tool_name = sanitize_tool_name_for_api(&raw_tool_name);
                        json!({
                            "type": "function",
                            "function": {
                                "name": api_tool_name,
                                "description": tool.description.clone().unwrap_or_default(),
                                "parameters": tool.input_schema.clone().unwrap_or(json!({}))
                            }
                        })
                    })
                    .collect();

                if !mcp_tool_values.is_empty() {
                    llm_context.insert("tools".into(), Value::Array(mcp_tool_values.clone()));
                    log::info!(
                        "[ChatV2::VariantPipeline] execute_single_variant: variant={} injected {} tools",
                        ctx.variant_id(),
                        mcp_tool_values.len()
                    );
                }
            }
        }

        // è°ƒç”¨ LLM
        // ğŸ”§ P1ä¿®å¤ï¼šæ·»åŠ  Pipeline å±‚è¶…æ—¶ä¿æŠ¤
        let llm_future = self.llm_manager.call_unified_model_2_stream(
            &llm_context,
            &messages,
            "",
            true,
            enable_thinking,
            Some("chat_v2_variant"),
            ctx.emitter().window(),
            &stream_event,
            None,
            disable_tools,
            max_input_tokens_override,
            options.model_id.clone(),
            options.temperature,
            Some(system_prompt),
            options.top_p,
            options.frequency_penalty,
            options.presence_penalty,
            options.max_tokens,
        );

        let call_result =
            match timeout(Duration::from_secs(LLM_STREAM_TIMEOUT_SECS), llm_future).await {
                Ok(result) => result,
                Err(_) => {
                    log::error!(
                        "[ChatV2::VariantPipeline] LLM stream call timeout after {}s, variant={}",
                        LLM_STREAM_TIMEOUT_SECS,
                        ctx.variant_id()
                    );
                    self.llm_manager
                        .unregister_stream_hooks(&stream_event)
                        .await;
                    ctx.fail(&format!(
                        "LLM stream call timed out after {}s",
                        LLM_STREAM_TIMEOUT_SECS
                    ));
                    return Err(ChatV2Error::Timeout(format!(
                        "LLM stream call timed out after {}s",
                        LLM_STREAM_TIMEOUT_SECS
                    )));
                }
            };

        // æ³¨é”€ hooks
        self.llm_manager
            .unregister_stream_hooks(&stream_event)
            .await;

        // å¤„ç†ç»“æœ
        match call_result {
            Ok(output) => {
                if output.cancelled {
                    ctx.cancel();
                } else {
                    ctx.complete();
                }
                Ok(())
            }
            Err(e) => {
                ctx.fail(&e.to_string());
                Err(ChatV2Error::Llm(e.to_string()))
            }
        }
    }

    async fn execute_single_variant_with_config(
        &self,
        ctx: Arc<super::super::variant_context::VariantExecutionContext>,
        config_id: String,
        mut options: SendOptions,
        user_content: String,
        session_id: String,
        shared_context: Arc<SharedContext>,
        attachments: Vec<AttachmentInput>,
    ) -> ChatV2Result<()> {
        const MAX_TOOL_ROUNDS: u32 = 10;

        options.model_id = Some(config_id.clone());
        options.model2_override_id = Some(config_id.clone());

        ctx.start_streaming();

        if ctx.is_cancelled() {
            ctx.cancel();
            return Ok(());
        }

        let system_prompt = self
            .build_system_prompt_with_shared_context(&options, &shared_context)
            .await;
        let mut chat_history = self.load_variant_chat_history(&session_id).await?;
        // ğŸ†• 2026-02-22: ä¸ºå·²æ¿€æ´»çš„é»˜è®¤æŠ€èƒ½è‡ªåŠ¨æ³¨å…¥åˆæˆ load_skills å·¥å…·äº¤äº’
        inject_synthetic_load_skills(&mut chat_history, &options);
        let current_user_message = self.build_variant_user_message(&user_content, &attachments);

        let enable_thinking = options.enable_thinking.unwrap_or(true);
        let max_input_tokens_override = options.context_limit.map(|v| v as usize);
        let has_tools = options
            .mcp_tool_schemas
            .as_ref()
            .map(|s| !s.is_empty())
            .unwrap_or(false);
        let disable_tools = options.disable_tools.unwrap_or(false) || !has_tools;

        let mut messages = chat_history;
        messages.push(current_user_message);

        let adapter = Arc::new(VariantLLMAdapter::new(Arc::clone(&ctx), enable_thinking));
        let stream_event = format!("chat_v2_event_{}_{}", session_id, ctx.variant_id());
        self.llm_manager
            .register_stream_hooks(&stream_event, adapter.clone())
            .await;

        let mut llm_context: std::collections::HashMap<String, Value> =
            std::collections::HashMap::new();
        if let Some(ref rag_sources) = shared_context.rag_sources {
            llm_context.insert(
                "prefetched_rag_sources".into(),
                serde_json::to_value(rag_sources).unwrap_or(Value::Null),
            );
        }
        if let Some(ref memory_sources) = shared_context.memory_sources {
            llm_context.insert(
                "prefetched_memory_sources".into(),
                serde_json::to_value(memory_sources).unwrap_or(Value::Null),
            );
        }
        if let Some(ref graph_sources) = shared_context.graph_sources {
            llm_context.insert(
                "prefetched_graph_sources".into(),
                serde_json::to_value(graph_sources).unwrap_or(Value::Null),
            );
        }
        if let Some(ref web_sources) = shared_context.web_search_sources {
            llm_context.insert(
                "prefetched_web_search_sources".into(),
                serde_json::to_value(web_sources).unwrap_or(Value::Null),
            );
        }

        // ğŸ†• å›¾ç‰‡å‹ç¼©ç­–ç•¥ï¼šä» options è·å–æˆ–ä½¿ç”¨é»˜è®¤å€¼
        let vq = options.vision_quality.as_deref().unwrap_or("auto");
        llm_context.insert("vision_quality".into(), Value::String(vq.to_string()));

        // ğŸ”§ å·¥å…·åç§°æ˜ å°„ï¼šsanitized API name â†’ original name
        let mut variant_tool_name_mapping: HashMap<String, String> = HashMap::new();

        if !disable_tools {
            if let Some(ref tool_schemas) = options.mcp_tool_schemas {
                let mcp_tool_values: Vec<Value> = tool_schemas
                    .iter()
                    .map(|tool| {
                        let raw_tool_name = if tool.name.starts_with(BUILTIN_NAMESPACE) {
                            tool.name.clone()
                        } else {
                            format!("mcp_{}", tool.name)
                        };
                        let api_tool_name = sanitize_tool_name_for_api(&raw_tool_name);
                        if api_tool_name != raw_tool_name {
                            variant_tool_name_mapping.insert(api_tool_name.clone(), raw_tool_name);
                        }
                        json!({
                            "type": "function",
                            "function": {
                                "name": api_tool_name,
                                "description": tool.description.clone().unwrap_or_default(),
                                "parameters": tool.input_schema.clone().unwrap_or(json!({}))
                            }
                        })
                    })
                    .collect();

                if !mcp_tool_values.is_empty() {
                    llm_context.insert("tools".into(), Value::Array(mcp_tool_values.clone()));
                    log::info!(
                        "[ChatV2::VariantPipeline] variant={} injected {} tools",
                        ctx.variant_id(),
                        mcp_tool_values.len()
                    );
                }
            }
        }

        let emitter_arc = ctx.emitter_arc();
        let canvas_note_id = options.canvas_note_id.clone();
        // ğŸ”§ ç”¨æˆ·å¯é€šè¿‡ disable_tool_whitelist å…³é—­ç™½åå•æ£€æŸ¥
        let skill_allowed_tools = if options.disable_tool_whitelist.unwrap_or(false) {
            log::info!("[ChatV2::VariantPipeline] ğŸ”“ Tool whitelist check disabled by user setting");
            None
        } else {
            options.skill_allowed_tools.clone()
        };
        let skill_contents = options.skill_contents.clone();
        let active_skill_ids = options.active_skill_ids.clone();
        let variant_session_key = format!("{}:{}", session_id, ctx.variant_id());

        let mut tool_round = 0u32;
        loop {
            if ctx.is_cancelled() {
                ctx.cancel();
                break;
            }

            // ğŸ”§ P1ä¿®å¤ï¼šæ·»åŠ  Pipeline å±‚è¶…æ—¶ä¿æŠ¤
            let llm_future = self.llm_manager.call_unified_model_2_stream(
                &llm_context,
                &messages,
                "",
                true,
                enable_thinking,
                Some("chat_v2_variant"),
                ctx.emitter().window(),
                &stream_event,
                None,
                disable_tools,
                max_input_tokens_override,
                options.model_id.clone(),
                options.temperature,
                Some(system_prompt.clone()),
                options.top_p,
                options.frequency_penalty,
                options.presence_penalty,
                options.max_tokens,
            );

            // ä½¿ç”¨ tokio::select! æ”¯æŒå–æ¶ˆï¼ˆä¸å•å˜ä½“ pipeline å¯¹é½ï¼‰
            let call_result = tokio::select! {
                result = timeout(
                    Duration::from_secs(LLM_STREAM_TIMEOUT_SECS),
                    llm_future,
                ) => {
                    match result {
                        Ok(r) => Some(r),
                        Err(_) => {
                            log::error!(
                                "[ChatV2::VariantPipeline] LLM stream call timeout after {}s, variant={}, round={}",
                                LLM_STREAM_TIMEOUT_SECS,
                                ctx.variant_id(),
                                tool_round
                            );
                            self.llm_manager
                                .unregister_stream_hooks(&stream_event)
                                .await;
                            ctx.fail(&format!(
                                "LLM stream call timed out after {}s",
                                LLM_STREAM_TIMEOUT_SECS
                            ));
                            return Err(ChatV2Error::Timeout(format!(
                                "LLM stream call timed out after {}s",
                                LLM_STREAM_TIMEOUT_SECS
                            )));
                        }
                    }
                }
                _ = ctx.cancel_token().cancelled() => {
                    log::info!(
                        "[ChatV2::VariantPipeline] LLM call cancelled via token, variant={}, round={}",
                        ctx.variant_id(),
                        tool_round
                    );
                    // åŒæ—¶é€šçŸ¥ LLM å±‚åœæ­¢ HTTP æµ
                    self.llm_manager.request_cancel_stream(&stream_event).await;
                    None
                }
            };

            match call_result {
                None => {
                    // cancel_token è§¦å‘çš„å–æ¶ˆ
                    ctx.cancel();
                    break;
                }
                Some(Ok(output)) => {
                    if output.cancelled {
                        ctx.cancel();
                        break;
                    }
                }
                Some(Err(e)) => {
                    self.llm_manager
                        .unregister_stream_hooks(&stream_event)
                        .await;
                    ctx.fail(&e.to_string());
                    return Err(ChatV2Error::Llm(e.to_string()));
                }
            }

            let tool_calls = adapter.take_tool_calls();
            if tool_calls.is_empty() {
                adapter.finalize_all();
                ctx.complete();
                break;
            }

            log::info!(
                "[ChatV2::VariantPipeline] variant={} round={} has {} tool calls",
                ctx.variant_id(),
                tool_round,
                tool_calls.len()
            );

            let current_reasoning = adapter.get_accumulated_reasoning();
            adapter.finalize_all();
            ctx.set_pending_reasoning(current_reasoning.clone());

            // ğŸ†• å–æ¶ˆæ”¯æŒï¼šä¼ é€’å–æ¶ˆä»¤ç‰Œç»™å·¥å…·æ‰§è¡Œå™¨
            let cancel_token = Some(ctx.cancel_token());
            let rag_top_k = options.rag_top_k;
            let rag_enable_reranking = options.rag_enable_reranking;
            let tool_results = self
                .execute_tool_calls(
                    &tool_calls,
                    &emitter_arc,
                    &variant_session_key,
                    ctx.message_id(),
                    &canvas_note_id,
                    &skill_allowed_tools,
                    &skill_contents,
                    &active_skill_ids,
                    cancel_token,
                    rag_top_k,
                    rag_enable_reranking,
                    &variant_tool_name_mapping,
                )
                .await?;

            let success_count = tool_results.iter().filter(|r| r.success).count();
            log::info!(
                "[ChatV2::VariantPipeline] variant={} tool execution: {}/{} succeeded",
                ctx.variant_id(),
                success_count,
                tool_results.len()
            );

            for tc in &tool_calls {
                let tool_call = crate::models::ToolCall {
                    id: tc.id.clone(),
                    tool_name: tc.name.clone(),
                    args_json: tc.arguments.clone(),
                };
                messages.push(LegacyChatMessage {
                    role: "assistant".to_string(),
                    content: String::new(),
                    timestamp: chrono::Utc::now(),
                    thinking_content: current_reasoning.clone(),
                    thought_signature: None,
                    rag_sources: None,
                    memory_sources: None,
                    graph_sources: None,
                    web_search_sources: None,
                    image_paths: None,
                    image_base64: None,
                    doc_attachments: None,
                    multimodal_content: None,
                    tool_call: Some(tool_call),
                    tool_result: None,
                    overrides: None,
                    relations: None,
                    persistent_stable_id: None,
                    metadata: None,
                });
            }

            for result in &tool_results {
                let result_content = if result.success {
                    serde_json::to_string(&result.output).unwrap_or_else(|_| "{}".to_string())
                } else {
                    format!(
                        "Error: {}",
                        result.error.as_deref().unwrap_or("Unknown error")
                    )
                };

                let tool_result = crate::models::ToolResult {
                    call_id: result.tool_call_id.clone().unwrap_or_default(),
                    ok: result.success,
                    error: result.error.clone(),
                    error_details: None,
                    data_json: Some(result.output.clone()),
                    usage: None,
                    citations: None,
                };
                messages.push(LegacyChatMessage {
                    role: "tool".to_string(),
                    content: result_content,
                    timestamp: chrono::Utc::now(),
                    thinking_content: None,
                    thought_signature: None,
                    rag_sources: None,
                    memory_sources: None,
                    graph_sources: None,
                    web_search_sources: None,
                    image_paths: None,
                    image_base64: None,
                    doc_attachments: None,
                    multimodal_content: None,
                    tool_call: None,
                    tool_result: Some(tool_result),
                    overrides: None,
                    relations: None,
                    persistent_stable_id: None,
                    metadata: None,
                });

                ctx.add_tool_result(result.clone());
            }

            let task_completed = tool_results.iter().any(|r| {
                r.output
                    .get("task_completed")
                    .and_then(|v| v.as_bool())
                    .unwrap_or(false)
            });
            if task_completed {
                log::info!(
                    "[ChatV2::VariantPipeline] variant={} task_completed detected, stopping",
                    ctx.variant_id()
                );
                ctx.complete();
                break;
            }

            tool_round += 1;
            ctx.increment_tool_round();

            if tool_round >= MAX_TOOL_ROUNDS {
                log::warn!(
                    "[ChatV2::VariantPipeline] variant={} reached max tool rounds ({})",
                    ctx.variant_id(),
                    MAX_TOOL_ROUNDS
                );
                ctx.complete();
                break;
            }

            adapter.reset_for_new_round();
        }

        self.llm_manager
            .unregister_stream_hooks(&stream_event)
            .await;
        Ok(())
    }

    /// å…±äº«æ£€ç´¢é˜¶æ®µï¼ˆå·²åºŸå¼ƒé¢„è°ƒç”¨æ¨¡å¼ï¼‰
    ///
    /// ğŸ”§ 2026-01-11 é‡æ„ï¼šå½»åº•ç§»é™¤é¢„è°ƒç”¨æ£€ç´¢ï¼Œå®Œå…¨é‡‡ç”¨å·¥å…·åŒ–æ¨¡å¼
    ///
    /// åŸé¢„è°ƒç”¨æ¨¡å¼ï¼ˆå·²åºŸå¼ƒï¼‰ï¼š
    /// - åœ¨å¤šå˜ä½“ LLM è°ƒç”¨å‰æ‰§è¡Œ RAG/å›¾è°±/è®°å¿†/ç½‘ç»œæœç´¢
    /// - ç»“æœæ³¨å…¥åˆ°å…±äº«çš„ç³»ç»Ÿæç¤ºä¸­
    ///
    /// æ–°å·¥å…·åŒ–æ¨¡å¼ï¼ˆå½“å‰ï¼‰ï¼š
    /// - æ£€ç´¢å·¥å…·ä½œä¸º MCP å·¥å…·æ³¨å…¥åˆ° LLM
    /// - æ¯ä¸ªå˜ä½“çš„ LLM æ ¹æ®ç”¨æˆ·é—®é¢˜ä¸»åŠ¨å†³å®šæ˜¯å¦è°ƒç”¨æ£€ç´¢å·¥å…·
    /// - å¤šå˜ä½“æ¨¡å¼ä¸‹ï¼Œæ¯ä¸ªå˜ä½“ç‹¬ç«‹è°ƒç”¨æ£€ç´¢ï¼ˆæŒ‰éœ€ï¼‰
    ///
    /// ## å‚æ•°
    /// - `request`: å‘é€æ¶ˆæ¯è¯·æ±‚
    /// - `_emitter`: äº‹ä»¶å‘å°„å™¨ï¼ˆä¸å†ä½¿ç”¨ï¼‰
    /// - `_message_id`: æ¶ˆæ¯ IDï¼ˆä¸å†ä½¿ç”¨ï¼‰
    ///
    /// ## è¿”å›
    /// ç©ºçš„ SharedContextï¼ˆå·¥å…·åŒ–æ¨¡å¼ä¸‹ç”± LLM æŒ‰éœ€è°ƒç”¨æ£€ç´¢ï¼‰
    #[allow(unused_variables)]
    async fn execute_shared_retrievals(
        &self,
        request: &SendMessageRequest,
        _emitter: &Arc<ChatV2EventEmitter>,
        _message_id: &str,
    ) -> ChatV2Result<SharedContext> {
        // ğŸ”§ å·¥å…·åŒ–æ¨¡å¼ï¼šè·³è¿‡æ‰€æœ‰é¢„è°ƒç”¨æ£€ç´¢
        // å¤šå˜ä½“æ¨¡å¼ä¸‹ï¼Œæ¯ä¸ªå˜ä½“çš„ LLM å¯ç‹¬ç«‹é€šè¿‡ tool_calls è°ƒç”¨å†…ç½®æ£€ç´¢å·¥å…·
        log::info!(
            "[ChatV2::pipeline] Tool-based retrieval mode (multi-variant): skipping shared pre-call retrievals for session={}",
            request.session_id
        );
        Ok(SharedContext::default())
    }

    /// æ„å»ºå¸¦å…±äº«ä¸Šä¸‹æ–‡çš„ç³»ç»Ÿæç¤º
    ///
    /// ä½¿ç”¨ prompt_builder æ¨¡å—ç»Ÿä¸€æ ¼å¼åŒ–ï¼Œç”¨äºå¤šå˜ä½“å¹¶è¡Œæ‰§è¡Œåœºæ™¯ï¼Œ
    /// å…±äº«æ£€ç´¢ç»“æœæ³¨å…¥åˆ°æ‰€æœ‰å˜ä½“çš„ system prompt ä¸­ã€‚
    /// å¦‚æœæœ‰ Canvas ç¬”è®°ï¼Œä¹Ÿä¼šä¸€å¹¶æ³¨å…¥ã€‚
    async fn build_system_prompt_with_shared_context(
        &self,
        options: &SendOptions,
        shared_context: &SharedContext,
    ) -> String {
        // æ„å»º Canvas ç¬”è®°ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        let canvas_note = self.build_canvas_note_info_from_options(options).await;
        prompt_builder::build_system_prompt_with_shared_context(
            options,
            shared_context,
            canvas_note,
        )
    }

    /// æ ¹æ® SendOptions æ„å»º Canvas ç¬”è®°ä¿¡æ¯
    async fn build_canvas_note_info_from_options(
        &self,
        options: &SendOptions,
    ) -> Option<prompt_builder::CanvasNoteInfo> {
        let note_id = options.canvas_note_id.as_ref()?;
        let notes_mgr = self.notes_manager.as_ref()?;
        match notes_mgr.get_note(note_id) {
            Ok(note) => {
                let word_count = note.content_md.chars().count();
                log::info!(
                    "[ChatV2::pipeline] Canvas mode (variant): loaded note '{}' ({} chars, is_long={})",
                    note.title,
                    word_count,
                    word_count >= 3000
                );
                Some(prompt_builder::CanvasNoteInfo::new(
                    note_id.clone(),
                    note.title,
                    note.content_md,
                ))
            }
            Err(e) => {
                log::warn!(
                    "[ChatV2::pipeline] Canvas mode (variant): failed to read note {}: {}",
                    note_id,
                    e
                );
                None
            }
        }
    }

    /// åŠ è½½å˜ä½“çš„èŠå¤©å†å²ï¼ˆV2 å¢å¼ºç‰ˆï¼‰
    ///
    /// å¯¹é½å•å˜ä½“ `load_chat_history()` çš„å®Œæ•´èƒ½åŠ›ï¼š
    /// - ä½¿ç”¨ DEFAULT_MAX_HISTORY_MESSAGES é™åˆ¶æ¶ˆæ¯æ•°
    /// - æå–æ‰€æœ‰ content å—å¹¶æ‹¼æ¥ï¼ˆä¸åªæ˜¯ç¬¬ä¸€ä¸ªï¼‰
    /// - æå– thinking å—å†…å®¹
    /// - æå– mcp_tool å—çš„å·¥å…·è°ƒç”¨ä¿¡æ¯
    /// - è§£æ context_snapshotï¼ˆå¦‚æœæœ‰ vfs_db è¿æ¥ï¼‰
    /// - ä»é™„ä»¶ä¸­æå–å›¾ç‰‡ base64 å’Œæ–‡æ¡£é™„ä»¶
    async fn load_variant_chat_history(
        &self,
        session_id: &str,
    ) -> ChatV2Result<Vec<LegacyChatMessage>> {
        log::debug!(
            "[ChatV2::pipeline] Loading variant chat history for session={}",
            session_id
        );

        let conn = self.db.get_conn_safe()?;

        // ğŸ†• è·å– VFS æ•°æ®åº“è¿æ¥ï¼ˆç”¨äºè§£æå†å²æ¶ˆæ¯ä¸­çš„ context_snapshotï¼‰
        let vfs_conn_opt = self.vfs_db.as_ref().and_then(|vfs_db| {
            match vfs_db.get_conn_safe() {
                Ok(vfs_conn) => Some(vfs_conn),
                Err(e) => {
                    log::warn!("[ChatV2::pipeline] Failed to get vfs.db connection for variant history context_snapshot: {}", e);
                    None
                }
            }
        });
        let vfs_blobs_dir = self
            .vfs_db
            .as_ref()
            .map(|vfs_db| vfs_db.blobs_dir().to_path_buf());

        let messages = ChatV2Repo::get_session_messages_with_conn(&conn, session_id)?;

        if messages.is_empty() {
            log::debug!(
                "[ChatV2::pipeline] No variant chat history found for session={}",
                session_id
            );
            return Ok(Vec::new());
        }

        // ğŸ”§ ä½¿ç”¨å›ºå®šçš„æ¶ˆæ¯æ¡æ•°é™åˆ¶ï¼ˆå¯¹é½å•å˜ä½“ï¼‰
        let max_messages = DEFAULT_MAX_HISTORY_MESSAGES;
        let messages_to_load: Vec<_> = if messages.len() > max_messages {
            // å–æœ€æ–°çš„ max_messages æ¡æ¶ˆæ¯
            messages
                .into_iter()
                .rev()
                .take(max_messages)
                .rev()
                .collect()
        } else {
            messages
        };

        log::debug!(
            "[ChatV2::pipeline] Loading {} variant messages (max_messages={})",
            messages_to_load.len(),
            max_messages
        );

        let mut chat_history = Vec::new();
        for message in messages_to_load {
            let blocks = ChatV2Repo::get_message_blocks_with_conn(&conn, &message.id)?;

            // ğŸ”§ æå–æ‰€æœ‰ content ç±»å‹å—çš„å†…å®¹å¹¶æ‹¼æ¥ï¼ˆä¸åªæ˜¯ç¬¬ä¸€ä¸ªï¼‰
            let content: String = blocks
                .iter()
                .filter(|b| b.block_type == block_types::CONTENT)
                .filter_map(|b| b.content.as_ref())
                .cloned()
                .collect::<Vec<_>>()
                .join("");

            // ğŸ†• æå– thinking ç±»å‹å—çš„å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
            let thinking_content: Option<String> = {
                let thinking: String = blocks
                    .iter()
                    .filter(|b| b.block_type == block_types::THINKING)
                    .filter_map(|b| b.content.as_ref())
                    .cloned()
                    .collect::<Vec<_>>()
                    .join("");
                if thinking.is_empty() {
                    None
                } else {
                    Some(thinking)
                }
            };

            // ğŸ†• æå– mcp_tool ç±»å‹å—çš„å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼ˆæŒ‰ block_index æ’åºï¼‰
            let mut tool_blocks: Vec<_> = blocks
                .iter()
                .filter(|b| b.block_type == block_types::MCP_TOOL)
                .collect();
            tool_blocks.sort_by_key(|b| b.block_index);

            // ğŸ†• å¯¹äºç”¨æˆ·æ¶ˆæ¯ï¼Œè§£æ context_snapshot.user_refs å¹¶å°†å†…å®¹è¿½åŠ åˆ° content
            let (content, vfs_image_base64) = if message.role == MessageRole::User {
                if let (Some(ref vfs_conn), Some(ref blobs_dir)) = (&vfs_conn_opt, &vfs_blobs_dir) {
                    self.resolve_history_context_snapshot_v2(
                        &content,
                        &message,
                        &**vfs_conn,
                        blobs_dir,
                    )
                } else {
                    (content, Vec::new())
                }
            } else {
                (content, Vec::new())
            };

            let role = match message.role {
                MessageRole::User => "user",
                MessageRole::Assistant => "assistant",
            };

            // ğŸ†• å¦‚æœæ˜¯ assistant æ¶ˆæ¯ä¸”æœ‰å·¥å…·è°ƒç”¨ï¼Œå…ˆæ·»åŠ å·¥å…·è°ƒç”¨æ¶ˆæ¯
            if role == "assistant" && !tool_blocks.is_empty() {
                for (idx, tool_block) in tool_blocks.iter().enumerate() {
                    // ç”Ÿæˆ tool_call_idï¼ˆä½¿ç”¨å— ID æˆ–ç”Ÿæˆæ–°çš„ï¼‰
                    let tool_call_id = format!("tc_{}", tool_block.id.replace("blk_", ""));

                    // æå–å·¥å…·åç§°å’Œè¾“å…¥
                    let tool_name = tool_block.tool_name.clone().unwrap_or_default();
                    let tool_input = tool_block
                        .tool_input
                        .clone()
                        .unwrap_or(serde_json::Value::Null);
                    let tool_output = tool_block
                        .tool_output
                        .clone()
                        .unwrap_or(serde_json::Value::Null);
                    let tool_success = tool_block.status == block_status::SUCCESS;
                    let tool_error = tool_block.error.clone();

                    // 1. æ·»åŠ  assistant æ¶ˆæ¯ï¼ˆåŒ…å« tool_callï¼‰
                    let tool_call = crate::models::ToolCall {
                        id: tool_call_id.clone(),
                        tool_name: tool_name.clone(),
                        args_json: tool_input,
                    };
                    let assistant_tool_msg = LegacyChatMessage {
                        role: "assistant".to_string(),
                        content: String::new(),
                        timestamp: chrono::Utc::now(),
                        thinking_content: None,
                        thought_signature: None,
                        rag_sources: None,
                        memory_sources: None,
                        graph_sources: None,
                        web_search_sources: None,
                        image_paths: None,
                        image_base64: None,
                        doc_attachments: None,
                        multimodal_content: None,
                        tool_call: Some(tool_call),
                        tool_result: None,
                        overrides: None,
                        relations: None,
                        persistent_stable_id: None,
                        metadata: None,
                    };
                    chat_history.push(assistant_tool_msg);

                    // 2. æ·»åŠ  tool æ¶ˆæ¯ï¼ˆåŒ…å« tool_resultï¼‰
                    let tool_result = crate::models::ToolResult {
                        call_id: tool_call_id,
                        ok: tool_success,
                        error: tool_error,
                        error_details: None,
                        data_json: Some(tool_output.clone()),
                        usage: None,
                        citations: None,
                    };
                    let tool_msg = LegacyChatMessage {
                        role: "tool".to_string(),
                        content: serde_json::to_string(&tool_output).unwrap_or_default(),
                        timestamp: chrono::Utc::now(),
                        thinking_content: None,
                        thought_signature: None,
                        rag_sources: None,
                        memory_sources: None,
                        graph_sources: None,
                        web_search_sources: None,
                        image_paths: None,
                        image_base64: None,
                        doc_attachments: None,
                        multimodal_content: None,
                        tool_call: None,
                        tool_result: Some(tool_result),
                        overrides: None,
                        relations: None,
                        persistent_stable_id: None,
                        metadata: None,
                    };
                    chat_history.push(tool_msg);

                    log::debug!(
                        "[ChatV2::pipeline] Loaded variant tool call from history: tool={}, block_id={}, index={}",
                        tool_name,
                        tool_block.id,
                        idx
                    );
                }
            }

            // è·³è¿‡ç©ºå†…å®¹æ¶ˆæ¯ï¼ˆä½†å·¥å…·è°ƒç”¨æ¶ˆæ¯å·²ç»æ·»åŠ ï¼‰
            if content.is_empty() {
                continue;
            }

            // ğŸ†• ä»é™„ä»¶ä¸­æå–å›¾ç‰‡ base64ï¼ˆä»…ç”¨æˆ·æ¶ˆæ¯æœ‰é™„ä»¶ï¼‰
            // åˆå¹¶æ—§é™„ä»¶å›¾ç‰‡å’Œ VFS å›¾ç‰‡
            let mut all_images: Vec<String> = message
                .attachments
                .as_ref()
                .map(|attachments| {
                    attachments
                        .iter()
                        .filter(|a| a.r#type == "image")
                        .filter_map(|a| {
                            // preview_url æ ¼å¼ä¸º "data:image/xxx;base64,{base64_content}"
                            a.preview_url
                                .as_ref()
                                .and_then(|url| url.split(',').nth(1).map(|s| s.to_string()))
                        })
                        .collect::<Vec<_>>()
                })
                .unwrap_or_default();

            // è¿½åŠ ä» VFS context_snapshot è§£æçš„å›¾ç‰‡
            all_images.extend(vfs_image_base64);

            let image_base64: Option<Vec<String>> = if all_images.is_empty() {
                None
            } else {
                Some(all_images)
            };

            // ğŸ†• ä»é™„ä»¶ä¸­æå–æ–‡æ¡£é™„ä»¶ï¼ˆåŒæ—¶æ”¯æŒæ–‡æœ¬å’ŒäºŒè¿›åˆ¶æ–‡æ¡£ï¼‰
            let doc_attachments: Option<Vec<crate::models::DocumentAttachment>> = message.attachments
                .as_ref()
                .map(|attachments| {
                    attachments.iter()
                        .filter(|a| a.r#type == "document")
                        .map(|a| {
                            // åˆ¤æ–­æ˜¯å¦ä¸ºæ–‡æœ¬ç±»å‹
                            let is_text_type = a.mime_type.starts_with("text/") ||
                                               a.mime_type == "application/json" ||
                                               a.mime_type == "application/xml" ||
                                               a.mime_type == "application/javascript";

                            let mut text_content: Option<String> = None;
                            let mut base64_content: Option<String> = None;

                            // ä» preview_url æå–å†…å®¹
                            if let Some(ref url) = a.preview_url {
                                if url.starts_with("data:") {
                                    if let Some(data_part) = url.split(',').nth(1) {
                                        if is_text_type {
                                            // æ–‡æœ¬ç±»å‹ï¼šè§£ç  base64 ä¸ºæ–‡æœ¬
                                            use base64::Engine;
                                            text_content = base64::engine::general_purpose::STANDARD
                                                .decode(data_part)
                                                .ok()
                                                .and_then(|bytes| String::from_utf8(bytes).ok());
                                        } else {
                                            // äºŒè¿›åˆ¶ç±»å‹ï¼ˆå¦‚ docx/PDFï¼‰ï¼šå…ˆä¿å­˜ base64
                                            base64_content = Some(data_part.to_string());

                                            // å°è¯•ä½¿ç”¨ DocumentParser è§£æäºŒè¿›åˆ¶æ–‡æ¡£
                                            let parser = crate::document_parser::DocumentParser::new();
                                            match parser.extract_text_from_base64(&a.name, data_part) {
                                                Ok(text) => {
                                                    log::debug!("[ChatV2::pipeline] Extracted {} chars from variant history document: {}", text.len(), a.name);
                                                    text_content = Some(text);
                                                }
                                                Err(e) => {
                                                    log::debug!("[ChatV2::pipeline] Could not parse variant history document {}: {}", a.name, e);
                                                }
                                            }
                                        }
                                    }
                                }
                            }

                            crate::models::DocumentAttachment {
                                name: a.name.clone(),
                                mime_type: a.mime_type.clone(),
                                size_bytes: a.size as usize,
                                text_content,
                                base64_content,
                            }
                        })
                        .collect::<Vec<_>>()
                })
                .filter(|v| !v.is_empty());

            let legacy_message = LegacyChatMessage {
                role: role.to_string(),
                content: content.clone(),
                timestamp: chrono::Utc::now(),
                thinking_content,
                thought_signature: None,
                rag_sources: None,
                memory_sources: None,
                graph_sources: None,
                web_search_sources: None,
                image_paths: None,
                image_base64,
                doc_attachments,
                multimodal_content: None,
                tool_call: None,
                tool_result: None,
                overrides: None,
                relations: None,
                persistent_stable_id: message.persistent_stable_id.clone(),
                metadata: None,
            };

            chat_history.push(legacy_message);
        }

        log::info!(
            "[ChatV2::pipeline] Loaded {} variant messages from history for session={}",
            chat_history.len(),
            session_id
        );

        // ğŸ†• éªŒè¯å·¥å…·è°ƒç”¨é“¾å®Œæ•´æ€§
        validate_tool_chain(&chat_history);

        Ok(chat_history)
    }

    /// æ„å»ºå˜ä½“ç”¨æˆ·æ¶ˆæ¯
    fn build_variant_user_message(
        &self,
        user_content: &str,
        attachments: &[AttachmentInput],
    ) -> LegacyChatMessage {
        let image_base64: Option<Vec<String>> = {
            let images: Vec<String> = attachments
                .iter()
                .filter(|a| a.mime_type.starts_with("image/"))
                .filter_map(|a| a.base64_content.clone())
                .collect();
            if images.is_empty() {
                None
            } else {
                Some(images)
            }
        };

        let doc_attachments: Option<Vec<crate::models::DocumentAttachment>> = {
            let docs: Vec<crate::models::DocumentAttachment> = attachments
                .iter()
                .filter(|a| {
                    !a.mime_type.starts_with("image/")
                        && !a.mime_type.starts_with("audio/")
                        && !a.mime_type.starts_with("video/")
                })
                .map(|a| {
                    // ğŸ”§ P0ä¿®å¤ï¼šå¦‚æœæ²¡æœ‰ text_content ä½†æœ‰ base64_contentï¼Œå°è¯•ä½¿ç”¨ DocumentParser è§£æ
                    let text_content = if a.text_content.is_some() {
                        a.text_content.clone()
                    } else if let Some(ref base64) = a.base64_content {
                        // å°è¯•ä½¿ç”¨ DocumentParser è§£æäºŒè¿›åˆ¶æ–‡æ¡£ï¼ˆdocx/pdf ç­‰ï¼‰
                        let parser = crate::document_parser::DocumentParser::new();
                        match parser.extract_text_from_base64(&a.name, base64) {
                            Ok(text) => {
                                log::info!(
                                    "[ChatV2::pipeline] Extracted {} chars from document: {}",
                                    text.len(),
                                    a.name
                                );
                                Some(text)
                            }
                            Err(e) => {
                                log::warn!(
                                    "[ChatV2::pipeline] Failed to parse document {}: {}",
                                    a.name,
                                    e
                                );
                                None
                            }
                        }
                    } else {
                        None
                    };

                    crate::models::DocumentAttachment {
                        name: a.name.clone(),
                        mime_type: a.mime_type.clone(),
                        size_bytes: a
                            .base64_content
                            .as_ref()
                            .map(|c| (c.len() * 3) / 4)
                            .unwrap_or(0),
                        text_content,
                        base64_content: a.base64_content.clone(),
                    }
                })
                .collect();
            if docs.is_empty() {
                None
            } else {
                Some(docs)
            }
        };

        LegacyChatMessage {
            role: "user".to_string(),
            content: user_content.to_string(),
            timestamp: chrono::Utc::now(),
            thinking_content: None,
            thought_signature: None,
            rag_sources: None,
            memory_sources: None,
            graph_sources: None,
            web_search_sources: None,
            image_paths: None,
            image_base64,
            doc_attachments,
            multimodal_content: None,
            tool_call: None,
            tool_result: None,
            overrides: None,
            relations: None,
            persistent_stable_id: None,
            metadata: None,
        }
    }

    /// æ‰§è¡Œæ‰¹é‡å˜ä½“é‡è¯•
    ///
    /// å¤ç”¨åŸæœ‰ SharedContextï¼Œå¹¶è¡Œæ‰§è¡Œå¤šä¸ªå˜ä½“çš„é‡è¯•ã€‚
    /// ä½¿ç”¨å•ä¸€äº‹ä»¶å‘å°„å™¨ä»¥ä¿è¯åºåˆ—å·å…¨å±€é€’å¢ã€‚
    pub async fn execute_variants_retry_batch(
        &self,
        window: Window,
        session_id: String,
        message_id: String,
        variants: Vec<VariantRetrySpec>,
        user_content: String,
        user_attachments: Vec<AttachmentInput>,
        shared_context: SharedContext,
        options: SendOptions,
        cancel_token: CancellationToken,
        chat_v2_state: Option<Arc<super::super::state::ChatV2State>>,
    ) -> ChatV2Result<()> {
        use super::super::variant_context::{ParallelExecutionManager, VariantExecutionContext};
        use futures::future::join_all;

        log::info!(
            "[ChatV2::pipeline] execute_variants_retry_batch: session={}, message={}, variants={}",
            session_id,
            message_id,
            variants.len()
        );

        if variants.is_empty() {
            return Err(ChatV2Error::Validation(
                "No variant IDs provided for batch retry".to_string(),
            ));
        }

        // å•ä¸€äº‹ä»¶å‘å°„å™¨ï¼Œç¡®ä¿ sequenceId å…¨å±€é€’å¢
        let emitter = Arc::new(super::super::events::ChatV2EventEmitter::new(
            window.clone(),
            session_id.clone(),
        ));

        let shared_context_arc = Arc::new(shared_context);

        // åˆ›å»ºå¹¶è¡Œæ‰§è¡Œç®¡ç†å™¨ï¼ˆå¤šå˜ä½“é‡è¯•ï¼‰
        let manager = ParallelExecutionManager::with_cancel_token(cancel_token.clone());

        let mut variant_contexts: Vec<(Arc<VariantExecutionContext>, String)> =
            Vec::with_capacity(variants.len());

        for spec in &variants {
            let ctx = manager.create_variant(
                spec.variant_id.clone(),
                spec.model_id.clone(),
                message_id.clone(),
                Arc::clone(&shared_context_arc),
                Arc::clone(&emitter),
            );
            ctx.set_config_id(spec.config_id.clone());

            // æ³¨å†Œæ¯ä¸ªå˜ä½“çš„ cancel tokenï¼ˆç”¨äºæŒ‰ variant å–æ¶ˆï¼‰
            if let Some(ref state) = chat_v2_state {
                let cancel_key = format!("{}:{}", session_id, spec.variant_id);
                state.register_existing_token(&cancel_key, ctx.cancel_token().clone());
                log::debug!(
                    "[ChatV2::pipeline] Registered cancel token for retry variant: {}",
                    cancel_key
                );
            }

            variant_contexts.push((ctx, spec.config_id.clone()));
        }

        // ğŸ”§ P1ä¿®å¤ï¼šå¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å˜ä½“ï¼ˆä½¿ç”¨ä»»åŠ¡è¿½è¸ªå™¨ï¼‰
        let self_clone = self.clone();
        let options_arc = Arc::new(options.clone());
        let user_content_arc = Arc::new(user_content.clone());
        let session_id_arc = Arc::new(session_id.clone());
        let attachments_arc = Arc::new(user_attachments.clone());

        let futures: Vec<_> = variant_contexts
            .iter()
            .map(|(ctx, config_id)| {
                let self_ref = self_clone.clone();
                let ctx_clone = Arc::clone(ctx);
                let config_id_clone = config_id.clone();
                let options_clone = Arc::clone(&options_arc);
                let user_content_clone = Arc::clone(&user_content_arc);
                let session_id_clone = Arc::clone(&session_id_arc);
                let attachments_clone = Arc::clone(&attachments_arc);
                let shared_ctx = Arc::clone(&shared_context_arc);
                let state_clone = chat_v2_state.clone();

                let future = async move {
                    self_ref
                        .execute_single_variant_with_config(
                            ctx_clone,
                            config_id_clone,
                            (*options_clone).clone(),
                            (*user_content_clone).clone(),
                            (*session_id_clone).clone(),
                            shared_ctx,
                            (*attachments_clone).clone(),
                        )
                        .await
                };

                // ğŸ”§ P1ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ spawn_tracked è¿½è¸ªä»»åŠ¡
                if let Some(ref state) = state_clone {
                    state.spawn_tracked(future)
                } else {
                    log::warn!("[ChatV2::pipeline] spawn_tracked unavailable, using untracked tokio::spawn for retry variant task");
                    tokio::spawn(future)
                }
            })
            .collect();

        let results = join_all(futures).await;

        for (i, result) in results.into_iter().enumerate() {
            let (ctx, _) = &variant_contexts[i];
            match result {
                Ok(Ok(())) => {
                    log::info!(
                        "[ChatV2::pipeline] Retry variant {} completed successfully",
                        ctx.variant_id()
                    );
                }
                Ok(Err(e)) => {
                    log::error!(
                        "[ChatV2::pipeline] Retry variant {} failed: {}",
                        ctx.variant_id(),
                        e
                    );
                    // é”™è¯¯å·²åœ¨ execute_single_variant_with_config ä¸­å¤„ç†
                }
                Err(e) => {
                    log::error!(
                        "[ChatV2::pipeline] Retry variant {} task panicked: {}",
                        ctx.variant_id(),
                        e
                    );
                    ctx.fail(&format!("Task panicked: {}", e));
                }
            }
        }

        // æŒä¹…åŒ–æ¯ä¸ªå˜ä½“
        let mut update_error: Option<ChatV2Error> = None;
        for (ctx, _) in &variant_contexts {
            if let Err(e) = self.update_variant_after_retry(&message_id, ctx).await {
                log::error!(
                    "[ChatV2::pipeline] Failed to update retry variant {}: {}",
                    ctx.variant_id(),
                    e
                );
                if update_error.is_none() {
                    update_error = Some(e);
                }
            }
        }

        // æ¸…ç† cancel token
        if let Some(ref state) = chat_v2_state {
            for (ctx, _) in &variant_contexts {
                let cancel_key = format!("{}:{}", session_id, ctx.variant_id());
                state.remove_stream(&cancel_key);
            }
        }

        if let Some(err) = update_error {
            return Err(err);
        }

        Ok(())
    }

    /// æ‰§è¡Œå˜ä½“é‡è¯•
    ///
    /// é‡æ–°æ‰§è¡ŒæŒ‡å®šå˜ä½“çš„ LLM è°ƒç”¨ï¼Œå¤ç”¨åŸæœ‰çš„ SharedContextï¼ˆæ£€ç´¢ç»“æœï¼‰ã€‚
    ///
    /// ## å‚æ•°
    /// - `window`: Tauri çª—å£ï¼Œç”¨äºäº‹ä»¶å‘å°„
    /// - `session_id`: ä¼šè¯ ID
    /// - `message_id`: åŠ©æ‰‹æ¶ˆæ¯ ID
    /// - `variant_id`: è¦é‡è¯•çš„å˜ä½“ ID
    /// - `model_id`: æ¨¡å‹ IDï¼ˆå¯èƒ½å·²è¢« model_override è¦†ç›–ï¼‰
    /// - `user_content`: åŸå§‹ç”¨æˆ·æ¶ˆæ¯å†…å®¹
    /// - `user_attachments`: åŸå§‹ç”¨æˆ·é™„ä»¶
    /// - `shared_context`: å…±äº«ä¸Šä¸‹æ–‡ï¼ˆæ£€ç´¢ç»“æœï¼Œä»åŸæ¶ˆæ¯æ¢å¤ï¼‰
    /// - `options`: å‘é€é€‰é¡¹
    /// - `cancel_token`: å–æ¶ˆä»¤ç‰Œ
    ///
    /// ## è¿”å›
    /// æˆåŠŸå®Œæˆåè¿”å› Ok(())
    pub async fn execute_variant_retry(
        &self,
        window: Window,
        session_id: String,
        message_id: String,
        variant_id: String,
        model_id: String,
        user_content: String,
        user_attachments: Vec<AttachmentInput>,
        shared_context: SharedContext,
        options: SendOptions,
        cancel_token: CancellationToken,
    ) -> ChatV2Result<()> {
        log::info!(
            "[ChatV2::pipeline] execute_variant_retry: session={}, message={}, variant={}, model={}",
            session_id,
            message_id,
            variant_id,
            model_id
        );

        // åˆ›å»ºäº‹ä»¶å‘å°„å™¨
        let emitter = Arc::new(super::super::events::ChatV2EventEmitter::new(
            window.clone(),
            session_id.clone(),
        ));

        // åˆ›å»ºå…±äº«ä¸Šä¸‹æ–‡çš„ Arc
        let shared_context_arc = Arc::new(shared_context);

        // ğŸ”§ P1-4 ä¿®å¤ï¼šå°† config_id è§£æä¸ºæ¨¡å‹æ˜¾ç¤ºåç§°
        // model_id å¯èƒ½æ˜¯ API é…ç½® UUIDï¼ˆå¦‚ "builtin-siliconflow"ï¼‰ï¼Œéœ€è¦è§£æä¸ºæ˜¾ç¤ºåç§°ï¼ˆå¦‚ "Qwen/Qwen3-8B"ï¼‰
        // ç”¨äº variant_start äº‹ä»¶å’Œ variant.model_id å­˜å‚¨ï¼Œç¡®ä¿å‰ç«¯èƒ½æ­£ç¡®æ˜¾ç¤ºä¾›åº”å•†å›¾æ ‡
        let display_model_id = match self.llm_manager.get_api_configs().await {
            Ok(configs) => {
                configs
                    .iter()
                    .find(|c| c.id == model_id)
                    .map(|c| c.model.clone())
                    .or_else(|| {
                        // é€šè¿‡ model åç§°åŒ¹é…ï¼ˆconfig_id æœ¬èº«å¯èƒ½å°±æ˜¯æ¨¡å‹åï¼‰
                        configs.iter().find(|c| c.model == model_id).map(|c| c.model.clone())
                    })
                    .unwrap_or_else(|| {
                        // æ— æ³•ä» configs è§£ææ—¶ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºé…ç½® ID æ ¼å¼
                        if is_config_id_format(&model_id) {
                            log::warn!(
                                "[ChatV2::pipeline] variant retry: config_id is not a display name: {}",
                                model_id
                            );
                            // å›é€€åˆ°ç©ºå­—ç¬¦ä¸²ï¼Œå‰ç«¯ä¼šæ˜¾ç¤º generic å›¾æ ‡
                            // ä¼˜äºæ˜¾ç¤ºæ— æ³•è¯†åˆ«çš„ UUID
                            String::new()
                        } else {
                            model_id.clone()
                        }
                    })
            }
            Err(_) => model_id.clone(),
        };

        // åˆ›å»ºå¹¶è¡Œæ‰§è¡Œç®¡ç†å™¨ï¼ˆå•å˜ä½“ï¼‰
        let manager = super::super::variant_context::ParallelExecutionManager::with_cancel_token(
            cancel_token.clone(),
        );

        // åˆ›å»ºå˜ä½“æ‰§è¡Œä¸Šä¸‹æ–‡ï¼ˆä½¿ç”¨å·²æœ‰çš„ variant_idï¼‰
        // ä½¿ç”¨ display_model_id ä½œä¸ºå˜ä½“çš„æ¨¡å‹æ ‡è¯†ï¼ˆç”¨äºå‰ç«¯å›¾æ ‡æ˜¾ç¤ºï¼‰
        let ctx = manager.create_variant(
            variant_id.clone(),
            display_model_id,
            message_id.clone(),
            Arc::clone(&shared_context_arc),
            Arc::clone(&emitter),
        );

        // æ‰§è¡Œå˜ä½“ï¼ˆä½¿ç”¨å®Œæ•´å·¥å…·å¾ªç¯è·¯å¾„ï¼Œä¸å¤šå˜ä½“ä¸»æµç¨‹ä¿æŒä¸€è‡´ï¼‰
        // æ³¨æ„ï¼šmodel_idï¼ˆåŸå§‹ config_idï¼‰ä¼ é€’ç»™ execute_single_variant_with_config ç”¨äº LLM è°ƒç”¨
        let result = self
            .execute_single_variant_with_config(
                ctx.clone(),
                model_id.clone(),
                options,
                user_content,
                session_id.clone(),
                shared_context_arc,
                user_attachments,
            )
            .await;

        // å¤„ç†ç»“æœå¹¶æ›´æ–°å˜ä½“çŠ¶æ€
        // ğŸ”§ P0ä¿®å¤ï¼šæ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œéƒ½éœ€è¦æŒä¹…åŒ–å˜ä½“çŠ¶æ€
        match result {
            Ok(()) => {
                // æ›´æ–°å˜ä½“åœ¨æ•°æ®åº“ä¸­çš„çŠ¶æ€å’Œå†…å®¹
                self.update_variant_after_retry(&message_id, &ctx).await?;
                log::info!(
                    "[ChatV2::pipeline] Variant retry completed: variant={}, status={}",
                    variant_id,
                    ctx.status()
                );
                Ok(())
            }
            Err(e) => {
                log::error!(
                    "[ChatV2::pipeline] Variant retry failed: variant={}, error={}",
                    variant_id,
                    e
                );
                // ğŸ”§ P0ä¿®å¤ï¼šå¤±è´¥æ—¶ä¹Ÿéœ€è¦æ›´æ–°å˜ä½“çŠ¶æ€åˆ°æ•°æ®åº“
                // ctx.status() åœ¨ execute_single_variant å¤±è´¥æ—¶ä¼šè¢«è®¾ç½®ä¸º ERROR æˆ– CANCELLED
                if let Err(update_err) = self.update_variant_after_retry(&message_id, &ctx).await {
                    log::error!(
                        "[ChatV2::pipeline] Failed to update variant status after error: {}",
                        update_err
                    );
                }
                Err(e)
            }
        }
    }

    /// æ›´æ–°é‡è¯•åçš„å˜ä½“
    ///
    /// æ›´æ–°å˜ä½“çŠ¶æ€ã€å—å†…å®¹ç­‰åˆ°æ•°æ®åº“
    async fn update_variant_after_retry(
        &self,
        message_id: &str,
        ctx: &Arc<super::super::variant_context::VariantExecutionContext>,
    ) -> ChatV2Result<()> {
        let conn = self.db.get_conn_safe()?;
        let now_ms = chrono::Utc::now().timestamp_millis();

        // è·å–æ¶ˆæ¯
        let mut message = ChatV2Repo::get_message_with_conn(&conn, message_id)?
            .ok_or_else(|| ChatV2Error::MessageNotFound(message_id.to_string()))?;

        // æ›´æ–°å˜ä½“çŠ¶æ€
        if let Some(ref mut variants) = message.variants {
            if let Some(variant) = variants.iter_mut().find(|v| v.id == ctx.variant_id()) {
                variant.status = ctx.status();
                variant.error = ctx.error();
                variant.block_ids = ctx.block_ids();
                let usage = ctx.get_usage();
                variant.usage = if usage.total_tokens > 0 {
                    Some(usage)
                } else {
                    None
                };
            }
        }

        // ğŸ”§ ä¼˜åŒ–ï¼šé‡è¯•æˆåŠŸåè‡ªåŠ¨è®¾ä¸ºæ¿€æ´»å˜ä½“
        if ctx.status() == variant_status::SUCCESS {
            message.active_variant_id = Some(ctx.variant_id().to_string());
            log::info!(
                "[ChatV2::pipeline] Auto-activated successful retry variant: {}",
                ctx.variant_id()
            );
        }

        // ä¿å­˜ thinking å—ï¼ˆå¦‚æœæœ‰ï¼‰
        if let Some(thinking_block_id) = ctx.get_thinking_block_id() {
            let thinking_content = ctx.get_accumulated_reasoning();
            let thinking_block = MessageBlock {
                id: thinking_block_id.clone(),
                message_id: message_id.to_string(),
                block_type: block_types::THINKING.to_string(),
                status: block_status::SUCCESS.to_string(),
                content: thinking_content,
                tool_name: None,
                tool_input: None,
                tool_output: None,
                citations: None,
                error: None,
                // ğŸ”§ P3ä¿®å¤ï¼šä½¿ç”¨ first_chunk_at ä½œä¸º started_atï¼ˆçœŸæ­£çš„å¼€å§‹æ—¶é—´ï¼‰
                started_at: ctx.get_thinking_first_chunk_at().or(Some(now_ms)),
                ended_at: Some(now_ms),
                // ğŸ”§ ä½¿ç”¨ VariantContext è®°å½•çš„ first_chunk_at æ—¶é—´æˆ³
                first_chunk_at: ctx.get_thinking_first_chunk_at(),
                block_index: 0,
            };
            ChatV2Repo::create_block_with_conn(&conn, &thinking_block)?;

            // æ·»åŠ åˆ°æ¶ˆæ¯çš„ block_ids
            if !message.block_ids.contains(&thinking_block_id) {
                message.block_ids.push(thinking_block_id);
            }
        }

        // ä¿å­˜ content å—
        if let Some(content_block_id) = ctx.get_content_block_id() {
            let content = ctx.get_accumulated_content();
            let content_block = MessageBlock {
                id: content_block_id.clone(),
                message_id: message_id.to_string(),
                block_type: block_types::CONTENT.to_string(),
                // ğŸ”§ P1ä¿®å¤ï¼šæ­£ç¡®å¤„ç† CANCELLED çŠ¶æ€
                status: match ctx.status().as_str() {
                    s if s == variant_status::SUCCESS => block_status::SUCCESS.to_string(),
                    s if s == variant_status::ERROR => block_status::ERROR.to_string(),
                    s if s == variant_status::CANCELLED => block_status::SUCCESS.to_string(), // cancelled ä½†æœ‰å†…å®¹ï¼Œæ ‡è®°ä¸º success
                    _ => block_status::RUNNING.to_string(),
                },
                content: if content.is_empty() {
                    None
                } else {
                    Some(content)
                },
                tool_name: None,
                tool_input: None,
                tool_output: None,
                citations: None,
                error: ctx.error(),
                // ğŸ”§ P3ä¿®å¤ï¼šä½¿ç”¨ first_chunk_at ä½œä¸º started_atï¼ˆçœŸæ­£çš„å¼€å§‹æ—¶é—´ï¼‰
                started_at: ctx.get_content_first_chunk_at().or(Some(now_ms)),
                ended_at: Some(now_ms),
                // ğŸ”§ ä½¿ç”¨ VariantContext è®°å½•çš„ first_chunk_at æ—¶é—´æˆ³
                first_chunk_at: ctx.get_content_first_chunk_at(),
                block_index: 1, // content åœ¨ thinking ä¹‹å
            };
            ChatV2Repo::create_block_with_conn(&conn, &content_block)?;

            // æ·»åŠ åˆ°æ¶ˆæ¯çš„ block_ids
            if !message.block_ids.contains(&content_block_id) {
                message.block_ids.push(content_block_id);
            }
        }

        // æ›´æ–°æ¶ˆæ¯
        ChatV2Repo::update_message_with_conn(&conn, &message)?;

        log::debug!(
            "[ChatV2::pipeline] Updated variant after retry: variant={}, blocks={}",
            ctx.variant_id(),
            ctx.block_ids().len()
        );

        Ok(())
    }

    /// ä¿å­˜å¤šå˜ä½“ç»“æœ
    ///
    /// ä»æ¯ä¸ª VariantExecutionContext è·å–ç´¯ç§¯çš„å†…å®¹ï¼Œåˆ›å»ºå—å¹¶ä¿å­˜ã€‚
    ///
    /// ## ç»Ÿä¸€ä¸Šä¸‹æ–‡æ³¨å…¥ç³»ç»Ÿæ”¯æŒ
    /// - `context_snapshot`: ä¸Šä¸‹æ–‡å¿«ç…§ï¼ˆåªå­˜ ContextRefï¼‰
    async fn save_multi_variant_results(
        &self,
        session_id: &str,
        user_message_id: &str,
        assistant_message_id: &str,
        user_content: &str,
        attachments: &[AttachmentInput],
        options: &SendOptions,
        shared_context: &SharedContext,
        variant_contexts: &[Arc<super::super::variant_context::VariantExecutionContext>],
        active_variant_id: Option<&str>,
        context_snapshot: Option<ContextSnapshot>,
    ) -> ChatV2Result<()> {
        let conn = self.db.get_conn_safe()?;
        let now_ms = chrono::Utc::now().timestamp_millis();

        // P0 ä¿®å¤ï¼šä½¿ç”¨äº‹åŠ¡åŒ…è£¹æ‰€æœ‰å†™æ“ä½œï¼Œç¡®ä¿å¤šå˜ä½“ä¿å­˜çš„åŸå­æ€§
        conn.execute("BEGIN IMMEDIATE", []).map_err(|e| {
            log::error!(
                "[ChatV2::pipeline] Failed to begin transaction for save_multi_variant_results: {}",
                e
            );
            ChatV2Error::Database(format!("Failed to begin transaction: {}", e))
        })?;

        let save_result = (|| -> ChatV2Result<()> {

        // === 1. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ ===
        let mut user_msg_params =
            UserMessageParams::new(session_id.to_string(), user_content.to_string())
                .with_id(user_message_id.to_string())
                .with_attachments(attachments.to_vec())
                .with_timestamp(now_ms);

        if let Some(snapshot) = context_snapshot.clone() {
            user_msg_params = user_msg_params.with_context_snapshot(snapshot);
        }

        let user_msg_result = build_user_message(user_msg_params);

        ChatV2Repo::create_message_with_conn(&conn, &user_msg_result.message)?;
        ChatV2Repo::create_block_with_conn(&conn, &user_msg_result.block)?;

        // === 2. ğŸ”§ P1ä¿®å¤ï¼šä¿å­˜æ£€ç´¢å— ===
        let mut all_block_ids: Vec<String> = Vec::new();
        let mut pending_blocks: Vec<MessageBlock> = Vec::new();
        let mut block_index_counter = 0;

        // 2.1 ä¿å­˜ RAG æ£€ç´¢å—
        if let Some(ref block_id) = shared_context.rag_block_id {
            if shared_context
                .rag_sources
                .as_ref()
                .map_or(false, |v| !v.is_empty())
            {
                let rag_block = MessageBlock {
                    id: block_id.clone(),
                    message_id: assistant_message_id.to_string(),
                    block_type: block_types::RAG.to_string(),
                    status: block_status::SUCCESS.to_string(),
                    content: None,
                    tool_name: None,
                    tool_input: None,
                    tool_output: Some(json!({ "sources": shared_context.rag_sources })),
                    citations: None,
                    error: None,
                    started_at: Some(now_ms),
                    ended_at: Some(now_ms),
                    // ğŸ”§ æ£€ç´¢å—ä½¿ç”¨ now_ms ä½œä¸º first_chunk_at
                    first_chunk_at: Some(now_ms),
                    block_index: block_index_counter,
                };
                pending_blocks.push(rag_block);
                all_block_ids.push(block_id.clone());
                block_index_counter += 1;
            }
        }

        // 2.2 ä¿å­˜ Memory æ£€ç´¢å—
        if let Some(ref block_id) = shared_context.memory_block_id {
            if shared_context
                .memory_sources
                .as_ref()
                .map_or(false, |v| !v.is_empty())
            {
                let memory_block = MessageBlock {
                    id: block_id.clone(),
                    message_id: assistant_message_id.to_string(),
                    block_type: block_types::MEMORY.to_string(),
                    status: block_status::SUCCESS.to_string(),
                    content: None,
                    tool_name: None,
                    tool_input: None,
                    tool_output: Some(json!({ "sources": shared_context.memory_sources })),
                    citations: None,
                    error: None,
                    started_at: Some(now_ms),
                    ended_at: Some(now_ms),
                    // ğŸ”§ æ£€ç´¢å—ä½¿ç”¨ now_ms ä½œä¸º first_chunk_at
                    first_chunk_at: Some(now_ms),
                    block_index: block_index_counter,
                };
                pending_blocks.push(memory_block);
                all_block_ids.push(block_id.clone());
                block_index_counter += 1;
            }
        }

        // 2.4 ä¿å­˜ Web æœç´¢æ£€ç´¢å—
        if let Some(ref block_id) = shared_context.web_search_block_id {
            if shared_context
                .web_search_sources
                .as_ref()
                .map_or(false, |v| !v.is_empty())
            {
                let web_block = MessageBlock {
                    id: block_id.clone(),
                    message_id: assistant_message_id.to_string(),
                    block_type: block_types::WEB_SEARCH.to_string(),
                    status: block_status::SUCCESS.to_string(),
                    content: None,
                    tool_name: None,
                    tool_input: None,
                    tool_output: Some(json!({ "sources": shared_context.web_search_sources })),
                    citations: None,
                    error: None,
                    started_at: Some(now_ms),
                    ended_at: Some(now_ms),
                    // ğŸ”§ æ£€ç´¢å—ä½¿ç”¨ now_ms ä½œä¸º first_chunk_at
                    first_chunk_at: Some(now_ms),
                    block_index: block_index_counter,
                };
                pending_blocks.push(web_block);
                all_block_ids.push(block_id.clone());
                block_index_counter += 1;
            }
        }

        log::debug!(
            "[ChatV2::pipeline] Multi-variant retrieval blocks saved: {} blocks",
            block_index_counter
        );

        // === 3. æ”¶é›†æ‰€æœ‰å˜ä½“å—ä¿¡æ¯ ===
        let mut variants: Vec<Variant> = Vec::with_capacity(variant_contexts.len());

        for ctx in variant_contexts {
            let mut block_index = 0;

            // ä¿å­˜ thinking å—ï¼ˆå¦‚æœæœ‰ï¼‰
            if let Some(thinking_block_id) = ctx.get_thinking_block_id() {
                let thinking_content = ctx.get_accumulated_reasoning();
                let thinking_block = MessageBlock {
                    id: thinking_block_id.clone(),
                    message_id: assistant_message_id.to_string(),
                    block_type: block_types::THINKING.to_string(),
                    status: block_status::SUCCESS.to_string(),
                    content: thinking_content,
                    tool_name: None,
                    tool_input: None,
                    tool_output: None,
                    citations: None,
                    error: None,
                    // ğŸ”§ P3ä¿®å¤ï¼šä½¿ç”¨ first_chunk_at ä½œä¸º started_atï¼ˆçœŸæ­£çš„å¼€å§‹æ—¶é—´ï¼‰
                    started_at: ctx.get_thinking_first_chunk_at().or(Some(now_ms)),
                    ended_at: Some(now_ms),
                    // ğŸ”§ ä½¿ç”¨ VariantContext è®°å½•çš„ first_chunk_at æ—¶é—´æˆ³
                    first_chunk_at: ctx.get_thinking_first_chunk_at(),
                    block_index,
                };
                pending_blocks.push(thinking_block);
                all_block_ids.push(thinking_block_id);
                block_index += 1;
            }

            // æ”¶é›† content å—
            if let Some(content_block_id) = ctx.get_content_block_id() {
                let content = ctx.get_accumulated_content();
                let content_block = MessageBlock {
                    id: content_block_id.clone(),
                    message_id: assistant_message_id.to_string(),
                    block_type: block_types::CONTENT.to_string(),
                    status: if ctx.status() == variant_status::SUCCESS {
                        block_status::SUCCESS.to_string()
                    } else if ctx.status() == variant_status::ERROR {
                        block_status::ERROR.to_string()
                    } else {
                        block_status::RUNNING.to_string()
                    },
                    content: if content.is_empty() {
                        None
                    } else {
                        Some(content)
                    },
                    tool_name: None,
                    tool_input: None,
                    tool_output: None,
                    citations: None,
                    error: ctx.error(),
                    // ğŸ”§ P3ä¿®å¤ï¼šä½¿ç”¨ first_chunk_at ä½œä¸º started_atï¼ˆçœŸæ­£çš„å¼€å§‹æ—¶é—´ï¼‰
                    started_at: ctx.get_content_first_chunk_at().or(Some(now_ms)),
                    ended_at: Some(now_ms),
                    // ğŸ”§ ä½¿ç”¨ VariantContext è®°å½•çš„ first_chunk_at æ—¶é—´æˆ³
                    first_chunk_at: ctx.get_content_first_chunk_at(),
                    block_index,
                };
                pending_blocks.push(content_block);
                all_block_ids.push(content_block_id);
            }

            // åˆ›å»º Variant ç»“æ„
            let variant = ctx.to_variant();
            variants.push(variant);

            log::debug!(
                "[ChatV2::pipeline] Saved blocks for variant {}: status={}",
                ctx.variant_id(),
                ctx.status()
            );
        }

        // === 4. ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯ï¼ˆå¸¦å˜ä½“ä¿¡æ¯ï¼‰===
        let assistant_message = ChatMessage {
            id: assistant_message_id.to_string(),
            session_id: session_id.to_string(),
            role: MessageRole::Assistant,
            block_ids: all_block_ids,
            timestamp: now_ms,
            persistent_stable_id: None,
            parent_id: None,
            supersedes: None,
            meta: Some(MessageMeta {
                model_id: None, // å¤šå˜ä½“æ¨¡å¼ä¸‹ä¸è®¾ç½®å•ä¸€æ¨¡å‹
                chat_params: Some(json!({
                    "temperature": options.temperature,
                    "maxTokens": options.max_tokens,
                    "enableThinking": options.enable_thinking,
                    "multiVariantMode": true,
                })),
                sources: if shared_context.has_sources() {
                    Some(MessageSources {
                        rag: shared_context.rag_sources.clone(),
                        memory: shared_context.memory_sources.clone(),
                        graph: shared_context.graph_sources.clone(),
                        web_search: shared_context.web_search_sources.clone(),
                        multimodal: shared_context.multimodal_sources.clone(),
                    })
                } else {
                    None
                },
                tool_results: None,
                anki_cards: None,
                // å¤šå˜ä½“æ¨¡å¼ä¸‹ usage ä¸º Noneï¼ˆå„å˜ä½“ç‹¬ç«‹è®°å½•ï¼‰
                usage: None,
                // ğŸ†• ç»Ÿä¸€ä¸Šä¸‹æ–‡æ³¨å…¥ç³»ç»Ÿï¼šå¤šå˜ä½“æ¨¡å¼æ”¯æŒ context_snapshot
                context_snapshot: context_snapshot.clone(),
            }),
            attachments: None,
            active_variant_id: active_variant_id.map(|s| s.to_string()),
            variants: Some(variants),
            shared_context: Some(shared_context.clone()),
        };

        ChatV2Repo::create_message_with_conn(&conn, &assistant_message)?;

        // ğŸ†• ç»Ÿä¸€ä¸Šä¸‹æ–‡æ³¨å…¥ç³»ç»Ÿï¼šæ¶ˆæ¯ä¿å­˜åå¢åŠ èµ„æºå¼•ç”¨è®¡æ•°
        // ğŸ†• VFS ç»Ÿä¸€å­˜å‚¨ï¼ˆ2025-12-07ï¼‰ï¼šä½¿ç”¨ vfs.db
        if let Some(ref snapshot) = context_snapshot {
            if snapshot.has_refs() {
                if let Some(ref vfs_db) = self.vfs_db {
                    if let Ok(vfs_conn) = vfs_db.get_conn_safe() {
                        let resource_ids = snapshot.all_resource_ids();
                        // ä½¿ç”¨åŒæ­¥æ–¹æ³•å¢åŠ å¼•ç”¨è®¡æ•°ï¼ˆä½¿ç”¨ç°æœ‰è¿æ¥é¿å…æ­»é”ï¼‰
                        for resource_id in &resource_ids {
                            if let Err(e) =
                                VfsResourceRepo::increment_ref_with_conn(&vfs_conn, resource_id)
                            {
                                log::warn!(
                                    "[ChatV2::pipeline] Failed to increment ref for resource {}: {}",
                                    resource_id, e
                                );
                            }
                        }
                        log::debug!(
                            "[ChatV2::pipeline] Multi-variant: incremented refs for {} resources in vfs.db",
                            resource_ids.len()
                        );
                    } else {
                        log::warn!("[ChatV2::pipeline] Multi-variant: failed to get vfs.db connection for increment refs");
                    }
                } else {
                    log::warn!("[ChatV2::pipeline] Multi-variant: vfs_db not available, skipping increment refs");
                }
            }
        }

        // === 4. ç°åœ¨å¯ä»¥å®‰å…¨åœ°åˆ›å»ºå—äº†ï¼ˆåŠ©æ‰‹æ¶ˆæ¯å·²å­˜åœ¨ï¼‰===
        for block in pending_blocks {
            ChatV2Repo::create_block_with_conn(&conn, &block)?;
        }

        log::info!(
            "[ChatV2::pipeline] Multi-variant results saved: user_msg={}, assistant_msg={}, variants={}",
            user_message_id,
            assistant_message_id,
            variant_contexts.len()
        );

        Ok(())
        })(); // é—­åŒ…ç»“æŸ

        match save_result {
            Ok(()) => {
                conn.execute("COMMIT", []).map_err(|e| {
                    log::error!(
                        "[ChatV2::pipeline] Failed to commit multi-variant save: {}",
                        e
                    );
                    ChatV2Error::Database(format!("Failed to commit transaction: {}", e))
                })?;
                Ok(())
            }
            Err(e) => {
                if let Err(rollback_err) = conn.execute("ROLLBACK", []) {
                    log::error!(
                        "[ChatV2::pipeline] Failed to rollback multi-variant save: {} (original: {:?})",
                        rollback_err,
                        e
                    );
                } else {
                    log::warn!(
                        "[ChatV2::pipeline] Multi-variant save rolled back: {:?}",
                        e
                    );
                }
                Err(e)
            }
        }
    }
}
