//! VFS LanceDB å‘é‡å­˜å‚¨æ¨¡å—
//!
//! å°†å‘é‡åŒ–èƒ½åŠ›å†…åŒ–ä¸º VFS çš„ç´¢å¼•å±‚ï¼Œå¤ç”¨ LanceVectorStore æ ¸å¿ƒé€»è¾‘ã€‚
//!
//! ## ä¸æ—§ RAG ç³»ç»Ÿçš„å·®å¼‚
//! - `document_id` â†’ `resource_id`ï¼ˆå…³è” VFS èµ„æºï¼‰
//! - `sub_library_id` â†’ `folder_id`ï¼ˆæ–‡ä»¶å¤¹è¿‡æ»¤ï¼Œå¯é€‰ï¼‰
//! - æ–°å¢ `resource_type` å­—æ®µ
//! - è¡¨å‘½åï¼š`vfs_emb_{modality}_{dim}`

#![allow(unused_variables)]
#![allow(dead_code)]

use std::cmp::Ordering;
use std::fs;
use std::path::{Path, PathBuf};
use std::sync::Arc;
use std::time::Instant;

use arrow_array::{
    Array, ArrayRef, FixedSizeListArray, Float32Array, Int32Array, RecordBatch,
    RecordBatchIterator, StringArray,
};
use arrow_schema::{DataType, Field, Schema};
use futures_util::TryStreamExt;
use lancedb::index::scalar::FtsIndexBuilder;
use lancedb::index::scalar::FullTextSearchQuery;
use lancedb::index::Index;
use lancedb::query::{ExecutableQuery, QueryBase, QueryExecutionOptions};
use lancedb::table::{OptimizeAction, OptimizeOptions};
use lancedb::DistanceType;
use lancedb::{Connection, Table};
use tracing::{debug, info, warn};

use crate::vfs::database::VfsDatabase;
use crate::vfs::error::{VfsError, VfsResult};

// ============================================================================
// å¸¸é‡å®šä¹‰
// ============================================================================

/// VFS å‘é‡è¡¨å‰ç¼€
const VFS_LANCE_TABLE_PREFIX: &str = "vfs_emb_";

/// FTS ç‰ˆæœ¬æ ‡è¯†
const VFS_FTS_VERSION: &str = "2026-01-vfs-ngram-v1";

/// ä¼˜åŒ–æœ€å°é—´éš”ï¼ˆç§’ï¼‰
const OPTIMIZE_MIN_INTERVAL_SECS: i64 = 600; // 10min

/// Lance ç›¸å…³æ€§å¾—åˆ†åˆ—å
const LANCE_RELEVANCE_COL: &str = "_relevance_score";
const LANCE_FTS_SCORE_COL: &str = "_score";

// ============================================================================
// ç±»å‹å®šä¹‰
// ============================================================================

/// VFS å‘é‡è¡Œç»“æ„ï¼ˆå¯¹åº” LanceDB è¡¨ä¸­çš„ä¸€è¡Œï¼‰
#[derive(Debug, Clone)]
pub struct VfsLanceRow {
    pub embedding_id: String,
    pub resource_id: String,
    pub resource_type: String,
    pub folder_id: Option<String>,
    pub chunk_index: i32,
    pub text: String,
    pub metadata_json: Option<String>,
    pub created_at: String,
    pub embedding: Vec<f32>,
}

/// å‘é‡æ£€ç´¢ç»“æœ
#[derive(Debug, Clone)]
pub struct VfsLanceSearchResult {
    pub embedding_id: String,
    pub resource_id: String,
    pub resource_type: String,
    pub folder_id: Option<String>,
    pub chunk_index: i32,
    pub text: String,
    pub score: f32,
    pub metadata_json: Option<String>,
    /// é¡µé¢ç´¢å¼•ï¼ˆç”¨äº PDF/æ•™æå®šä½ï¼Œä» metadata_json è§£æï¼‰
    pub page_index: Option<i32>,
    /// æ¥æº IDï¼ˆä» metadata_json è§£æï¼‰
    pub source_id: Option<String>,
}

#[derive(Debug, Clone, serde::Serialize)]
#[serde(rename_all = "camelCase")]
pub struct LanceTableDiagnostic {
    pub table_name: String,
    pub dimension: usize,
    pub row_count: usize,
    pub columns: Vec<String>,
    pub has_metadata_column: bool,
    pub has_embedding_id_column: bool,
    pub has_resource_id_column: bool,
    pub has_text_column: bool,
    pub sample_metadata: Vec<Option<String>>,
    pub metadata_with_page_index: usize,
    pub metadata_null_count: usize,
    pub schema_valid: bool,
    pub issue_description: Option<String>,
}

// ============================================================================
// VfsLanceStore å®ç°
// ============================================================================

/// VFS LanceDB å‘é‡å­˜å‚¨
///
/// å¤ç”¨ LanceVectorStore çš„æ ¸å¿ƒé€»è¾‘ï¼Œé€‚é… VFS èµ„æºæ¨¡å‹ã€‚
pub struct VfsLanceStore {
    db: Arc<VfsDatabase>,
    lance_base_path: PathBuf,
}

impl VfsLanceStore {
    /// åˆ›å»ºæ–°çš„ VfsLanceStore å®ä¾‹
    pub fn new(db: Arc<VfsDatabase>) -> VfsResult<Self> {
        let lance_base_path = Self::resolve_lance_base(&db)?;

        info!(
            "[VfsLanceStore] Initialized with base path: {}",
            lance_base_path.display()
        );

        Ok(Self {
            db,
            lance_base_path,
        })
    }

    /// è§£æ Lance åŸºç¡€ç›®å½•
    fn resolve_lance_base(db: &VfsDatabase) -> VfsResult<PathBuf> {
        let vfs_db_path = db.db_path();
        let base_dir = vfs_db_path
            .parent()
            .map(|p| p.to_path_buf())
            .unwrap_or_else(|| std::env::current_dir().unwrap_or_else(|_| PathBuf::from(".")));

        let lance_dir = base_dir.join("lance").join("vfs");
        Self::ensure_dir(&lance_dir)?;

        Ok(lance_dir)
    }

    /// ç¡®ä¿ç›®å½•å­˜åœ¨
    fn ensure_dir(path: &Path) -> VfsResult<()> {
        fs::create_dir_all(path).map_err(|e| {
            VfsError::Other(format!("åˆ›å»º Lance ç›®å½•å¤±è´¥: {} - {}", path.display(), e))
        })
    }

    /// è·å– Lance è¿æ¥è·¯å¾„
    fn get_lance_path(&self) -> String {
        self.lance_base_path.to_string_lossy().to_string()
    }

    /// è¿æ¥åˆ° LanceDB
    async fn connect(&self) -> VfsResult<Connection> {
        let path = self.get_lance_path();
        lancedb::connect(&path)
            .execute()
            .await
            .map_err(|e| VfsError::Other(format!("è¿æ¥ LanceDB å¤±è´¥: {}", e)))
    }

    /// è·å–è¡¨å
    fn table_name(modality: &str, dim: usize) -> String {
        format!("{}{}_{}", VFS_LANCE_TABLE_PREFIX, modality, dim)
    }

    /// ä»æ•°æ®åº“è·å–å·²æ³¨å†Œçš„ç»´åº¦åˆ—è¡¨
    fn get_registered_dimensions(&self, modality: &str) -> VfsResult<Vec<usize>> {
        use crate::vfs::repos::embedding_dim_repo;

        let conn = self.db.get_conn()?;
        let dims = embedding_dim_repo::list_by_modality(&conn, modality)?;
        Ok(dims.iter().map(|d| d.dimension as usize).collect())
    }

    /// ä» Lance ç›®å½•å‘ç°æŸä¸ªæ¨¡æ€çš„å®é™…è¡¨ç»´åº¦ï¼ˆç”¨äºç»´åº¦æ³¨å†Œè¡¨æ¼‚ç§»å…œåº•ï¼‰ã€‚
    fn discover_dimensions_from_disk(&self, modality: &str) -> Vec<usize> {
        let mut dims = Vec::new();
        let prefix = format!("{}{}_", VFS_LANCE_TABLE_PREFIX, modality);

        let entries = match fs::read_dir(&self.lance_base_path) {
            Ok(entries) => entries,
            Err(_) => return dims,
        };

        for entry in entries.flatten() {
            let name = entry.file_name();
            let name = name.to_string_lossy();
            if let Some(suffix) = name.strip_prefix(&prefix) {
                if let Ok(dim) = suffix.parse::<usize>() {
                    dims.push(dim);
                }
            }
        }

        dims
    }

    fn get_all_registered_dimensions(&self) -> VfsResult<Vec<(String, usize)>> {
        use crate::vfs::repos::embedding_dim_repo;

        let conn = self.db.get_conn()?;
        let dims = embedding_dim_repo::list_all(&conn)?;
        Ok(dims
            .iter()
            .map(|d| (d.modality.clone(), d.dimension as usize))
            .collect())
    }

    // ========================================================================
    // è¡¨ç®¡ç†
    // ========================================================================

    /// åˆ é™¤æŒ‡å®šçš„ LanceDB è¡¨ï¼ˆS2 fix: ç»´åº¦åˆ é™¤æ—¶æ¸…ç†å‘é‡æ•°æ®ï¼‰
    ///
    /// å¦‚æœè¡¨ä¸å­˜åœ¨åˆ™é™é»˜è¿”å› Okã€‚
    pub async fn drop_table(&self, table_name: &str) -> VfsResult<()> {
        let conn = self.connect().await?;
        match conn.drop_table(table_name, &[]).await {
            Ok(_) => {
                info!("[VfsLanceStore] Dropped table: {}", table_name);
                Ok(())
            }
            Err(e) => {
                let msg = e.to_string();
                // è¡¨ä¸å­˜åœ¨ä¸ç®—é”™è¯¯
                if msg.contains("not found")
                    || msg.contains("does not exist")
                    || msg.contains("Table not found")
                {
                    debug!(
                        "[VfsLanceStore] Table {} does not exist, skip drop",
                        table_name
                    );
                    Ok(())
                } else {
                    Err(VfsError::Other(format!(
                        "Failed to drop Lance table {}: {}",
                        table_name, e
                    )))
                }
            }
        }
    }

    /// ç¡®ä¿å‘é‡è¡¨å­˜åœ¨ï¼ˆåŠ¨æ€åˆ›å»ºï¼‰
    pub async fn ensure_table(&self, modality: &str, dim: usize) -> VfsResult<Table> {
        let conn = self.connect().await?;
        let table_name = Self::table_name(modality, dim);

        let tbl = match conn.open_table(&table_name).execute().await {
            Ok(tbl) => tbl,
            Err(_) => {
                // åˆ›å»ºæ–°è¡¨
                let schema = Self::build_schema(dim);
                let empty: Vec<std::result::Result<RecordBatch, arrow_schema::ArrowError>> =
                    Vec::new();
                let iter = RecordBatchIterator::new(empty.into_iter(), Arc::new(schema));

                conn.create_table(&table_name, iter)
                    .execute()
                    .await
                    .map_err(|e| VfsError::Other(format!("åˆ›å»º Lance è¡¨å¤±è´¥: {}", e)))?
            }
        };

        // ç¡®ä¿å‘é‡ç´¢å¼•
        let embed_start = Instant::now();
        let embed_res = tbl
            .create_index(&["embedding"], Index::Auto)
            .replace(false)
            .execute()
            .await;

        if let Err(err) = embed_res {
            let msg = err.to_string();
            if !msg.contains("already exists") {
                warn!(
                    "[VfsLanceStore] embedding index ensure failed on {}: {}",
                    table_name, msg
                );
            }
        } else {
            debug!(
                "[VfsLanceStore] ensured embedding index on {} in {}ms",
                table_name,
                embed_start.elapsed().as_millis()
            );
        }

        // ç¡®ä¿ FTS ç´¢å¼•
        let fts_start = Instant::now();
        let fts_builder = self.build_fts_index_builder();
        let fts_res = tbl
            .create_index(&["text"], Index::FTS(fts_builder))
            .replace(false)
            .execute()
            .await;

        match fts_res {
            Ok(_) => {
                debug!(
                    "[VfsLanceStore] ensured FTS index on {} in {}ms",
                    table_name,
                    fts_start.elapsed().as_millis()
                );
            }
            Err(err) => {
                let msg = err.to_string();
                if !msg.contains("already exists") {
                    warn!(
                        "[VfsLanceStore] FTS index ensure failed on {}: {}",
                        table_name, msg
                    );
                }
            }
        }

        Ok(tbl)
    }

    /// æ„å»ºè¡¨ Schema
    fn build_schema(dim: usize) -> Schema {
        Schema::new(vec![
            Field::new("embedding_id", DataType::Utf8, false),
            Field::new("resource_id", DataType::Utf8, false),
            Field::new("resource_type", DataType::Utf8, false),
            Field::new("folder_id", DataType::Utf8, true),
            Field::new("chunk_index", DataType::Int32, false),
            Field::new("text", DataType::Utf8, false),
            Field::new("metadata", DataType::Utf8, true),
            Field::new("created_at", DataType::Utf8, false),
            Field::new(
                "embedding",
                DataType::FixedSizeList(
                    Arc::new(Field::new("item", DataType::Float32, false)),
                    dim as i32,
                ),
                false,
            ),
        ])
    }

    /// æ„å»º FTS ç´¢å¼•é…ç½®
    fn build_fts_index_builder(&self) -> FtsIndexBuilder {
        // ä½¿ç”¨ ngram åˆ†è¯å™¨ï¼Œé€‚åˆä¸­æ–‡
        FtsIndexBuilder::default()
            .base_tokenizer("ngram".to_string())
            .ngram_min_length(2)
            .ngram_max_length(4)
            .ngram_prefix_only(true)
            .max_token_length(Some(64))
            .lower_case(true)
            .stem(false)
            .remove_stop_words(false)
            .ascii_folding(true)
    }

    // ========================================================================
    // å†™å…¥æ“ä½œ
    // ========================================================================

    /// æ‰¹é‡å†™å…¥å‘é‡æ•°æ®
    pub async fn write_chunks(&self, modality: &str, rows: &[VfsLanceRow]) -> VfsResult<()> {
        if rows.is_empty() {
            return Ok(());
        }

        let dim = rows[0].embedding.len();

        let with_metadata = rows.iter().filter(|r| r.metadata_json.is_some()).count();
        info!(
            "[VfsLanceStore] write_chunks: dim={}, rows={}, with_metadata={}",
            dim,
            rows.len(),
            with_metadata
        );
        if with_metadata > 0 {
            if let Some(first_meta) = rows.iter().find_map(|r| r.metadata_json.as_ref()) {
                info!("[VfsLanceStore] sample metadata_json: {}", first_meta);
            }
        }

        let tbl = self.ensure_table(modality, dim).await?;

        // åˆ é™¤å·²å­˜åœ¨çš„è®°å½•ï¼ˆæŒ‰ embedding_idï¼‰
        let embedding_ids: Vec<String> = rows.iter().map(|r| r.embedding_id.clone()).collect();
        for batch_ids in embedding_ids.chunks(900) {
            let in_list = batch_ids
                .iter()
                .map(|s| format!("'{}'", s.replace("'", "''")))
                .collect::<Vec<_>>()
                .join(",");
            let expr = format!("embedding_id IN ({})", in_list);
            let _ = tbl.delete(expr.as_str()).await;
        }

        // æ„å»ºæ‰¹æ¬¡å¹¶å†™å…¥
        let (schema, batch) = self.build_batch(dim, rows)?;
        let iter = RecordBatchIterator::new(vec![Ok(batch)].into_iter(), schema);

        tbl.add(iter)
            .execute()
            .await
            .map_err(|e| VfsError::Other(format!("å†™å…¥ Lance è¡¨å¤±è´¥: {}", e)))?;

        info!(
            "[VfsLanceStore] Wrote {} chunks to {}",
            rows.len(),
            Self::table_name(modality, dim)
        );

        Ok(())
    }

    /// æ„å»º RecordBatch
    fn build_batch(
        &self,
        dim: usize,
        rows: &[VfsLanceRow],
    ) -> VfsResult<(Arc<Schema>, RecordBatch)> {
        let n = rows.len();
        let mut flat: Vec<f32> = Vec::with_capacity(n * dim);

        for row in rows.iter() {
            if row.embedding.len() != dim {
                return Err(VfsError::InvalidArgument {
                    param: "embedding".to_string(),
                    reason: format!("ç»´åº¦ä¸ä¸€è‡´: expected {}, got {}", dim, row.embedding.len()),
                });
            }
            flat.extend_from_slice(&row.embedding);
        }

        let schema = Arc::new(Self::build_schema(dim));

        let embedding_id_arr: ArrayRef = Arc::new(StringArray::from_iter_values(
            rows.iter().map(|r| r.embedding_id.as_str()),
        ));
        let resource_id_arr: ArrayRef = Arc::new(StringArray::from_iter_values(
            rows.iter().map(|r| r.resource_id.as_str()),
        ));
        let resource_type_arr: ArrayRef = Arc::new(StringArray::from_iter_values(
            rows.iter().map(|r| r.resource_type.as_str()),
        ));
        let folder_id_arr: ArrayRef = Arc::new(StringArray::from_iter(
            rows.iter().map(|r| r.folder_id.as_deref()),
        ));
        let chunk_index_arr: ArrayRef = Arc::new(Int32Array::from_iter_values(
            rows.iter().map(|r| r.chunk_index),
        ));
        let text_arr: ArrayRef = Arc::new(StringArray::from_iter_values(
            rows.iter().map(|r| r.text.as_str()),
        ));
        let metadata_arr: ArrayRef = Arc::new(StringArray::from_iter(
            rows.iter().map(|r| r.metadata_json.as_deref()),
        ));
        let created_at_arr: ArrayRef = Arc::new(StringArray::from_iter_values(
            rows.iter().map(|r| r.created_at.as_str()),
        ));

        let values = Arc::new(Float32Array::from(flat)) as ArrayRef;
        let field_ref = Arc::new(Field::new("item", DataType::Float32, false));
        let embedding_arr: ArrayRef = Arc::new(
            FixedSizeListArray::try_new(field_ref, dim as i32, values, None)
                .map_err(|e| VfsError::Other(format!("æ„å»º embedding æ•°ç»„å¤±è´¥: {}", e)))?,
        );

        let batch = RecordBatch::try_new(
            schema.clone(),
            vec![
                embedding_id_arr,
                resource_id_arr,
                resource_type_arr,
                folder_id_arr,
                chunk_index_arr,
                text_arr,
                metadata_arr,
                created_at_arr,
                embedding_arr,
            ],
        )
        .map_err(|e| VfsError::Other(format!("æ„å»ºæ‰¹æ¬¡å¤±è´¥: {}", e)))?;

        Ok((schema, batch))
    }

    /// åˆ é™¤èµ„æºçš„æ‰€æœ‰å‘é‡
    pub async fn delete_by_resource(&self, modality: &str, resource_id: &str) -> VfsResult<usize> {
        let conn = self.connect().await?;
        let mut deleted = 0usize;

        let mut dims = self.get_registered_dimensions(modality)?;
        for dim in self.discover_dimensions_from_disk(modality) {
            if !dims.contains(&dim) {
                dims.push(dim);
            }
        }

        dims.sort_unstable();
        dims.dedup();

        for dim in dims {
            let table_name = Self::table_name(modality, dim);
            if let Ok(tbl) = conn.open_table(&table_name).execute().await {
                let expr = format!("resource_id = '{}'", resource_id.replace("'", "''"));
                if tbl.delete(expr.as_str()).await.is_ok() {
                    deleted += 1;
                }
            }
        }

        debug!(
            "[VfsLanceStore] Deleted vectors for resource {} from {} tables",
            resource_id, deleted
        );

        Ok(deleted)
    }

    /// åˆ é™¤èµ„æºå‘é‡ï¼Œä½†ä¿ç•™æŒ‡å®šç»´åº¦çš„è¡¨ï¼ˆç”¨äºæ— ç©ºçª—é‡å»ºæµç¨‹ï¼‰ã€‚
    pub async fn delete_by_resource_except_dim(
        &self,
        modality: &str,
        resource_id: &str,
        keep_dim: usize,
    ) -> VfsResult<usize> {
        let conn = self.connect().await?;
        let mut deleted = 0usize;

        let mut dims = self.get_registered_dimensions(modality)?;
        for dim in self.discover_dimensions_from_disk(modality) {
            if !dims.contains(&dim) {
                dims.push(dim);
            }
        }

        dims.sort_unstable();
        dims.dedup();

        for dim in dims {
            if dim == keep_dim {
                continue;
            }
            let table_name = Self::table_name(modality, dim);
            if let Ok(tbl) = conn.open_table(&table_name).execute().await {
                let expr = format!("resource_id = '{}'", resource_id.replace("'", "''"));
                if tbl.delete(expr.as_str()).await.is_ok() {
                    deleted += 1;
                }
            }
        }

        debug!(
            "[VfsLanceStore] Deleted vectors for resource {} from {} tables (keep_dim={})",
            resource_id, deleted, keep_dim
        );

        Ok(deleted)
    }

    // ========================================================================
    // æ£€ç´¢æ“ä½œ
    // ========================================================================

    /// å‘é‡æ£€ç´¢
    pub async fn vector_search(
        &self,
        modality: &str,
        query_embedding: &[f32],
        top_k: usize,
        folder_ids: Option<&[String]>,
        resource_types: Option<&[String]>,
    ) -> VfsResult<Vec<VfsLanceSearchResult>> {
        self.vector_search_full(
            modality,
            query_embedding,
            top_k,
            folder_ids,
            None,
            resource_types,
        )
        .await
    }

    /// å‘é‡æ£€ç´¢ï¼ˆæ”¯æŒ resource_ids è¿‡æ»¤ï¼‰
    pub async fn vector_search_full(
        &self,
        modality: &str,
        query_embedding: &[f32],
        top_k: usize,
        folder_ids: Option<&[String]>,
        resource_ids: Option<&[String]>,
        resource_types: Option<&[String]>,
    ) -> VfsResult<Vec<VfsLanceSearchResult>> {
        let dim = query_embedding.len();
        let tbl = self.ensure_table(modality, dim).await?;

        let fetch_limit = (top_k * 3).max(20).min(500);

        // è¯Šæ–­æ—¥å¿—ï¼šæŸ¥è¯¢å‘é‡èŒƒæ•°
        let query_norm: f32 = query_embedding.iter().map(|x| x * x).sum::<f32>().sqrt();
        info!(
            "[VfsLanceStore] vector_search: dim={}, query_norm={:.6}, top_k={}, fetch_limit={}",
            dim, query_norm, top_k, fetch_limit
        );

        let start = Instant::now();
        debug!(
            "[VfsLanceStore] vector_search: dim={}, top_k={}, fetch_limit={}, folders={:?}, resources={:?}, types={:?}",
            dim, top_k, fetch_limit, folder_ids, resource_ids, resource_types
        );

        // æ„å»ºè¿‡æ»¤è¡¨è¾¾å¼
        let filter_expr = Self::build_filter_expr_full(folder_ids, resource_ids, resource_types);

        let mut query = tbl
            .vector_search(query_embedding)
            .map_err(|e| VfsError::Other(format!("å‘é‡æŸ¥è¯¢æ„å»ºå¤±è´¥: {}", e)))?
            .distance_type(DistanceType::Cosine)
            .limit(fetch_limit);

        if let Some(ref expr) = filter_expr {
            query = query.only_if(expr.as_str());
        }

        let mut stream = query
            .execute()
            .await
            .map_err(|e| VfsError::Other(format!("å‘é‡æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {}", e)))?;

        let mut results = Vec::new();
        while let Some(batch) = stream
            .try_next()
            .await
            .map_err(|e| VfsError::Other(format!("å‘é‡æŸ¥è¯¢æµè¯»å–å¤±è´¥: {}", e)))?
        {
            let batch_results = Self::extract_search_results(&batch)?;
            results.extend(batch_results);
        }

        // æŒ‰åˆ†æ•°æ’åºå¹¶æˆªæ–­
        results.sort_by(|a, b| b.score.partial_cmp(&a.score).unwrap_or(Ordering::Equal));
        results.truncate(top_k);

        info!(
            "[VfsLanceStore] vector_search completed: {} results in {}ms",
            results.len(),
            start.elapsed().as_millis()
        );

        Ok(results)
    }

    /// æ··åˆæ£€ç´¢ï¼ˆFTS + Vectorï¼‰
    pub async fn hybrid_search(
        &self,
        modality: &str,
        query_text: &str,
        query_embedding: &[f32],
        top_k: usize,
        folder_ids: Option<&[String]>,
        resource_types: Option<&[String]>,
    ) -> VfsResult<Vec<VfsLanceSearchResult>> {
        self.hybrid_search_full(
            modality,
            query_text,
            query_embedding,
            top_k,
            folder_ids,
            None,
            resource_types,
        )
        .await
    }

    /// æ··åˆæ£€ç´¢ï¼ˆæ”¯æŒ resource_ids è¿‡æ»¤ï¼‰
    pub async fn hybrid_search_full(
        &self,
        modality: &str,
        query_text: &str,
        query_embedding: &[f32],
        top_k: usize,
        folder_ids: Option<&[String]>,
        resource_ids: Option<&[String]>,
        resource_types: Option<&[String]>,
    ) -> VfsResult<Vec<VfsLanceSearchResult>> {
        let dim = query_embedding.len();
        let tbl = self.ensure_table(modality, dim).await?;

        let fetch_limit = (top_k * 3).max(20).min(500);

        // è¯Šæ–­æ—¥å¿—ï¼šæŸ¥è¯¢å‘é‡èŒƒæ•°
        let query_norm: f32 = query_embedding.iter().map(|x| x * x).sum::<f32>().sqrt();
        info!(
            "[VfsLanceStore] hybrid_search: dim={}, query_norm={:.6}, top_k={}, query='{}'",
            dim, query_norm, top_k, query_text
        );

        let start = Instant::now();
        debug!(
            "[VfsLanceStore] hybrid_search: dim={}, top_k={}, query='{}', resources={:?}",
            dim, top_k, query_text, resource_ids
        );

        let fts_query = FullTextSearchQuery::new(query_text.to_owned());
        let filter_expr = Self::build_filter_expr_full(folder_ids, resource_ids, resource_types);

        let mut query = tbl
            .query()
            .full_text_search(fts_query)
            .nearest_to(query_embedding.to_vec())
            .map_err(|e| VfsError::Other(format!("æ··åˆæŸ¥è¯¢æ„å»ºå¤±è´¥: {}", e)))?
            .distance_type(DistanceType::Cosine)
            .limit(fetch_limit);

        if let Some(ref expr) = filter_expr {
            query = query.only_if(expr.as_str());
        }

        let mut stream = query
            .execute_hybrid(QueryExecutionOptions::default())
            .await
            .map_err(|e| VfsError::Other(format!("æ··åˆæŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {}", e)))?;

        let mut results = Vec::new();
        while let Some(batch) = stream
            .try_next()
            .await
            .map_err(|e| VfsError::Other(format!("æ··åˆæŸ¥è¯¢æµè¯»å–å¤±è´¥: {}", e)))?
        {
            let batch_results = Self::extract_search_results_hybrid(&batch)?;
            results.extend(batch_results);
        }

        // æŒ‰åˆ†æ•°æ’åºå¹¶æˆªæ–­
        results.sort_by(|a, b| b.score.partial_cmp(&a.score).unwrap_or(Ordering::Equal));
        results.truncate(top_k);

        // å½’ä¸€åŒ– RRF å¾—åˆ†åˆ° [0, 1] èŒƒå›´ï¼Œä½¿æœ€é«˜åˆ†æ¥è¿‘ 1.0
        // RRF å¾—åˆ†å…¬å¼: 1 / (k + rank)ï¼Œk=60 æ—¶æœ€å¤§çº¦ 0.0164
        if !results.is_empty() {
            let max_score = results.iter().map(|r| r.score).fold(0.0f32, f32::max);
            if max_score > 0.0 {
                for r in results.iter_mut() {
                    r.score = (r.score / max_score).clamp(0.0, 1.0);
                }
            }
        }

        info!(
            "[VfsLanceStore] hybrid_search completed: {} results in {}ms",
            results.len(),
            start.elapsed().as_millis()
        );

        Ok(results)
    }

    /// æ„å»ºè¿‡æ»¤è¡¨è¾¾å¼
    fn build_filter_expr(
        folder_ids: Option<&[String]>,
        resource_types: Option<&[String]>,
    ) -> Option<String> {
        Self::build_filter_expr_full(folder_ids, None, resource_types)
    }

    /// æ„å»ºå®Œæ•´è¿‡æ»¤è¡¨è¾¾å¼ï¼ˆæ”¯æŒ resource_idsï¼‰
    fn build_filter_expr_full(
        folder_ids: Option<&[String]>,
        resource_ids: Option<&[String]>,
        resource_types: Option<&[String]>,
    ) -> Option<String> {
        let mut parts = Vec::new();

        // æ–‡ä»¶å¤¹è¿‡æ»¤
        if let Some(ids) = folder_ids {
            let values: Vec<String> = ids
                .iter()
                .filter(|s| !s.trim().is_empty())
                .map(|s| format!("'{}'", s.replace("'", "''")))
                .collect();

            if !values.is_empty() {
                if values.len() == 1 {
                    parts.push(format!("folder_id = {}", values[0]));
                } else {
                    parts.push(format!("folder_id IN ({})", values.join(", ")));
                }
            }
        }

        // ğŸ†• èµ„æº ID è¿‡æ»¤ï¼ˆç²¾ç¡®åˆ°ç‰¹å®šæ–‡æ¡£ï¼‰
        if let Some(ids) = resource_ids {
            let values: Vec<String> = ids
                .iter()
                .filter(|s| !s.trim().is_empty())
                .map(|s| format!("'{}'", s.replace("'", "''")))
                .collect();

            if !values.is_empty() {
                if values.len() == 1 {
                    parts.push(format!("resource_id = {}", values[0]));
                } else {
                    parts.push(format!("resource_id IN ({})", values.join(", ")));
                }
            }
        }

        // èµ„æºç±»å‹è¿‡æ»¤
        if let Some(types) = resource_types {
            let values: Vec<String> = types
                .iter()
                .filter(|s| !s.trim().is_empty())
                .map(|s| format!("'{}'", s.replace("'", "''")))
                .collect();

            if !values.is_empty() {
                if values.len() == 1 {
                    parts.push(format!("resource_type = {}", values[0]));
                } else {
                    parts.push(format!("resource_type IN ({})", values.join(", ")));
                }
            }
        }

        if parts.is_empty() {
            None
        } else {
            Some(parts.join(" AND "))
        }
    }

    /// ä»æ‰¹æ¬¡ä¸­æå–æœç´¢ç»“æœï¼ˆå‘é‡æ£€ç´¢ï¼‰
    fn extract_search_results(batch: &RecordBatch) -> VfsResult<Vec<VfsLanceSearchResult>> {
        let schema = batch.schema();

        // å½“è¡¨ä¸ºç©ºæˆ–æ— åŒ¹é…æ—¶ï¼Œå¯èƒ½è¿”å›ä¸å«æ•°æ®åˆ—çš„ batchï¼Œç›´æ¥è¿”å›ç©ºç»“æœ
        if batch.num_rows() == 0 || schema.index_of("embedding_id").is_err() {
            debug!(
                "[VfsLanceStore] extract_search_results: skipping batch with {} rows, fields={:?}",
                batch.num_rows(),
                schema
                    .fields()
                    .iter()
                    .map(|f| f.name().as_str())
                    .collect::<Vec<_>>()
            );
            return Ok(Vec::new());
        }

        let idx_emb_id = schema
            .index_of("embedding_id")
            .map_err(|e| VfsError::Other(format!("ç¼ºå°‘ embedding_id åˆ—: {}", e)))?;
        let idx_res_id = schema
            .index_of("resource_id")
            .map_err(|e| VfsError::Other(format!("ç¼ºå°‘ resource_id åˆ—: {}", e)))?;
        let idx_res_type = schema
            .index_of("resource_type")
            .map_err(|e| VfsError::Other(format!("ç¼ºå°‘ resource_type åˆ—: {}", e)))?;
        let idx_folder = schema.index_of("folder_id").ok();
        let idx_chunk = schema
            .index_of("chunk_index")
            .map_err(|e| VfsError::Other(format!("ç¼ºå°‘ chunk_index åˆ—: {}", e)))?;
        let idx_text = schema
            .index_of("text")
            .map_err(|e| VfsError::Other(format!("ç¼ºå°‘ text åˆ—: {}", e)))?;
        let idx_meta = schema.index_of("metadata").ok();
        let idx_dist = schema.index_of("_distance").ok();

        let emb_id_arr = batch
            .column(idx_emb_id)
            .as_any()
            .downcast_ref::<StringArray>()
            .ok_or_else(|| VfsError::Other("embedding_id åˆ—ç±»å‹é”™è¯¯".to_string()))?;
        let res_id_arr = batch
            .column(idx_res_id)
            .as_any()
            .downcast_ref::<StringArray>()
            .ok_or_else(|| VfsError::Other("resource_id åˆ—ç±»å‹é”™è¯¯".to_string()))?;
        let res_type_arr = batch
            .column(idx_res_type)
            .as_any()
            .downcast_ref::<StringArray>()
            .ok_or_else(|| VfsError::Other("resource_type åˆ—ç±»å‹é”™è¯¯".to_string()))?;
        let folder_arr =
            idx_folder.and_then(|i| batch.column(i).as_any().downcast_ref::<StringArray>());
        let chunk_arr = batch
            .column(idx_chunk)
            .as_any()
            .downcast_ref::<Int32Array>()
            .ok_or_else(|| VfsError::Other("chunk_index åˆ—ç±»å‹é”™è¯¯".to_string()))?;
        let text_arr = batch
            .column(idx_text)
            .as_any()
            .downcast_ref::<StringArray>()
            .ok_or_else(|| VfsError::Other("text åˆ—ç±»å‹é”™è¯¯".to_string()))?;
        let meta_arr =
            idx_meta.and_then(|i| batch.column(i).as_any().downcast_ref::<StringArray>());

        // è§£æè·ç¦»/åˆ†æ•°
        let mut dists: Option<Vec<f32>> = None;
        if let Some(idx) = idx_dist {
            let col = batch.column(idx);
            if let Some(arr32) = col.as_any().downcast_ref::<Float32Array>() {
                dists = Some((0..arr32.len()).map(|j| arr32.value(j)).collect());
            } else if let Some(arr64) = col.as_any().downcast_ref::<arrow_array::Float64Array>() {
                dists = Some((0..arr64.len()).map(|j| arr64.value(j) as f32).collect());
            }
        }

        let mut results = Vec::with_capacity(batch.num_rows());
        for i in 0..batch.num_rows() {
            let dist = dists.as_ref().map(|v| v[i]).unwrap_or(1.0);
            let score = (1.0 - dist).clamp(-1.0, 1.0);

            // è¯Šæ–­æ—¥å¿—ï¼šæŸ¥çœ‹å®é™…è·ç¦»å€¼
            if i < 3 {
                debug!(
                    "[VfsLanceStore] Result {}: _distance={:.6}, score={:.6}",
                    i, dist, score
                );
            }

            let metadata_json = meta_arr.and_then(|arr| {
                if arr.is_null(i) {
                    None
                } else {
                    Some(arr.value(i).to_string())
                }
            });
            let (page_index, source_id) = Self::parse_metadata_fields(&metadata_json);

            results.push(VfsLanceSearchResult {
                embedding_id: emb_id_arr.value(i).to_string(),
                resource_id: res_id_arr.value(i).to_string(),
                resource_type: res_type_arr.value(i).to_string(),
                folder_id: folder_arr.and_then(|arr| {
                    if arr.is_null(i) {
                        None
                    } else {
                        Some(arr.value(i).to_string())
                    }
                }),
                chunk_index: chunk_arr.value(i),
                text: text_arr.value(i).to_string(),
                score,
                metadata_json,
                page_index,
                source_id,
            });
        }

        Ok(results)
    }

    /// ä»æ‰¹æ¬¡ä¸­æå–æœç´¢ç»“æœï¼ˆæ··åˆæ£€ç´¢ï¼‰
    fn extract_search_results_hybrid(batch: &RecordBatch) -> VfsResult<Vec<VfsLanceSearchResult>> {
        let schema = batch.schema();

        // å½“è¡¨ä¸ºç©ºæˆ–æ··åˆæ£€ç´¢æ— åŒ¹é…æ—¶ï¼ŒLanceDB çš„ RRF reranker å¯èƒ½åªè¿”å›åˆ†æ•°åˆ—
        // ï¼ˆå¦‚ _score, _relevance_scoreï¼‰ï¼Œä¸åŒ…å«æ•°æ®åˆ—ã€‚æ­¤æ—¶ç›´æ¥è¿”å›ç©ºç»“æœã€‚
        if batch.num_rows() == 0 || schema.index_of("embedding_id").is_err() {
            debug!(
                "[VfsLanceStore] extract_search_results_hybrid: skipping batch with {} rows, fields={:?}",
                batch.num_rows(),
                schema.fields().iter().map(|f| f.name().as_str()).collect::<Vec<_>>()
            );
            return Ok(Vec::new());
        }

        let idx_emb_id = schema
            .index_of("embedding_id")
            .map_err(|e| VfsError::Other(format!("ç¼ºå°‘ embedding_id åˆ—: {}", e)))?;
        let idx_res_id = schema
            .index_of("resource_id")
            .map_err(|e| VfsError::Other(format!("ç¼ºå°‘ resource_id åˆ—: {}", e)))?;
        let idx_res_type = schema
            .index_of("resource_type")
            .map_err(|e| VfsError::Other(format!("ç¼ºå°‘ resource_type åˆ—: {}", e)))?;
        let idx_folder = schema.index_of("folder_id").ok();
        let idx_chunk = schema
            .index_of("chunk_index")
            .map_err(|e| VfsError::Other(format!("ç¼ºå°‘ chunk_index åˆ—: {}", e)))?;
        let idx_text = schema
            .index_of("text")
            .map_err(|e| VfsError::Other(format!("ç¼ºå°‘ text åˆ—: {}", e)))?;
        let idx_meta = schema.index_of("metadata").ok();
        let idx_dist = schema.index_of("_distance").ok();
        let idx_relevance = schema.index_of(LANCE_RELEVANCE_COL).ok();
        let idx_score = schema.index_of(LANCE_FTS_SCORE_COL).ok();

        let emb_id_arr = batch
            .column(idx_emb_id)
            .as_any()
            .downcast_ref::<StringArray>()
            .ok_or_else(|| VfsError::Other("embedding_id åˆ—ç±»å‹é”™è¯¯".to_string()))?;
        let res_id_arr = batch
            .column(idx_res_id)
            .as_any()
            .downcast_ref::<StringArray>()
            .ok_or_else(|| VfsError::Other("resource_id åˆ—ç±»å‹é”™è¯¯".to_string()))?;
        let res_type_arr = batch
            .column(idx_res_type)
            .as_any()
            .downcast_ref::<StringArray>()
            .ok_or_else(|| VfsError::Other("resource_type åˆ—ç±»å‹é”™è¯¯".to_string()))?;
        let folder_arr =
            idx_folder.and_then(|i| batch.column(i).as_any().downcast_ref::<StringArray>());
        let chunk_arr = batch
            .column(idx_chunk)
            .as_any()
            .downcast_ref::<Int32Array>()
            .ok_or_else(|| VfsError::Other("chunk_index åˆ—ç±»å‹é”™è¯¯".to_string()))?;
        let text_arr = batch
            .column(idx_text)
            .as_any()
            .downcast_ref::<StringArray>()
            .ok_or_else(|| VfsError::Other("text åˆ—ç±»å‹é”™è¯¯".to_string()))?;
        let meta_arr =
            idx_meta.and_then(|i| batch.column(i).as_any().downcast_ref::<StringArray>());

        // è§£æè·ç¦»/åˆ†æ•°
        let mut dists: Option<Vec<f32>> = None;
        if let Some(idx) = idx_dist {
            let col = batch.column(idx);
            if let Some(arr32) = col.as_any().downcast_ref::<Float32Array>() {
                dists = Some((0..arr32.len()).map(|j| arr32.value(j)).collect());
            } else if let Some(arr64) = col.as_any().downcast_ref::<arrow_array::Float64Array>() {
                dists = Some((0..arr64.len()).map(|j| arr64.value(j) as f32).collect());
            }
        }

        let mut relevance_scores: Option<Vec<f32>> = None;
        if let Some(idx) = idx_relevance {
            if let Some(arr) = batch.column(idx).as_any().downcast_ref::<Float32Array>() {
                relevance_scores = Some((0..arr.len()).map(|j| arr.value(j)).collect());
            }
        }

        let mut fts_scores: Option<Vec<f32>> = None;
        if let Some(idx) = idx_score {
            if let Some(arr) = batch.column(idx).as_any().downcast_ref::<Float32Array>() {
                fts_scores = Some((0..arr.len()).map(|j| arr.value(j)).collect());
            }
        }

        let mut results = Vec::with_capacity(batch.num_rows());
        for i in 0..batch.num_rows() {
            let dist_val = dists.as_ref().map(|v| v[i]);
            let rel_val = relevance_scores.as_ref().map(|v| v[i]);
            let fts_val = fts_scores.as_ref().map(|v| v[i]);

            let score = if let Some(ref rel) = relevance_scores {
                rel[i]
            } else if let Some(ref dist_vec) = dists {
                (1.0 - dist_vec[i]).clamp(-1.0, 1.0)
            } else if let Some(ref fts_vec) = fts_scores {
                fts_vec[i]
            } else {
                0.0
            };

            // è¯Šæ–­æ—¥å¿—ï¼šæŸ¥çœ‹æ··åˆæ£€ç´¢çš„å„é¡¹å¾—åˆ†
            if i < 3 {
                info!(
                    "[VfsLanceStore] Hybrid Result {}: _distance={:?}, _relevance={:?}, _fts={:?}, final_score={:.6}",
                    i, dist_val, rel_val, fts_val, score
                );
            }

            let metadata_json = meta_arr.and_then(|arr| {
                if arr.is_null(i) {
                    None
                } else {
                    Some(arr.value(i).to_string())
                }
            });
            let (page_index, source_id) = Self::parse_metadata_fields(&metadata_json);

            results.push(VfsLanceSearchResult {
                embedding_id: emb_id_arr.value(i).to_string(),
                resource_id: res_id_arr.value(i).to_string(),
                resource_type: res_type_arr.value(i).to_string(),
                folder_id: folder_arr.and_then(|arr| {
                    if arr.is_null(i) {
                        None
                    } else {
                        Some(arr.value(i).to_string())
                    }
                }),
                chunk_index: chunk_arr.value(i),
                text: text_arr.value(i).to_string(),
                score,
                metadata_json,
                page_index,
                source_id,
            });
        }

        Ok(results)
    }

    /// ä» metadata_json ä¸­è§£æ page_index å’Œ source_id
    fn parse_metadata_fields(metadata_json: &Option<String>) -> (Option<i32>, Option<String>) {
        let Some(json_str) = metadata_json else {
            return (None, None);
        };
        let Ok(json) = serde_json::from_str::<serde_json::Value>(json_str) else {
            return (None, None);
        };
        let page_index = json
            .get("page_index")
            .and_then(|v| v.as_i64())
            .map(|v| v as i32);
        let source_id = json
            .get("source_id")
            .and_then(|v| v.as_str())
            .map(|s| s.to_string());
        (page_index, source_id)
    }

    // ========================================================================
    // è¡¨ä¼˜åŒ–
    // ========================================================================

    /// ä¼˜åŒ–æŒ‡å®šè¡¨
    pub async fn optimize_table(&self, modality: &str, dim: usize) -> VfsResult<()> {
        let table_name = Self::table_name(modality, dim);
        let conn = self.connect().await?;

        let tbl = match conn.open_table(&table_name).execute().await {
            Ok(tbl) => tbl,
            Err(_) => return Ok(()), // è¡¨ä¸å­˜åœ¨ï¼Œè·³è¿‡
        };

        let start = Instant::now();

        // Compact
        let compact_stats = tbl
            .optimize(OptimizeAction::Compact {
                options: lancedb::table::CompactionOptions::default(),
                remap_options: None,
            })
            .await
            .map_err(|e| VfsError::Other(format!("Compact ä¼˜åŒ–å¤±è´¥: {}", e)))?;

        if let Some(metrics) = compact_stats.compaction {
            info!(
                "[VfsLanceStore] {} Compact: +{} / -{}",
                table_name, metrics.files_added, metrics.files_removed
            );
        }

        // Prune
        let prune_stats = tbl
            .optimize(OptimizeAction::Prune {
                older_than: chrono::Duration::try_days(7),
                delete_unverified: Some(false),
                error_if_tagged_old_versions: Some(false),
            })
            .await
            .map_err(|e| VfsError::Other(format!("Prune ä¼˜åŒ–å¤±è´¥: {}", e)))?;

        if let Some(metrics) = prune_stats.prune {
            info!(
                "[VfsLanceStore] {} Prune: åˆ é™¤{}ä¸ªæ—§ç‰ˆæœ¬, å›æ”¶{}å­—èŠ‚",
                table_name, metrics.old_versions, metrics.bytes_removed
            );
        }

        // Index
        tbl.optimize(OptimizeAction::Index(OptimizeOptions::default()))
            .await
            .map_err(|e| VfsError::Other(format!("Index ä¼˜åŒ–å¤±è´¥: {}", e)))?;

        info!(
            "[VfsLanceStore] {} ä¼˜åŒ–å®Œæˆï¼Œè€—æ—¶ {}ms",
            table_name,
            start.elapsed().as_millis()
        );

        Ok(())
    }

    /// ä¼˜åŒ–æ‰€æœ‰è¡¨
    pub async fn optimize_all(&self, modality: &str) -> VfsResult<usize> {
        let mut optimized = 0usize;

        let dims = self.get_registered_dimensions(modality)?;
        for dim in dims {
            if self.optimize_table(modality, dim).await.is_ok() {
                optimized += 1;
            }
        }

        Ok(optimized)
    }

    /// è·å–è¡¨ç»Ÿè®¡ä¿¡æ¯
    pub async fn get_table_stats(&self, modality: &str) -> VfsResult<Vec<(String, usize)>> {
        let conn = self.connect().await?;
        let mut stats = Vec::new();

        let dims = self.get_registered_dimensions(modality)?;
        for dim in dims {
            let table_name = Self::table_name(modality, dim);
            if let Ok(tbl) = conn.open_table(&table_name).execute().await {
                if let Ok(count) = tbl.count_rows(None).await {
                    if count > 0 {
                        stats.push((table_name, count));
                    }
                }
            }
        }

        Ok(stats)
    }

    /// â˜… 2026-01 è¯Šæ–­ï¼šè·å– Lance è¡¨ schema è¯Šæ–­ä¿¡æ¯
    ///
    /// æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨ metadata åˆ—ï¼Œç”¨äºæ’æŸ¥ pageIndex ä¸º null çš„é—®é¢˜
    pub async fn diagnose_table_schema(
        &self,
        modality: &str,
    ) -> VfsResult<Vec<LanceTableDiagnostic>> {
        let conn = self.connect().await?;
        let mut diagnostics = Vec::new();

        let dims = self.get_registered_dimensions(modality)?;
        for dim in dims {
            let table_name = Self::table_name(modality, dim);
            if let Ok(tbl) = conn.open_table(&table_name).execute().await {
                // è·å–è¡¨ schema
                let schema = tbl
                    .schema()
                    .await
                    .map_err(|e| VfsError::Other(format!("è·å– schema å¤±è´¥: {}", e)))?;
                let columns: Vec<String> = schema
                    .fields()
                    .iter()
                    .map(|f| f.name().to_string())
                    .collect();

                // æ£€æŸ¥å…³é”®åˆ—
                let has_metadata = columns.contains(&"metadata".to_string());
                let has_embedding_id = columns.contains(&"embedding_id".to_string());
                let has_resource_id = columns.contains(&"resource_id".to_string());
                let has_text = columns.contains(&"text".to_string());

                // è·å–è¡Œæ•°
                let row_count = tbl.count_rows(None).await.unwrap_or(0);

                // æŠ½æ ·æ£€æŸ¥ metadata åˆ—å†…å®¹
                let mut sample_metadata: Vec<Option<String>> = Vec::new();
                let mut metadata_with_page_index = 0usize;
                let mut metadata_null_count = 0usize;

                if has_metadata && row_count > 0 {
                    if let Ok(mut stream) = tbl.query().execute().await {
                        let mut total_checked = 0usize;
                        while let Ok(Some(batch)) = stream.try_next().await {
                            let batch_schema = batch.schema();
                            if let Ok(idx) = batch_schema.index_of("metadata") {
                                if let Some(arr) =
                                    batch.column(idx).as_any().downcast_ref::<StringArray>()
                                {
                                    for i in 0..arr.len() {
                                        if arr.is_null(i) {
                                            metadata_null_count += 1;
                                        } else {
                                            let val = arr.value(i).to_string();
                                            if val.contains("page_index")
                                                && !val.contains("\"page_index\":null")
                                            {
                                                metadata_with_page_index += 1;
                                            }
                                            if sample_metadata.len() < 10 {
                                                sample_metadata.push(Some(val));
                                            }
                                        }
                                        total_checked += 1;
                                    }
                                }
                            }
                        }
                        for _ in sample_metadata.len()..10.min(metadata_null_count) {
                            sample_metadata.push(None);
                        }
                    }
                }

                diagnostics.push(LanceTableDiagnostic {
                    table_name,
                    dimension: dim,
                    row_count,
                    columns,
                    has_metadata_column: has_metadata,
                    has_embedding_id_column: has_embedding_id,
                    has_resource_id_column: has_resource_id,
                    has_text_column: has_text,
                    sample_metadata,
                    metadata_with_page_index,
                    metadata_null_count,
                    schema_valid: has_metadata && has_embedding_id && has_resource_id && has_text,
                    issue_description: if !has_metadata {
                        Some("ç¼ºå°‘ metadata åˆ—ï¼ŒpageIndex å°†å§‹ç»ˆä¸º nullã€‚éœ€è¦é‡å»ºè¡¨æˆ–è¿ç§» schemaã€‚".to_string())
                    } else if metadata_with_page_index == 0 && row_count > 0 {
                        Some("metadata åˆ—å­˜åœ¨ä½†æ‰€æœ‰è®°å½•çš„ page_index éƒ½ä¸º nullï¼Œå¯èƒ½æ˜¯ç´¢å¼•æ—¶æœªæ­£ç¡®è®¾ç½®ã€‚".to_string())
                    } else {
                        None
                    },
                });
            }
        }

        Ok(diagnostics)
    }

    /// æ¸…é™¤æŒ‡å®šæ¨¡æ€çš„æ‰€æœ‰å‘é‡æ•°æ®
    ///
    /// åˆ é™¤æ‰€æœ‰ç»´åº¦è¡¨ä¸­çš„å…¨éƒ¨æ•°æ®
    pub async fn clear_all(&self, modality: &str) -> VfsResult<usize> {
        let conn = self.connect().await?;
        let mut deleted_tables = 0usize;

        let dims = self.get_registered_dimensions(modality)?;
        for dim in dims {
            let table_name = Self::table_name(modality, dim);
            if let Ok(tbl) = conn.open_table(&table_name).execute().await {
                // åˆ é™¤è¡¨ä¸­æ‰€æœ‰æ•°æ®
                if tbl.delete("true").await.is_ok() {
                    deleted_tables += 1;
                    info!("[VfsLanceStore] Cleared all data from table {}", table_name);
                }
            }
        }

        info!(
            "[VfsLanceStore] Cleared {} tables for modality {}",
            deleted_tables, modality
        );

        Ok(deleted_tables)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_table_name() {
        assert_eq!(VfsLanceStore::table_name("text", 768), "vfs_emb_text_768");
        assert_eq!(
            VfsLanceStore::table_name("multimodal", 4096),
            "vfs_emb_multimodal_4096"
        );
    }

    #[test]
    fn test_build_filter_expr() {
        // æ— è¿‡æ»¤
        assert_eq!(VfsLanceStore::build_filter_expr(None, None), None);

        // å•ä¸ªæ–‡ä»¶å¤¹
        let folders = vec!["folder1".to_string()];
        let expr = VfsLanceStore::build_filter_expr(Some(&folders), None);
        assert_eq!(expr, Some("folder_id = 'folder1'".to_string()));

        // å¤šä¸ªæ–‡ä»¶å¤¹
        let folders = vec!["folder1".to_string(), "folder2".to_string()];
        let expr = VfsLanceStore::build_filter_expr(Some(&folders), None);
        assert_eq!(
            expr,
            Some("folder_id IN ('folder1', 'folder2')".to_string())
        );

        // å•ä¸ªç±»å‹
        let types = vec!["note".to_string()];
        let expr = VfsLanceStore::build_filter_expr(None, Some(&types));
        assert_eq!(expr, Some("resource_type = 'note'".to_string()));

        // ç»„åˆè¿‡æ»¤
        let folders = vec!["folder1".to_string()];
        let types = vec!["note".to_string(), "textbook".to_string()];
        let expr = VfsLanceStore::build_filter_expr(Some(&folders), Some(&types));
        assert_eq!(
            expr,
            Some("folder_id = 'folder1' AND resource_type IN ('note', 'textbook')".to_string())
        );
    }
}
