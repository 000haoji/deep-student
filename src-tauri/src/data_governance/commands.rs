//! # æ•°æ®æ²»ç† Tauri å‘½ä»¤
//!
//! å®šä¹‰æ•°æ®æ²»ç†ç³»ç»Ÿæš´éœ²ç»™å‰ç«¯çš„ Tauri å‘½ä»¤ã€‚
//!
//! ## å‘½ä»¤åˆ—è¡¨
//!
//! - `data_governance_get_schema_registry`: è·å– Schema æ³¨å†Œè¡¨
//! - `data_governance_get_audit_logs`: è·å–å®¡è®¡æ—¥å¿—
//! - `data_governance_get_migration_status`: è·å–è¿ç§»çŠ¶æ€
//! - `data_governance_run_health_check`: è¿è¡Œå¥åº·æ£€æŸ¥
//! - `data_governance_run_backup`: å¼‚æ­¥åå°å¤‡ä»½ï¼ˆå¸¦è¿›åº¦äº‹ä»¶ï¼‰
//! - `data_governance_backup_tiered`: å¼‚æ­¥åˆ†å±‚å¤‡ä»½ï¼ˆå¸¦è¿›åº¦äº‹ä»¶ï¼‰
//! - `data_governance_backup_and_export_zip`: ä¸€æ­¥å®Œæˆå¤‡ä»½å¹¶å¯¼å‡º ZIP
//! - `data_governance_export_zip`: å¼‚æ­¥ ZIP å¯¼å‡ºï¼ˆå¸¦è¿›åº¦äº‹ä»¶ï¼‰
//! - `data_governance_import_zip`: å¼‚æ­¥ ZIP å¯¼å…¥ï¼ˆå¸¦è¿›åº¦äº‹ä»¶ï¼‰
//! - `data_governance_restore_backup`: å¼‚æ­¥å¤‡ä»½æ¢å¤ï¼ˆå¸¦è¿›åº¦äº‹ä»¶ï¼‰
//! - `data_governance_cancel_backup`: å–æ¶ˆå¤‡ä»½ä»»åŠ¡
//! - `data_governance_get_backup_job`: è·å–å¤‡ä»½ä»»åŠ¡çŠ¶æ€
//! - `data_governance_list_backup_jobs`: è·å–æ‰€æœ‰å¤‡ä»½ä»»åŠ¡åˆ—è¡¨

use std::path::Path;
use std::sync::{Arc, RwLock};
use tauri::{AppHandle, Manager, State};

#[cfg(feature = "data_governance")]
use super::audit::{AuditFilter, AuditLog, AuditOperation, AuditRepository, AuditStatus};
use super::migration::{get_migration_set, MigrationCoordinator};
use super::schema_registry::{DatabaseId, DatabaseStatus, SchemaRegistry};
use crate::backup_common::{log_and_skip_entry_err, BACKUP_GLOBAL_LIMITER};
use crate::backup_job_manager::{
    BackupJobContext, BackupJobKind, BackupJobManagerState, BackupJobParams,
    BackupJobPhase, BackupJobResultPayload, BackupJobStatus, BackupJobSummary, PersistedJob,
};
use crate::utils::text::safe_truncate_chars;
use super::commands_types::{
    MaintenanceStatusResponse, SchemaRegistryResponse, DatabaseStatusResponse,
    AuditLogResponse, AuditLogPagedResponse, MigrationStatusResponse,
    MigrationDatabaseStatus, HealthCheckResponse, DatabaseHealthStatus,
    DatabaseDetailResponse, MigrationRecordResponse,
};
use super::commands_backup::{get_app_data_dir, sanitize_path_for_user};

fn resolve_target_and_pending(
    id: &DatabaseId,
    current_version: u32,
    status: Option<&DatabaseStatus>,
) -> (u32, usize) {
    let migration_set = get_migration_set(id.as_str());
    let target_version = status
        .map(|s| s.max_compatible_version)
        .or_else(|| migration_set.map(|set| set.latest_version() as u32))
        .unwrap_or(0);
    let pending_count = migration_set
        .map(|set| set.pending(current_version as i32).count())
        .unwrap_or(0);
    (target_version, pending_count)
}

/// æŒä¹…åŒ–è¿ç§»é”™è¯¯æ–‡ä»¶å
const MIGRATION_ERROR_FILE: &str = ".last_migration_error";

/// å°†çœŸå®çš„è¿ç§»é”™è¯¯æŒä¹…åŒ–åˆ°æ–‡ä»¶
///
/// è¿ç§»å¤±è´¥æ—¶ç”± lib.rs è°ƒç”¨ï¼Œå°†å®é™…çš„ SQL é”™è¯¯ä¿¡æ¯å†™å…¥æ–‡ä»¶ï¼Œ
/// ä¾›åç»­ `get_migration_status` å’Œè¯Šæ–­æŠ¥å‘Šè¯»å–ã€‚
pub fn persist_migration_error(app_data_dir: &Path, error: &str) {
    let error_file = app_data_dir.join(MIGRATION_ERROR_FILE);
    let payload = serde_json::json!({
        "error": error,
        "timestamp": chrono::Utc::now().to_rfc3339(),
    });
    if let Err(e) = std::fs::write(&error_file, payload.to_string()) {
        tracing::warn!(
            path = %error_file.display(),
            error = %e,
            "Failed to persist migration error to file"
        );
    }
}

/// è¿ç§»æˆåŠŸæ—¶æ¸…é™¤æŒä¹…åŒ–çš„é”™è¯¯æ–‡ä»¶
pub fn clear_migration_error(app_data_dir: &Path) {
    let error_file = app_data_dir.join(MIGRATION_ERROR_FILE);
    if error_file.exists() {
        let _ = std::fs::remove_file(&error_file);
    }
}

/// è¯»å–æŒä¹…åŒ–çš„è¿ç§»é”™è¯¯
fn read_persisted_migration_error(app_data_dir: &Path) -> Option<(String, String)> {
    let error_file = app_data_dir.join(MIGRATION_ERROR_FILE);
    let content = std::fs::read_to_string(&error_file).ok()?;
    let parsed: serde_json::Value = serde_json::from_str(&content).ok()?;
    let error = parsed.get("error")?.as_str()?.to_string();
    let timestamp = parsed.get("timestamp")?.as_str()?.to_string();
    Some((error, timestamp))
}

fn get_live_app_data_dir(app: &tauri::AppHandle) -> Result<std::path::PathBuf, String> {
    if let Some(state) = app.try_state::<crate::commands::AppState>() {
        return Ok(state.file_manager.get_writable_app_data_dir());
    }

    get_app_data_dir(app)
}

/// æ£€æŸ¥ä¸»æ•°æ®åº“æ˜¯å¦å¤„äºç»´æŠ¤æ¨¡å¼ã€‚
///
/// å½“å¤‡ä»½/æ¢å¤/æ•°æ®è¿ç§»ç­‰æ•°æ®æ²»ç†æ“ä½œæ­£åœ¨è¿›è¡Œæ—¶ï¼Œ
/// åŒæ­¥å‘½ä»¤ä¸åº”è®¿é—®æ•°æ®åº“æ–‡ä»¶ï¼Œå¦åˆ™ä¼šç»•è¿‡ç»´æŠ¤æ¨¡å¼é€ æˆæ•°æ®ä¸ä¸€è‡´ã€‚
pub(super) fn check_maintenance_mode(app: &tauri::AppHandle) -> Result<(), String> {
    if let Some(state) = app.try_state::<crate::commands::AppState>() {
        if state.database.is_in_maintenance_mode() {
            return Err("æ•°æ®æ²»ç†æ“ä½œæ­£åœ¨è¿›è¡Œï¼ˆç»´æŠ¤æ¨¡å¼ï¼‰ï¼Œè¯·ç¨åå†è¯•ã€‚".to_string());
        }
    }
    Ok(())
}

#[derive(Debug, Clone, serde::Serialize)]
pub struct AuditHealthSnapshot {
    pub is_healthy: bool,
    pub last_error: Option<String>,
    pub last_error_at: Option<String>,
}

#[derive(Debug, Clone)]
struct AuditHealthError {
    message: String,
    occurred_at: String,
}

#[derive(Default)]
pub struct AuditHealthState {
    last_error: std::sync::Mutex<Option<AuditHealthError>>,
}

impl AuditHealthSnapshot {
    fn healthy() -> Self {
        Self {
            is_healthy: true,
            last_error: None,
            last_error_at: None,
        }
    }
}

impl AuditHealthState {
    pub fn record_success(&self) {
        let mut guard = self.last_error.lock().ok();
        if let Some(ref mut slot) = guard {
            **slot = None;
        }
    }

    pub fn record_failure(&self, message: impl Into<String>) {
        let mut guard = self.last_error.lock().ok();
        let Some(ref mut slot) = guard else {
            return;
        };
        **slot = Some(AuditHealthError {
            message: message.into(),
            occurred_at: chrono::Utc::now().to_rfc3339(),
        });
    }

    pub fn snapshot(&self) -> AuditHealthSnapshot {
        let guard = self.last_error.lock().ok();
        match guard.as_deref() {
            Some(Some(err)) => AuditHealthSnapshot {
                is_healthy: false,
                last_error: Some(err.message.clone()),
                last_error_at: Some(err.occurred_at.clone()),
            },
            _ => AuditHealthSnapshot::healthy(),
        }
    }
}

/// åŒæ­¥å‘½ä»¤è·å–å…¨å±€é”çš„é»˜è®¤è¶…æ—¶æ—¶é—´ï¼ˆ60 ç§’ï¼‰
pub(super) const SYNC_LOCK_TIMEOUT_SECS: u64 = 60;

fn refresh_schema_registry_from_dir(
    app_data_dir: &Path,
    registry_state: &Arc<RwLock<SchemaRegistry>>,
) -> Result<SchemaRegistry, String> {
    let latest_registry = super::init::get_current_schema_state(app_data_dir).map_err(|e| {
        tracing::error!(
            "[data_governance] åˆ·æ–° SchemaRegistry å¤±è´¥ ({}): {}",
            app_data_dir.display(),
            e
        );
        format!(
            "åˆ·æ–° SchemaRegistry å¤±è´¥ ({}): {}",
            sanitize_path_for_user(app_data_dir),
            e
        )
    })?;

    let mut guard = registry_state
        .write()
        .map_err(|e| format!("å†™å…¥ SchemaRegistry çŠ¶æ€å¤±è´¥: {}", e))?;
    *guard = latest_registry.clone();

    Ok(latest_registry)
}

fn refresh_schema_registry_from_live_state(
    app: &tauri::AppHandle,
    registry_state: &Arc<RwLock<SchemaRegistry>>,
) -> Result<SchemaRegistry, String> {
    let app_data_dir = get_live_app_data_dir(app)?;
    refresh_schema_registry_from_dir(&app_data_dir, registry_state)
}

#[derive(Debug, Clone, serde::Serialize)]
pub struct SlotMigrationTestResponse {
    pub success: bool,
    pub report: String,
}

fn slot_c_test_dir(app_data_dir: &Path) -> std::path::PathBuf {
    app_data_dir.parent().unwrap_or(app_data_dir).join("slotC")
}

fn slot_d_test_dir(app_data_dir: &Path) -> std::path::PathBuf {
    app_data_dir.parent().unwrap_or(app_data_dir).join("slotD")
}

fn run_slot_c_empty_db_test(app_data_dir: &Path) -> SlotMigrationTestResponse {
    use std::fmt::Write;

    let slot_c_dir = slot_c_test_dir(app_data_dir);
    let mut report = String::new();
    let mut success = false;

    if slot_c_dir.exists() {
        let _ = std::fs::remove_dir_all(&slot_c_dir);
    }
    let _ = std::fs::create_dir_all(&slot_c_dir);

    let mut coordinator = MigrationCoordinator::new(slot_c_dir.clone()).with_audit_db(None);

    match coordinator.run_all() {
        Ok(migration_report) => {
            success = true;
            let _ = writeln!(
                report,
                "ç»“æœ: æˆåŠŸ ({}ms)",
                migration_report.total_duration_ms
            );
            for db_report in &migration_report.databases {
                let _ = writeln!(
                    report,
                    "  [{}] v{} -> v{}, åº”ç”¨ {} ä¸ªè¿ç§», {}ms",
                    db_report.id.as_str(),
                    db_report.from_version,
                    db_report.to_version,
                    db_report.applied_count,
                    db_report.duration_ms
                );
            }
        }
        Err(e) => {
            let _ = writeln!(report, "ç»“æœ: å¤±è´¥!");
            let _ = writeln!(report, "  ROOT CAUSE: {}", e);
        }
    }

    let _ = std::fs::remove_dir_all(&slot_c_dir);
    let _ = std::fs::create_dir_all(&slot_c_dir);

    SlotMigrationTestResponse { success, report }
}

fn run_slot_d_clone_db_test(app_data_dir: &Path) -> SlotMigrationTestResponse {
    use std::fmt::Write;

    let slot_d_dir = slot_d_test_dir(app_data_dir);
    let mut report = String::new();
    let mut success = false;

    if slot_d_dir.exists() {
        let _ = std::fs::remove_dir_all(&slot_d_dir);
    }
    let _ = std::fs::create_dir_all(&slot_d_dir);

    // å¤åˆ¶å½“å‰æ´»è·ƒæ’æ§½çš„æ•°æ®åº“æ–‡ä»¶ï¼ˆåªå¤åˆ¶ .db å’Œ .db-walï¼Œä¸å¤åˆ¶å¤§æ–‡ä»¶ï¼‰
    let db_files: &[&str] = &[
        "chat_v2.db",
        "chat_v2.db-wal",
        "mistakes.db",
        "mistakes.db-wal",
        "llm_usage.db",
        "llm_usage.db-wal",
    ];
    let db_subdir_files: &[(&str, &str)] = &[("databases", "vfs.db"), ("databases", "vfs.db-wal")];

    let mut copy_errors: Vec<String> = Vec::new();

    for file_name in db_files {
        let src = app_data_dir.join(file_name);
        if src.exists() {
            let dst = slot_d_dir.join(file_name);
            if let Err(e) = std::fs::copy(&src, &dst) {
                copy_errors.push(format!("{}: {}", file_name, e));
            }
        }
    }

    for (subdir, file_name) in db_subdir_files {
        let src = app_data_dir.join(subdir).join(file_name);
        if src.exists() {
            let dst_dir = slot_d_dir.join(subdir);
            let _ = std::fs::create_dir_all(&dst_dir);
            let dst = dst_dir.join(file_name);
            if let Err(e) = std::fs::copy(&src, &dst) {
                copy_errors.push(format!("{}/{}: {}", subdir, file_name, e));
            }
        }
    }

    if !copy_errors.is_empty() {
        let _ = writeln!(report, "å¤åˆ¶æ–‡ä»¶æ—¶å‡ºé”™: {}", copy_errors.join("; "));
    }

    let mut coordinator = MigrationCoordinator::new(slot_d_dir.clone()).with_audit_db(None);

    match coordinator.run_all() {
        Ok(migration_report) => {
            success = true;
            let _ = writeln!(
                report,
                "ç»“æœ: æˆåŠŸ ({}ms)",
                migration_report.total_duration_ms
            );
            for db_report in &migration_report.databases {
                if db_report.applied_count > 0 {
                    let _ = writeln!(
                        report,
                        "  [{}] v{} -> v{}, åº”ç”¨ {} ä¸ªè¿ç§», {}ms",
                        db_report.id.as_str(),
                        db_report.from_version,
                        db_report.to_version,
                        db_report.applied_count,
                        db_report.duration_ms
                    );
                } else {
                    let _ = writeln!(
                        report,
                        "  [{}] v{} (å·²æ˜¯æœ€æ–°)",
                        db_report.id.as_str(),
                        db_report.to_version
                    );
                }
            }
        }
        Err(e) => {
            let _ = writeln!(report, "ç»“æœ: å¤±è´¥!");
            let _ = writeln!(report, "  ROOT CAUSE: {}", e);
        }
    }

    let _ = std::fs::remove_dir_all(&slot_d_dir);
    let _ = std::fs::create_dir_all(&slot_d_dir);

    SlotMigrationTestResponse { success, report }
}

#[cfg(feature = "data_governance")]
pub(super) fn try_save_audit_log(app: &tauri::AppHandle, log: AuditLog) {
    // å®¡è®¡å¤±è´¥ä¸åº”é˜»æ–­ä¸»æµç¨‹ï¼šè¿™é‡Œåªåš best-effort è®°å½•ï¼Œå¹¶å†™å…¥ tracing warnã€‚
    let audit_health = app.try_state::<Arc<AuditHealthState>>();
    let Some(audit_db) = app.try_state::<Arc<super::audit::AuditDatabase>>() else {
        if let Some(state) = audit_health {
            state.record_failure("å®¡è®¡æ•°æ®åº“æœªåˆå§‹åŒ–");
        }
        return;
    };

    let conn = match audit_db.get_conn() {
        Ok(c) => c,
        Err(e) => {
            tracing::warn!("[data_governance] è·å–å®¡è®¡æ•°æ®åº“è¿æ¥å¤±è´¥: {}", e);
            if let Some(state) = audit_health {
                state.record_failure(format!("è·å–å®¡è®¡æ•°æ®åº“è¿æ¥å¤±è´¥: {}", e));
            }
            return;
        }
    };

    if let Err(e) = AuditRepository::init(&conn) {
        tracing::warn!("[data_governance] åˆå§‹åŒ–å®¡è®¡è¡¨å¤±è´¥ï¼Œè·³è¿‡å®¡è®¡è®°å½•: {}", e);
        if let Some(state) = audit_health {
            state.record_failure(format!("åˆå§‹åŒ–å®¡è®¡è¡¨å¤±è´¥: {}", e));
        }
        return;
    }

    if let Err(e) = AuditRepository::save(&conn, &log) {
        tracing::warn!("[data_governance] å†™å…¥å®¡è®¡æ—¥å¿—å¤±è´¥: {}", e);
        if let Some(state) = audit_health {
            state.record_failure(format!("å†™å…¥å®¡è®¡æ—¥å¿—å¤±è´¥: {}", e));
        }
    } else if let Some(state) = audit_health {
        state.record_success();
    }
}

/// æŸ¥è¯¢å½“å‰æ˜¯å¦å¤„äºç»´æŠ¤æ¨¡å¼
///
/// å‰ç«¯åº”ç”¨å¯åŠ¨æ—¶è°ƒç”¨æ­¤å‘½ä»¤ï¼Œå°†åç«¯ç»´æŠ¤æ¨¡å¼çŠ¶æ€åŒæ­¥åˆ°å‰ç«¯ storeã€‚
/// ç”¨äºå¤„ç†åº”ç”¨åœ¨ç»´æŠ¤æ¨¡å¼ä¸­å´©æºƒåé‡å¯çš„åœºæ™¯ã€‚
#[tauri::command]
pub fn data_governance_get_maintenance_status(
    app: AppHandle,
) -> Result<MaintenanceStatusResponse, String> {
    let in_maintenance = if let Some(state) = app.try_state::<crate::commands::AppState>() {
        state.database.is_in_maintenance_mode()
    } else {
        false
    };

    Ok(MaintenanceStatusResponse {
        is_in_maintenance_mode: in_maintenance,
    })
}

/// è·å– Schema æ³¨å†Œè¡¨
///
/// è¿”å›æ‰€æœ‰æ•°æ®åº“çš„ç‰ˆæœ¬çŠ¶æ€å’Œè¿ç§»å†å²ã€‚
#[tauri::command]
pub fn data_governance_get_schema_registry(
    app: AppHandle,
    registry: State<'_, Arc<RwLock<SchemaRegistry>>>,
) -> Result<SchemaRegistryResponse, String> {
    let registry = refresh_schema_registry_from_live_state(&app, registry.inner())?;

    Ok(SchemaRegistryResponse {
        global_version: registry.global_version,
        aggregated_at: registry.aggregated_at.clone(),
        databases: registry
            .databases
            .iter()
            .map(|(id, status)| DatabaseStatusResponse {
                id: id.as_str().to_string(),
                schema_version: status.schema_version,
                min_compatible_version: status.min_compatible_version,
                max_compatible_version: status.max_compatible_version,
                data_contract_version: status.data_contract_version.clone(),
                migration_count: status.migration_history.len(),
                checksum: status.checksum.clone(),
                updated_at: status.updated_at.clone(),
            })
            .collect(),
    })
}

/// è·å–å®¡è®¡æ—¥å¿—
///
/// æ”¯æŒæŒ‰æ“ä½œç±»å‹ã€æ—¶é—´èŒƒå›´ã€çŠ¶æ€è¿‡æ»¤ï¼Œæ”¯æŒåˆ†é¡µã€‚
#[tauri::command]
pub fn data_governance_get_audit_logs(
    audit_db: State<'_, Arc<super::audit::AuditDatabase>>,
    operation_type: Option<String>,
    status: Option<String>,
    limit: Option<usize>,
    offset: Option<usize>,
) -> Result<AuditLogPagedResponse, String> {
    // ä»å®¡è®¡æ•°æ®åº“è·å–è¿æ¥
    let conn = audit_db
        .get_conn()
        .map_err(|e| format!("è·å–å®¡è®¡æ•°æ®åº“è¿æ¥å¤±è´¥: {}", e))?;

    let parsed_status = match status.as_deref() {
        Some("Started") => Some(AuditStatus::Started),
        Some("Completed") => Some(AuditStatus::Completed),
        Some("Failed") => Some(AuditStatus::Failed),
        Some("Partial") => Some(AuditStatus::Partial),
        Some(other) => {
            return Err(format!(
                "æ— æ•ˆçš„çŠ¶æ€è¿‡æ»¤å€¼: {}ã€‚å¯é€‰å€¼: Completed, Failed, Partial",
                other
            ))
        }
        None => None,
    };

    // æ„å»ºè¿‡æ»¤å™¨
    let filter = AuditFilter {
        operation_type,
        status: parsed_status,
        limit: Some(limit.unwrap_or(100)),
        offset,
        ..Default::default()
    };

    // åˆ†é¡µæŸ¥è¯¢å®¡è®¡æ—¥å¿—
    let result = AuditRepository::query_paged(&conn, filter)
        .map_err(|e| format!("æŸ¥è¯¢å®¡è®¡æ—¥å¿—å¤±è´¥: {}", e))?;

    Ok(AuditLogPagedResponse {
        logs: result
            .logs
            .into_iter()
            .map(AuditLogResponse::from)
            .collect(),
        total: result.total,
    })
}

/// æ¸…ç†å®¡è®¡æ—¥å¿—
///
/// æ”¯æŒä¸¤ç§æ¸…ç†ç­–ç•¥ï¼š
/// - `keep_recent`: ä¿ç•™æœ€è¿‘ N æ¡è®°å½•ï¼Œåˆ é™¤å…¶ä½™ï¼ˆæœ€å°‘ä¿ç•™ 100 æ¡ï¼‰
/// - `before_days`: åˆ é™¤ N å¤©ä¹‹å‰çš„è®°å½•ï¼ˆæœ€å°‘ä¿ç•™ 7 å¤©ï¼‰
///
/// ä¸¤ä¸ªå‚æ•°äº’æ–¥ï¼Œä¼˜å…ˆä½¿ç”¨ `keep_recent`ã€‚
/// å¦‚æœéƒ½æœªæŒ‡å®šï¼Œé»˜è®¤æ¸…ç† 90 å¤©ä¹‹å‰çš„è®°å½•ã€‚
///
/// ## å®‰å…¨æœºåˆ¶
///
/// - æœ€å°ä¿ç•™ä¸‹é™ï¼š`keep_recent` ä¸å¾—ä½äº 100 æ¡ï¼Œ`before_days` ä¸å¾—ä½äº 7 å¤©
/// - éœ€è¦ `confirmation_token` å‚æ•°ï¼Œæ ¼å¼ä¸º `AUDIT_CLEANUP_{unix_timestamp_secs}`ï¼Œ
///   ä¸”æ—¶é—´æˆ³å¿…é¡»åœ¨å½“å‰æ—¶é—´ 60 ç§’å†…ï¼Œé˜²æ­¢è¢«æ¶æ„è„šæœ¬é™é»˜è°ƒç”¨
/// - æ¯æ¬¡æ¸…ç†æ“ä½œæœ¬èº«ä¹Ÿä¼šè¢«è®°å½•åˆ°å®¡è®¡æ—¥å¿—ä¸­
///
/// ## è¿”å›
///
/// è¢«åˆ é™¤çš„è®°å½•æ•°é‡
#[tauri::command]
pub fn data_governance_cleanup_audit_logs(
    app: tauri::AppHandle,
    audit_db: State<'_, Arc<super::audit::AuditDatabase>>,
    keep_recent: Option<usize>,
    before_days: Option<u64>,
    confirmation_token: String,
) -> Result<u64, String> {
    // â”€â”€ å®‰å…¨éªŒè¯ï¼šç¡®è®¤ä»¤ç‰Œ â”€â”€
    const TOKEN_PREFIX: &str = "AUDIT_CLEANUP_";
    const TOKEN_VALIDITY_SECS: i64 = 60;

    if !confirmation_token.starts_with(TOKEN_PREFIX) {
        return Err("å®¡è®¡æ¸…ç†ä»¤ç‰Œæ ¼å¼æ— æ•ˆï¼Œéœ€è¦ AUDIT_CLEANUP_{unix_timestamp}".to_string());
    }
    let ts_str = &confirmation_token[TOKEN_PREFIX.len()..];
    let token_ts: i64 = ts_str
        .parse()
        .map_err(|_| "å®¡è®¡æ¸…ç†ä»¤ç‰Œä¸­çš„æ—¶é—´æˆ³æ— æ•ˆ".to_string())?;
    let now_ts = chrono::Utc::now().timestamp();
    let diff = (now_ts - token_ts).abs();
    if diff > TOKEN_VALIDITY_SECS {
        return Err(format!(
            "å®¡è®¡æ¸…ç†ä»¤ç‰Œå·²è¿‡æœŸï¼ˆå·®å€¼ {}sï¼Œå…è®¸ {}s å†…ï¼‰",
            diff, TOKEN_VALIDITY_SECS
        ));
    }

    // â”€â”€ å®‰å…¨éªŒè¯ï¼šæœ€å°ä¿ç•™ä¸‹é™ â”€â”€
    const MIN_KEEP_RECENT: usize = 100;
    const MIN_BEFORE_DAYS: u64 = 7;

    if let Some(keep) = keep_recent {
        if keep < MIN_KEEP_RECENT {
            return Err(format!(
                "keep_recent ä¸å¾—ä½äº {}ï¼Œå½“å‰å€¼: {}",
                MIN_KEEP_RECENT, keep
            ));
        }
    }
    if let Some(days) = before_days {
        if days < MIN_BEFORE_DAYS {
            return Err(format!(
                "before_days ä¸å¾—ä½äº {} å¤©ï¼Œå½“å‰å€¼: {}",
                MIN_BEFORE_DAYS, days
            ));
        }
    }

    let conn = audit_db
        .get_conn()
        .map_err(|e| format!("è·å–å®¡è®¡æ•°æ®åº“è¿æ¥å¤±è´¥: {}", e))?;

    // â”€â”€ æ¸…ç†å‰å…ˆè®°å½•å®¡è®¡æ—¥å¿— â”€â”€
    #[cfg(feature = "data_governance")]
    {
        try_save_audit_log(
            &app,
            AuditLog::new(
                AuditOperation::Maintenance {
                    action: "cleanup_audit_logs".to_string(),
                },
                "cleanup_audit_logs_initiated".to_string(),
            )
            .with_details(serde_json::json!({
                "keep_recent": keep_recent,
                "before_days": before_days,
                "confirmation_token_ts": token_ts,
            }))
            .complete(0),
        );
    }

    // é»˜è®¤ä¿ç•™ 90 å¤©
    const DEFAULT_MAX_AGE_DAYS: u32 = 90;

    let deleted = if let Some(keep) = keep_recent {
        AuditRepository::cleanup_keep_recent(&conn, keep).map_err(|e| {
            #[cfg(feature = "data_governance")]
            {
                try_save_audit_log(
                    &app,
                    AuditLog::new(
                        AuditOperation::Maintenance {
                            action: "cleanup_audit_logs".to_string(),
                        },
                        "cleanup_audit_logs".to_string(),
                    )
                    .fail(e.to_string()),
                );
            }
            format!("æ¸…ç†å®¡è®¡æ—¥å¿—å¤±è´¥: {}", e)
        })?
    } else {
        let days = before_days.unwrap_or(DEFAULT_MAX_AGE_DAYS as u64);
        AuditRepository::cleanup_old_entries(&conn, days as u32).map_err(|e| {
            #[cfg(feature = "data_governance")]
            {
                try_save_audit_log(
                    &app,
                    AuditLog::new(
                        AuditOperation::Maintenance {
                            action: "cleanup_audit_logs".to_string(),
                        },
                        "cleanup_audit_logs".to_string(),
                    )
                    .fail(e.to_string()),
                );
            }
            format!("æ¸…ç†å®¡è®¡æ—¥å¿—å¤±è´¥: {}", e)
        })?
    };

    tracing::info!(deleted = deleted, "å®¡è®¡æ—¥å¿—æ¸…ç†å®Œæˆ");

    #[cfg(feature = "data_governance")]
    {
        try_save_audit_log(
            &app,
            AuditLog::new(
                AuditOperation::Maintenance {
                    action: "cleanup_audit_logs".to_string(),
                },
                "cleanup_audit_logs".to_string(),
            )
            .with_details(serde_json::json!({
                "deleted_count": deleted,
                "keep_recent": keep_recent,
                "before_days": before_days,
            }))
            .complete(0),
        );
    }

    Ok(deleted)
}

/// è·å–è¿ç§»çŠ¶æ€æ‘˜è¦
///
/// è¿”å›å„æ•°æ®åº“çš„å½“å‰ç‰ˆæœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬å¾…æ‰§è¡Œè¿ç§»æ•°é‡ã€‚
#[tauri::command]
pub fn data_governance_get_migration_status(
    app_handle: AppHandle,
    registry: State<'_, Arc<RwLock<SchemaRegistry>>>,
) -> Result<MigrationStatusResponse, String> {
    use tracing::{debug, warn};

    let registry = refresh_schema_registry_from_live_state(&app_handle, registry.inner())?;

    let mut pending_total = 0;
    let mut last_error: Option<String> = None;

    let databases: Vec<_> = DatabaseId::all_ordered()
        .into_iter()
        .map(|id| {
            let status = registry.get_status(&id);
            let current_version = status.map(|s| s.schema_version).unwrap_or(0);
            let (target_version, pending_count) =
                resolve_target_and_pending(&id, current_version, status);
            pending_total += pending_count;

            // æ£€æµ‹è¿ç§»å¤±è´¥ï¼šæ•°æ®åº“å·²åˆå§‹åŒ–ä½†æœ‰å¾…æ‰§è¡Œè¿ç§»
            if pending_count > 0 && current_version > 0 {
                let msg = format!(
                    "{} æœ‰ {} ä¸ªè¿ç§»æœªæ‰§è¡Œ (å½“å‰: v{}, ç›®æ ‡: v{})",
                    id.as_str(),
                    pending_count,
                    current_version,
                    target_version
                );
                warn!("âš ï¸ [MigrationStatus] {}", msg);
                if last_error.is_none() {
                    last_error = Some(msg);
                }
            }

            MigrationDatabaseStatus {
                id: id.as_str().to_string(),
                current_version,
                target_version,
                is_initialized: current_version > 0,
                last_migration_at: status.and_then(|s| {
                    if s.updated_at.is_empty() {
                        None
                    } else {
                        Some(s.updated_at.clone())
                    }
                }),
                pending_count,
                has_pending: pending_count > 0,
            }
        })
        .collect();

    let all_healthy = databases.iter().all(|d| d.is_initialized && !d.has_pending);

    // ä¼˜å…ˆä½¿ç”¨æŒä¹…åŒ–çš„çœŸå®è¿ç§»é”™è¯¯ï¼ˆæ¥è‡ªå®é™… SQL æ‰§è¡Œå¤±è´¥ï¼‰ï¼Œ
    // è€Œéä»…é ç‰ˆæœ¬å·æ¯”è¾ƒç”Ÿæˆçš„"æœ‰Nä¸ªè¿ç§»æœªæ‰§è¡Œ"ä¼ªä¿¡æ¯
    if pending_total > 0 {
        if let Ok(app_data_dir) = get_live_app_data_dir(&app_handle) {
            if let Some((real_error, _ts)) = read_persisted_migration_error(&app_data_dir) {
                last_error = Some(real_error);
            }
        }
    }

    debug!(
        "ğŸ“Š [MigrationStatus] å…¨å±€ç‰ˆæœ¬={}, å¥åº·={}, å¾…æ‰§è¡Œè¿ç§»æ€»æ•°={}",
        registry.global_version, all_healthy, pending_total
    );

    Ok(MigrationStatusResponse {
        global_version: registry.global_version,
        all_healthy,
        databases,
        pending_migrations_total: pending_total,
        has_pending_migrations: pending_total > 0,
        last_error,
    })
}

/// è¿è¡Œå¥åº·æ£€æŸ¥
///
/// æ£€æŸ¥æ‰€æœ‰æ•°æ®åº“çš„å®Œæ•´æ€§å’Œä¾èµ–å…³ç³»ï¼ŒåŒ…æ‹¬å¾…æ‰§è¡Œè¿ç§»æ£€æµ‹ã€‚
#[tauri::command]
pub fn data_governance_run_health_check(
    app: AppHandle,
    registry: State<'_, Arc<RwLock<SchemaRegistry>>>,
) -> Result<HealthCheckResponse, String> {
    use tracing::{info, warn};

    info!("ğŸ” [HealthCheck] å¼€å§‹è¿è¡Œå¥åº·æ£€æŸ¥...");
    let registry = refresh_schema_registry_from_live_state(&app, registry.inner())?;

    // æ£€æŸ¥ä¾èµ–å…³ç³»
    let dependency_check = registry.check_dependencies();
    let dependency_ok = dependency_check.is_ok();
    let dependency_error = dependency_check.err().map(|e| e.to_string());

    if let Some(ref err) = dependency_error {
        warn!("âš ï¸ [HealthCheck] ä¾èµ–å…³ç³»æ£€æŸ¥å¤±è´¥: {}", err);
    }

    // ç»Ÿè®¡å„çŠ¶æ€æ•°æ®åº“æ•°é‡
    let total_databases = DatabaseId::all_ordered().len();
    let initialized_count = registry
        .databases
        .values()
        .filter(|s| s.schema_version > 0)
        .count();
    let uninitialized_count = total_databases - initialized_count;

    info!(
        "ğŸ“Š [HealthCheck] æ•°æ®åº“ç»Ÿè®¡: æ€»æ•°={}, å·²åˆå§‹åŒ–={}, æœªåˆå§‹åŒ–={}",
        total_databases, initialized_count, uninitialized_count
    );

    let mut pending_migrations_total = 0;

    // æ„å»ºæ¯ä¸ªæ•°æ®åº“çš„å¥åº·çŠ¶æ€
    let database_health: Vec<_> = DatabaseId::all_ordered()
        .into_iter()
        .map(|id| {
            let status = registry.get_status(&id);
            let schema_version = status.map(|s| s.schema_version).unwrap_or(0);
            let (target_version, pending_count) =
                resolve_target_and_pending(&id, schema_version, status);
            let is_initialized = schema_version > 0;
            pending_migrations_total += pending_count;

            // æ£€æŸ¥ä¾èµ–æ˜¯å¦æ»¡è¶³
            let dependencies_met = id.dependencies().iter().all(|dep| {
                registry
                    .get_status(dep)
                    .map(|s| s.schema_version > 0)
                    .unwrap_or(false)
            });

            // æ”¶é›†æ‰€æœ‰é—®é¢˜
            let mut issues = Vec::new();
            if !is_initialized {
                issues.push("æ•°æ®åº“æœªåˆå§‹åŒ–".to_string());
            }
            if !dependencies_met {
                issues.push("ä¾èµ–æ•°æ®åº“æœªå°±ç»ª".to_string());
            }
            if pending_count > 0 {
                issues.push(format!(
                    "æœ‰ {} ä¸ªè¿ç§»å¾…æ‰§è¡Œ (å½“å‰: v{}, ç›®æ ‡: v{})",
                    pending_count, schema_version, target_version
                ));
            }

            // å¥åº·çŠ¶æ€ï¼šå·²åˆå§‹åŒ– + æ— å¾…æ‰§è¡Œè¿ç§» + ä¾èµ–æ»¡è¶³
            let is_healthy = is_initialized && pending_count == 0 && dependencies_met;

            // è¾“å‡ºæ¯ä¸ªæ•°æ®åº“çš„è¯¦ç»†çŠ¶æ€
            if is_healthy {
                info!(
                    "  âœ… [HealthCheck] {}: v{}, å¥åº·",
                    id.as_str(),
                    schema_version
                );
            } else {
                warn!(
                    "  âš ï¸ [HealthCheck] {}: v{} -> v{}, é—®é¢˜: {:?}",
                    id.as_str(),
                    schema_version,
                    target_version,
                    issues
                );
            }

            DatabaseHealthStatus {
                id: id.as_str().to_string(),
                is_healthy,
                dependencies_met,
                schema_version,
                target_version,
                pending_count,
                issues,
            }
        })
        .collect();

    // æ•´ä½“å¥åº·ï¼šä¾èµ–é€šè¿‡ + æ— æœªåˆå§‹åŒ–æ•°æ®åº“ + æ— å¾…æ‰§è¡Œè¿ç§»
    let overall_healthy =
        dependency_ok && uninitialized_count == 0 && pending_migrations_total == 0;

    if overall_healthy {
        info!("âœ… [HealthCheck] å¥åº·æ£€æŸ¥å®Œæˆ: æ‰€æœ‰æ•°æ®åº“çŠ¶æ€æ­£å¸¸");
    } else {
        warn!(
            "âš ï¸ [HealthCheck] å¥åº·æ£€æŸ¥å®Œæˆ: å‘ç°é—®é¢˜ (æœªåˆå§‹åŒ–: {}, ä¾èµ–æ£€æŸ¥: {}, å¾…æ‰§è¡Œè¿ç§»: {})",
            uninitialized_count,
            if dependency_ok { "é€šè¿‡" } else { "å¤±è´¥" },
            pending_migrations_total
        );
    }

    let audit_snapshot = app
        .try_state::<Arc<AuditHealthState>>()
        .map(|state| state.snapshot())
        .unwrap_or_else(AuditHealthSnapshot::healthy);

    Ok(HealthCheckResponse {
        overall_healthy,
        total_databases,
        initialized_count,
        uninitialized_count,
        dependency_check_passed: dependency_ok,
        dependency_error,
        databases: database_health,
        checked_at: chrono::Utc::now().to_rfc3339(),
        pending_migrations_count: pending_migrations_total,
        has_pending_migrations: pending_migrations_total > 0,
        audit_log_healthy: audit_snapshot.is_healthy,
        audit_log_error: audit_snapshot.last_error,
        audit_log_error_at: audit_snapshot.last_error_at,
    })
}

/// è·å–ç‰¹å®šæ•°æ®åº“çš„è¯¦ç»†çŠ¶æ€
#[tauri::command]
pub fn data_governance_get_database_status(
    app: AppHandle,
    registry: State<'_, Arc<RwLock<SchemaRegistry>>>,
    database_id: String,
) -> Result<Option<DatabaseDetailResponse>, String> {
    let registry = refresh_schema_registry_from_live_state(&app, registry.inner())?;

    let db_id = match database_id.as_str() {
        "vfs" => DatabaseId::Vfs,
        "chat_v2" => DatabaseId::ChatV2,
        "mistakes" => DatabaseId::Mistakes,
        "llm_usage" => DatabaseId::LlmUsage,
        _ => {
            return Err(format!(
                "æœªçŸ¥çš„æ•°æ®åº“ ID: {}ã€‚å¯é€‰å€¼: vfs, chat_v2, mistakes, llm_usage",
                database_id
            ))
        }
    };

    Ok(registry
        .get_status(&db_id)
        .map(|status| DatabaseDetailResponse {
            id: db_id.as_str().to_string(),
            schema_version: status.schema_version,
            min_compatible_version: status.min_compatible_version,
            max_compatible_version: status.max_compatible_version,
            data_contract_version: status.data_contract_version.clone(),
            checksum: status.checksum.clone(),
            updated_at: status.updated_at.clone(),
            migration_history: status
                .migration_history
                .iter()
                .map(|m| MigrationRecordResponse {
                    version: m.version,
                    name: m.name.clone(),
                    checksum: m.checksum.clone(),
                    applied_at: m.applied_at.clone(),
                    duration_ms: m.duration_ms,
                    success: m.success,
                })
                .collect(),
            dependencies: db_id
                .dependencies()
                .iter()
                .map(|d| d.as_str().to_string())
                .collect(),
        }))
}

/// ç”Ÿæˆè¿ç§»è¯Šæ–­æŠ¥å‘Š
///
/// æ”¶é›†æ‰€æœ‰æ•°æ®åº“çš„è¿ç§»çŠ¶æ€ã€é”™è¯¯ä¿¡æ¯ã€è¿ç§»å†å²ã€ç£ç›˜ç©ºé—´ç­‰ä¿¡æ¯ï¼Œ
/// è¿”å›æ ¼å¼åŒ–çš„çº¯æ–‡æœ¬æŠ¥å‘Šï¼Œç”¨äºç”¨æˆ·ä¸€é”®å¤åˆ¶ç»™å¼€å‘è€…ã€‚
#[tauri::command]
pub fn data_governance_get_migration_diagnostic_report(
    app_handle: AppHandle,
    registry: State<'_, Arc<RwLock<SchemaRegistry>>>,
) -> Result<String, String> {
    use std::fmt::Write;

    let app_data_dir = get_live_app_data_dir(&app_handle)?;
    let registry = refresh_schema_registry_from_live_state(&app_handle, registry.inner())?;

    let mut report = String::with_capacity(4096);

    // --- å¤´éƒ¨ ---
    let _ = writeln!(report, "=== Deep Student è¿ç§»è¯Šæ–­æŠ¥å‘Š ===");
    let _ = writeln!(report, "æ—¶é—´: {}", chrono::Utc::now().to_rfc3339());
    let _ = writeln!(
        report,
        "å¹³å°: {} {}",
        std::env::consts::OS,
        std::env::consts::ARCH
    );
    let _ = writeln!(report, "åº”ç”¨ç‰ˆæœ¬: {}", env!("CARGO_PKG_VERSION"));
    let _ = writeln!(report);

    // --- æ•°æ®åº“çŠ¶æ€ ---
    let _ = writeln!(report, "--- æ•°æ®åº“çŠ¶æ€ ---");
    let mut error_messages: Vec<String> = Vec::new();

    for id in DatabaseId::all_ordered() {
        let status = registry.get_status(&id);
        let current_version = status.map(|s| s.schema_version).unwrap_or(0);
        let (target_version, pending_count) =
            resolve_target_and_pending(&id, current_version, status);

        let flag = if pending_count > 0 && current_version > 0 {
            error_messages.push(format!(
                "{}: æœ‰ {} ä¸ªè¿ç§»æœªæ‰§è¡Œ (å½“å‰: v{}, ç›®æ ‡: v{})",
                id.as_str(),
                pending_count,
                current_version,
                target_version
            ));
            " âš ï¸"
        } else {
            ""
        };

        let _ = writeln!(
            report,
            "[{}] å½“å‰: v{}, ç›®æ ‡: v{}, å¾…æ‰§è¡Œ: {}{}",
            id.as_str(),
            current_version,
            target_version,
            pending_count,
            flag
        );
    }
    let _ = writeln!(report);

    // --- é”™è¯¯ä¿¡æ¯ï¼ˆå®æ—¶è¯Šæ–­ï¼‰ ---
    let _ = writeln!(report, "--- é”™è¯¯ä¿¡æ¯ ---");

    // ä¼˜å…ˆæ˜¾ç¤ºæŒä¹…åŒ–çš„çœŸå®è¿ç§»é”™è¯¯ï¼ˆæ¥è‡ªå®é™… SQL æ‰§è¡Œå¤±è´¥ï¼‰
    if let Some((real_error, error_ts)) = read_persisted_migration_error(&app_data_dir) {
        let _ = writeln!(report, "[{}] çœŸå®è¿ç§»é”™è¯¯: {}", error_ts, real_error);
    }

    if error_messages.is_empty() && read_persisted_migration_error(&app_data_dir).is_none() {
        let _ = writeln!(report, "(æ— )");
    } else {
        for msg in &error_messages {
            let _ = writeln!(report, "{}", msg);
        }
    }
    let _ = writeln!(report);

    // --- å®¡è®¡æ—¥å¿—ä¸­çš„è¿ç§»å¤±è´¥è®°å½• ---
    let _ = writeln!(report, "--- æœ€è¿‘è¿ç§»å¤±è´¥è®°å½•ï¼ˆå®¡è®¡æ—¥å¿—ï¼‰ ---");
    {
        let audit_db_path = app_data_dir.join("databases").join("audit.db");
        if audit_db_path.exists() {
            match rusqlite::Connection::open(&audit_db_path) {
                Ok(conn) => {
                    // ç›´æ¥æŸ¥æœ€è¿‘ 5 æ¡å¤±è´¥çš„è¿ç§»å®¡è®¡è®°å½•
                    let sql = "SELECT timestamp, target, error_message, details \
                               FROM __audit_log \
                               WHERE operation_type = 'migration' AND status = 'failed' \
                               ORDER BY timestamp DESC LIMIT 5";
                    match conn.prepare(sql) {
                        Ok(mut stmt) => {
                            let mut found = false;
                            if let Ok(rows) = stmt.query_map([], |row| {
                                Ok((
                                    row.get::<_, String>(0).unwrap_or_default(),
                                    row.get::<_, String>(1).unwrap_or_default(),
                                    row.get::<_, Option<String>>(2).unwrap_or(None),
                                    row.get::<_, Option<String>>(3).unwrap_or(None),
                                ))
                            }) {
                                for row in rows.flatten() {
                                    found = true;
                                    let (ts, target, err, details) = row;
                                    let _ = writeln!(report, "[{}] db={}", ts, target);
                                    if let Some(err) = err {
                                        let _ = writeln!(report, "  error: {}", err);
                                    }
                                    if let Some(details) = details {
                                        // æˆªå–å‰ 500 å­—ç¬¦ï¼Œé¿å…è¿‡é•¿
                                        let truncated = if details.chars().count() > 500 {
                                            format!(
                                                "{}...(truncated)",
                                                safe_truncate_chars(&details, 500)
                                            )
                                        } else {
                                            details
                                        };
                                        let _ = writeln!(report, "  details: {}", truncated);
                                    }
                                }
                            }
                            if !found {
                                let _ = writeln!(report, "(å®¡è®¡æ—¥å¿—ä¸­æ— è¿ç§»å¤±è´¥è®°å½•)");
                            }
                        }
                        Err(e) => {
                            let _ = writeln!(report, "(æŸ¥è¯¢å®¡è®¡æ—¥å¿—å¤±è´¥: {})", e);
                        }
                    }
                }
                Err(e) => {
                    let _ = writeln!(report, "(æ— æ³•æ‰“å¼€å®¡è®¡æ•°æ®åº“: {})", e);
                }
            }
        } else {
            let _ = writeln!(report, "(å®¡è®¡æ•°æ®åº“ä¸å­˜åœ¨)");
        }
    }
    let _ = writeln!(report);

    // --- æµ‹è¯•æ’æ§½è¿ç§»å¤ç°ï¼ˆå®‰å…¨æ²™ç®±ï¼‰ ---
    // ä½¿ç”¨æµ‹è¯•æ’æ§½ C/D åœ¨éš”ç¦»ç¯å¢ƒä¸­å¤ç°è¿ç§»é”™è¯¯ï¼Œä¸å½±å“ç”Ÿäº§æ•°æ®
    let _ = writeln!(report, "--- ç©ºåº“è¿ç§»æµ‹è¯• (Slot C) ---");
    {
        let result = run_slot_c_empty_db_test(&app_data_dir);
        let _ = write!(report, "{}", result.report);
    }
    let _ = writeln!(report);

    let _ = writeln!(report, "--- å½“å‰åº“é‡è¯•è¿ç§»æµ‹è¯• (Slot D) ---");
    let _ = writeln!(
        report,
        "(å¤åˆ¶å½“å‰æ´»è·ƒæ’æ§½çš„æ•°æ®åº“ï¼Œé‡æ–°æ‰§è¡Œè¿ç§»æµç¨‹ï¼›è‹¥æˆåŠŸè¯´æ˜é‡å¯å¯æ¢å¤)"
    );
    {
        let result = run_slot_d_clone_db_test(&app_data_dir);
        let _ = write!(report, "{}", result.report);
    }
    let _ = writeln!(report);

    // --- è¿ç§»å†å² ---
    let _ = writeln!(report, "--- è¿ç§»å†å² ---");
    for id in DatabaseId::all_ordered() {
        let status = registry.get_status(&id);
        if let Some(status) = status {
            let history_str: String = status
                .migration_history
                .iter()
                .map(|m| format!("v{}({})", m.version, m.name))
                .collect::<Vec<_>>()
                .join(" ");
            let _ = writeln!(
                report,
                "[{}] {}",
                id.as_str(),
                if history_str.is_empty() {
                    "(æ— è®°å½•)".to_string()
                } else {
                    history_str
                }
            );
        } else {
            let _ = writeln!(report, "[{}] (æ•°æ®åº“æœªåˆå§‹åŒ–)", id.as_str());
        }
    }
    let _ = writeln!(report);

    // --- ç£ç›˜ç©ºé—´ ---
    let _ = writeln!(report, "--- ç£ç›˜ç©ºé—´ ---");
    let available = crate::backup_common::get_available_disk_space(&app_data_dir).unwrap_or(0);
    let mut total_db_size: u64 = 0;
    for db_id in DatabaseId::all_ordered() {
        let db_path = match db_id {
            DatabaseId::Vfs => app_data_dir.join("databases").join("vfs.db"),
            DatabaseId::ChatV2 => app_data_dir.join("chat_v2.db"),
            DatabaseId::Mistakes => app_data_dir.join("mistakes.db"),
            DatabaseId::LlmUsage => app_data_dir.join("llm_usage.db"),
        };
        if db_path.exists() {
            if let Ok(meta) = std::fs::metadata(&db_path) {
                total_db_size += meta.len();
            }
        }
    }
    let _ = writeln!(
        report,
        "å¯ç”¨: {}MB, æ•°æ®åº“æ€»å¤§å°: {}MB",
        available / (1024 * 1024),
        total_db_size / (1024 * 1024)
    );
    let _ = writeln!(report);

    // --- æ•°æ®ç›®å½• ---
    let _ = writeln!(report, "--- æ•°æ®ç›®å½• ---");
    let _ = writeln!(report, "{}", app_data_dir.display());

    Ok(report)
}

/// è¿è¡Œ Slot C ç©ºåº“è¿ç§»æµ‹è¯•ï¼ˆæµ‹è¯•æ’æ§½ï¼Œä¸å½±å“å½“å‰æ•°æ®ï¼‰
#[tauri::command]
pub fn data_governance_run_slot_c_empty_db_test(
    app_handle: AppHandle,
) -> Result<SlotMigrationTestResponse, String> {
    let app_data_dir = get_live_app_data_dir(&app_handle)?;
    Ok(run_slot_c_empty_db_test(&app_data_dir))
}

/// è¿è¡Œ Slot D å…‹éš†åº“è¿ç§»æµ‹è¯•ï¼ˆæµ‹è¯•æ’æ§½ï¼Œä¸å½±å“å½“å‰æ•°æ®ï¼‰
#[tauri::command]
pub fn data_governance_run_slot_d_clone_db_test(
    app_handle: AppHandle,
) -> Result<SlotMigrationTestResponse, String> {
    let app_data_dir = get_live_app_data_dir(&app_handle)?;
    Ok(run_slot_d_clone_db_test(&app_data_dir))
}

#[cfg(test)]
mod tests {
    use super::{refresh_schema_registry_from_dir, resolve_target_and_pending};
    use crate::data_governance::commands_backup::{validate_backup_id, infer_database_from_table};
    use crate::data_governance::schema_registry::{DatabaseId, DatabaseStatus, SchemaRegistry};
    use std::sync::{Arc, RwLock};
    use tempfile::TempDir;

    fn create_refinery_history_with_version(db_path: &std::path::Path, version: i32) {
        let conn = rusqlite::Connection::open(db_path).unwrap();
        conn.execute(
            "CREATE TABLE IF NOT EXISTS refinery_schema_history (
                version INTEGER PRIMARY KEY,
                name TEXT,
                applied_on TEXT,
                checksum TEXT
            )",
            [],
        )
        .unwrap();
        conn.execute(
            "INSERT OR REPLACE INTO refinery_schema_history(version, name, applied_on, checksum)
             VALUES (?1, ?2, ?3, ?4)",
            rusqlite::params![
                version,
                format!("V{}_test", version),
                "2026-02-07T00:00:00Z",
                "abc"
            ],
        )
        .unwrap();
    }

    #[test]
    fn resolve_target_and_pending_uses_migration_set_when_status_missing() {
        // Mistakes è¿ç§»é›†ï¼šV20260130, V20260131, V20260201, V20260207, V20260208, V20260209
        // ä» V20260130 å¼€å§‹ï¼Œpending = 5ï¼ˆåç»­ 5 ä¸ªè¿ç§»ï¼‰
        let (target_version, pending_count) =
            resolve_target_and_pending(&DatabaseId::Mistakes, 20260130, None);

        let expected_latest = super::super::migration::MISTAKES_MIGRATIONS.latest_version() as u32;
        let expected_pending = super::super::migration::MISTAKES_MIGRATIONS
            .pending(20260130)
            .count();

        assert_eq!(target_version, expected_latest);
        assert_eq!(pending_count, expected_pending);
    }

    #[test]
    fn resolve_target_and_pending_returns_zero_when_latest_reached() {
        let latest = super::super::migration::MISTAKES_MIGRATIONS.latest_version() as u32;
        let (target_version, pending_count) =
            resolve_target_and_pending(&DatabaseId::Mistakes, latest, None);

        assert_eq!(target_version, latest);
        assert_eq!(pending_count, 0);
    }

    #[test]
    fn resolve_target_and_pending_prefers_status_target_version() {
        let status = DatabaseStatus {
            id: DatabaseId::Mistakes,
            schema_version: 20260130,
            min_compatible_version: 1,
            max_compatible_version: 20260299,
            data_contract_version: "1.0.0".to_string(),
            migration_history: Vec::new(),
            checksum: String::new(),
            updated_at: String::new(),
        };

        let (target_version, pending_count) =
            resolve_target_and_pending(&DatabaseId::Mistakes, 20260130, Some(&status));

        let expected_pending = super::super::migration::MISTAKES_MIGRATIONS
            .pending(20260130)
            .count();

        assert_eq!(target_version, 20260299);
        assert_eq!(pending_count, expected_pending);
    }

    #[test]
    fn validate_backup_id_allows_safe_id() {
        let result = validate_backup_id("backup-20260206_120000");
        assert_eq!(result.unwrap(), "backup-20260206_120000");
    }

    #[test]
    fn validate_backup_id_rejects_parent_traversal() {
        let result = validate_backup_id("../escape");
        assert!(result.is_err());
    }

    #[test]
    fn validate_backup_id_rejects_absolute_path() {
        let result = validate_backup_id("/tmp/escape");
        assert!(result.is_err());
    }

    #[test]
    fn validate_backup_id_rejects_encoded_bypass() {
        let result = validate_backup_id("%2e%2e%2fescape");
        assert!(result.is_err());
    }

    #[test]
    fn refresh_schema_registry_from_dir_swaps_latest_live_state() {
        let temp_dir = TempDir::new().unwrap();
        let app_data_dir = temp_dir.path();
        std::fs::create_dir_all(app_data_dir.join("databases")).unwrap();

        let vfs_db = app_data_dir.join("databases").join("vfs.db");
        create_refinery_history_with_version(&vfs_db, 1);

        let registry_state = Arc::new(RwLock::new(SchemaRegistry::default()));
        let first = refresh_schema_registry_from_dir(app_data_dir, &registry_state).unwrap();
        assert_eq!(
            first.get_status(&DatabaseId::Vfs).map(|s| s.schema_version),
            Some(1)
        );

        create_refinery_history_with_version(&vfs_db, 2);

        let second = refresh_schema_registry_from_dir(app_data_dir, &registry_state).unwrap();
        assert_eq!(
            second
                .get_status(&DatabaseId::Vfs)
                .map(|s| s.schema_version),
            Some(2)
        );

        let guard = registry_state.read().unwrap();
        assert_eq!(
            guard.get_status(&DatabaseId::Vfs).map(|s| s.schema_version),
            Some(2)
        );
    }

    #[test]
    fn refresh_schema_registry_from_dir_maps_poisoned_lock_error() {
        let temp_dir = TempDir::new().unwrap();
        let app_data_dir = temp_dir.path();
        std::fs::create_dir_all(app_data_dir.join("databases")).unwrap();

        let registry_state = Arc::new(RwLock::new(SchemaRegistry::default()));
        let poison_target = registry_state.clone();
        let _ = std::panic::catch_unwind(move || {
            let _guard = poison_target.write().unwrap();
            panic!("poison registry lock");
        });

        let err = refresh_schema_registry_from_dir(app_data_dir, &registry_state).unwrap_err();
        assert!(err.contains("å†™å…¥ SchemaRegistry çŠ¶æ€å¤±è´¥"));
    }

    // ========================================================================
    // infer_database_from_table æµ‹è¯•
    // ========================================================================

    #[test]
    fn test_infer_database_chat_v2_prefix() {
        assert_eq!(
            infer_database_from_table("chat_v2_sessions"),
            Some("chat_v2")
        );
        assert_eq!(
            infer_database_from_table("chat_v2_messages"),
            Some("chat_v2")
        );
        assert_eq!(
            infer_database_from_table("chat_v2_blocks"),
            Some("chat_v2")
        );
    }

    #[test]
    fn test_infer_database_chat_v2_known_tables() {
        assert_eq!(
            infer_database_from_table("workspace_index"),
            Some("chat_v2")
        );
        assert_eq!(
            infer_database_from_table("sleep_block"),
            Some("chat_v2")
        );
        assert_eq!(
            infer_database_from_table("subagent_task"),
            Some("chat_v2")
        );
    }

    #[test]
    fn test_infer_database_resources_ambiguous_returns_none() {
        // resources è¡¨åŒæ—¶å­˜åœ¨äº chat_v2 å’Œ vfsï¼Œlegacy å˜æ›´æ— æ³•åˆ¤å®šï¼Œåº”è·³è¿‡
        assert_eq!(infer_database_from_table("resources"), None);
    }

    #[test]
    fn test_infer_database_mistakes() {
        assert_eq!(
            infer_database_from_table("mistakes"),
            Some("mistakes")
        );
        assert_eq!(
            infer_database_from_table("anki_cards"),
            Some("mistakes")
        );
        assert_eq!(
            infer_database_from_table("document_tasks"),
            Some("mistakes")
        );
        assert_eq!(
            infer_database_from_table("settings"),
            Some("mistakes")
        );
        assert_eq!(
            infer_database_from_table("review_analyses"),
            Some("mistakes")
        );
        assert_eq!(
            infer_database_from_table("exam_sheet_sessions"),
            Some("mistakes")
        );
    }

    #[test]
    fn test_infer_database_vfs() {
        assert_eq!(infer_database_from_table("notes"), Some("vfs"));
        assert_eq!(infer_database_from_table("files"), Some("vfs"));
        assert_eq!(infer_database_from_table("folders"), Some("vfs"));
        assert_eq!(infer_database_from_table("blobs"), Some("vfs"));
        assert_eq!(infer_database_from_table("questions"), Some("vfs"));
        assert_eq!(infer_database_from_table("mindmaps"), Some("vfs"));
        assert_eq!(infer_database_from_table("essays"), Some("vfs"));
    }

    #[test]
    fn test_infer_database_llm_usage() {
        assert_eq!(
            infer_database_from_table("llm_usage_logs"),
            Some("llm_usage")
        );
        assert_eq!(
            infer_database_from_table("llm_usage_daily"),
            Some("llm_usage")
        );
    }

    #[test]
    fn test_infer_database_unknown_returns_none() {
        assert_eq!(infer_database_from_table("unknown_table_xyz"), None);
        assert_eq!(infer_database_from_table("__change_log"), None);
    }

    #[test]
    fn test_infer_database_no_cross_routing() {
        // ç¡®ä¿ mistakes è¡¨ä¸ä¼šè¢«è·¯ç”±åˆ° chat_v2
        assert_ne!(
            infer_database_from_table("anki_cards"),
            Some("chat_v2")
        );
        // ç¡®ä¿ vfs è¡¨ä¸ä¼šè¢«è·¯ç”±åˆ° mistakes
        assert_ne!(infer_database_from_table("notes"), Some("mistakes"));
    }
}
