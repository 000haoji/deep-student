/**
 * Chat V2 - å¯ç”¨æ¨¡å‹åˆ—è¡¨ Hook
 *
 * è·å–ç³»ç»Ÿé…ç½®çš„æ¨¡å‹åˆ—è¡¨ï¼Œç”¨äº @æ¨¡å‹ è§£æå’Œå¤šå˜ä½“æ”¯æŒã€‚
 */

import { useState, useEffect, useMemo, useCallback } from 'react';
import { invoke } from '@tauri-apps/api/core';
import type { ModelInfo } from '../utils/parseModelMentions';

// ============================================================================
// ç±»å‹
// ============================================================================

/**
 * æ¨¡å‹é…ç½®æ¥å£ï¼ˆä¸åç«¯ ApiConfig å¯¹åº”ï¼‰
 * ğŸ”§ æ‰©å±•ï¼šæ·»åŠ æ¨¡å‹èƒ½åŠ›å­—æ®µï¼Œä¾¿äºå‰ç«¯æ ¹æ®æ¨¡å‹èƒ½åŠ›æ˜¾ç¤ºä¸åŒ UI
 */
interface ModelConfig {
  id: string;
  name: string;
  model: string;
  isMultimodal?: boolean;
  /** æ˜¯å¦ä¸ºæ¨ç†æ¨¡å‹ï¼ˆæ”¯æŒ thinking/reasoningï¼‰ */
  isReasoning?: boolean;
  /** æ˜¯å¦æ”¯æŒå·¥å…·è°ƒç”¨ */
  supportsTools?: boolean;
  /** æ˜¯å¦å¯ç”¨ */
  enabled?: boolean;
  /** æ˜¯å¦ä¸ºåµŒå…¥æ¨¡å‹ */
  isEmbedding?: boolean;
  is_embedding?: boolean;
  /** æ˜¯å¦ä¸ºé‡æ’åºæ¨¡å‹ */
  isReranker?: boolean;
  is_reranker?: boolean;
  /** æ¨¡å‹æœ€å¤§è¾“å‡º tokens */
  maxOutputTokens?: number;
  max_output_tokens?: number;
  /** ä¾›åº”å•†çº§åˆ« max_tokens ä¸Šé™ */
  maxTokensLimit?: number;
  max_tokens_limit?: number;
}

interface UseAvailableModelsReturn {
  /** å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼ˆå·²è½¬æ¢ä¸º ModelInfo æ ¼å¼ï¼‰ */
  models: ModelInfo[];
  /** æ˜¯å¦æ­£åœ¨åŠ è½½ */
  loading: boolean;
  /** åŠ è½½é”™è¯¯ */
  error: Error | null;
  /** é‡æ–°åŠ è½½ */
  reload: () => Promise<void>;
}

// ============================================================================
// ç¼“å­˜
// ============================================================================

let cachedModels: ModelInfo[] | null = null;
let cacheTimestamp = 0;
const CACHE_TTL_MS = 5 * 60 * 1000; // 5 åˆ†é’Ÿç¼“å­˜

// ============================================================================
// å…±äº«åŠ è½½é€»è¾‘
// ============================================================================

/**
 * ä»åç«¯æ‹‰å–å¹¶è½¬æ¢èŠå¤©æ¨¡å‹é…ç½®
 */
async function fetchAvailableModelInfos(): Promise<ModelInfo[]> {
  const configs = await invoke<ModelConfig[]>('get_api_configurations');

  // è¿‡æ»¤æ‰åµŒå…¥æ¨¡å‹ã€é‡æ’åºæ¨¡å‹å’Œæœªå¯ç”¨çš„æ¨¡å‹ï¼ˆä¾›åº”å•†æ²¡æœ‰ API Key çš„æ¨¡å‹ enabled=falseï¼‰
  const chatModels = (configs || []).filter((c) => {
    const isEmbedding = c.isEmbedding === true || c.is_embedding === true;
    const isReranker = c.isReranker === true || c.is_reranker === true;
    const isEnabled = c.enabled !== false;
    return !isEmbedding && !isReranker && isEnabled;
  });

  // è½¬æ¢ä¸º ModelInfo æ ¼å¼
  // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ model å­—æ®µä½œä¸ºæ˜¾ç¤º IDï¼Œè€Œéæ•°æ®åº“ ID
  // ğŸ”§ æ‰©å±•ï¼šä¼ é€’æ¨¡å‹èƒ½åŠ›å­—æ®µï¼ˆisReasoningã€supportsToolsã€enabledï¼‰
  return chatModels.map((config) => ({
    id: config.id, // æ•°æ®åº“ IDï¼ˆç”¨äºåç«¯è°ƒç”¨ï¼‰
    name: config.name || config.model, // ç”¨æˆ·å®šä¹‰çš„åç§°ï¼ˆç”¨äºæ˜¾ç¤ºå’Œ @mention æ’å…¥ï¼‰
    // æ¨¡å‹æ ‡è¯†ç¬¦ï¼ˆå¦‚ "gpt-4", "deepseek-chat"ï¼‰- ç”¨äº Popover å‰¯æ ‡é¢˜æ˜¾ç¤º
    model: config.model,
    // ç”Ÿæˆåˆ«åï¼šåŒ…å«åç§°ã€æ¨¡å‹æ ‡è¯†ç¬¦
    aliases: [
      config.name?.toLowerCase(),
      config.model?.toLowerCase(),
    ].filter((s): s is string => !!s && s.length > 0),
    // ğŸ”§ æ–°å¢ï¼šæ¨¡å‹èƒ½åŠ›å­—æ®µï¼Œä¾¿äº UI æ ¹æ®èƒ½åŠ›æ˜¾ç¤ºä¸åŒçŠ¶æ€
    isMultimodal: config.isMultimodal,
    isReasoning: config.isReasoning,
    supportsTools: config.supportsTools,
    enabled: config.enabled,
    // ä¸Šä¸‹æ–‡é¢„ç®—æ¨æ–­æ‰€éœ€å…ƒä¿¡æ¯
    maxOutputTokens: config.maxOutputTokens ?? config.max_output_tokens,
    maxTokensLimit: config.maxTokensLimit ?? config.max_tokens_limit,
  }));
}

/**
 * ç¡®ä¿ç¼“å­˜å·²åŠ è½½
 */
export async function ensureModelsCacheLoaded(forceRefresh = false): Promise<ModelInfo[]> {
  const now = Date.now();
  if (!forceRefresh && cachedModels && now - cacheTimestamp < CACHE_TTL_MS) {
    return cachedModels;
  }

  const modelInfos = await fetchAvailableModelInfos();
  cachedModels = modelInfos;
  cacheTimestamp = now;
  return modelInfos;
}

// ============================================================================
// Hook
// ============================================================================

/**
 * useAvailableModels - è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
 *
 * ç‰¹æ€§ï¼š
 * - 5 åˆ†é’Ÿå†…å­˜ç¼“å­˜
 * - è‡ªåŠ¨è½¬æ¢ä¸º ModelInfo æ ¼å¼
 * - æ”¯æŒæ‰‹åŠ¨åˆ·æ–°
 *
 * @example
 * ```tsx
 * const { models, loading } = useAvailableModels();
 * // ä¼ é€’ç»™ useInputBarV2
 * useInputBarV2(store, { availableModels: models });
 * ```
 */
export function useAvailableModels(): UseAvailableModelsReturn {
  const [models, setModels] = useState<ModelInfo[]>(cachedModels || []);
  const [loading, setLoading] = useState(!cachedModels);
  const [error, setError] = useState<Error | null>(null);

  const loadModels = useCallback(async () => {
    // æ£€æŸ¥ç¼“å­˜
    const now = Date.now();
    if (cachedModels && now - cacheTimestamp < CACHE_TTL_MS) {
      setModels(cachedModels);
      setLoading(false);
      return;
    }

    try {
      setLoading(true);
      setError(null);

      const modelInfos = await ensureModelsCacheLoaded(true);
      setModels(modelInfos);
    } catch (err: unknown) {
      console.error('[useAvailableModels] Failed to load models:', err);
      setError(err instanceof Error ? err : new Error(String(err)));
    } finally {
      setLoading(false);
    }
  }, []);

  useEffect(() => {
    void loadModels();
  }, [loadModels]);

  // é…ç½®å˜æ›´æ—¶æ¸…ç†ç¼“å­˜å¹¶åˆ·æ–°ï¼ˆé¿å… 5 åˆ†é’Ÿ TTL é€ æˆâ€œæ”¹äº†é…ç½®å´ä¸ç”Ÿæ•ˆâ€çš„é”™è§‰ï¼‰
  useEffect(() => {
    const onChanged = () => {
      clearModelsCache();
      void loadModels();
    };
    try {
      window.addEventListener('api_configurations_changed', onChanged as any);
    } catch {}
    return () => {
      try {
        window.removeEventListener('api_configurations_changed', onChanged as any);
      } catch {}
    };
  }, [loadModels]);

  return useMemo(
    () => ({
      models,
      loading,
      error,
      reload: loadModels,
    }),
    [models, loading, error]
  );
}

/**
 * æ¸…é™¤æ¨¡å‹ç¼“å­˜
 *
 * åœ¨æ¨¡å‹é…ç½®å˜æ›´åè°ƒç”¨
 */
export function clearModelsCache(): void {
  cachedModels = null;
  cacheTimestamp = 0;
}

/**
 * è·å–ç¼“å­˜çš„æ¨¡å‹åˆ—è¡¨ï¼ˆé React ç¯å¢ƒä½¿ç”¨ï¼‰
 *
 * â˜… ç”¨äº TauriAdapter ç­‰é React ç»„ä»¶è·å–æ¨¡å‹é…ç½®
 */
export function getCachedModels(): ModelInfo[] | null {
  return cachedModels;
}

/**
 * æ ¹æ®æ¨¡å‹ ID æŸ¥æ‰¾ç¼“å­˜ä¸­çš„æ¨¡å‹ä¿¡æ¯
 */
export function getModelInfoByConfigId(modelId: string | undefined): ModelInfo | undefined {
  if (!modelId || !cachedModels) {
    return undefined;
  }
  return cachedModels.find((m) => m.id === modelId);
}

/**
 * æ ¹æ®æ¨¡å‹ ID æŸ¥æ‰¾æ¨¡å‹æ˜¯å¦æ”¯æŒå¤šæ¨¡æ€
 *
 * â˜… ç”¨äºä¸Šä¸‹æ–‡æ³¨å…¥æ¨¡å—åˆ¤æ–­æ˜¯å¦æ³¨å…¥å›¾ç‰‡
 *
 * @param modelId æ¨¡å‹é…ç½® ID
 * @returns æ˜¯å¦æ”¯æŒå¤šæ¨¡æ€ï¼ˆæœªæ‰¾åˆ°æ—¶è¿”å› falseï¼‰
 */
export function isModelMultimodal(modelId: string | undefined): boolean {
  if (!modelId || !cachedModels) {
    return false;
  }
  const model = cachedModels.find((m) => m.id === modelId);
  return model?.isMultimodal === true;
}

/**
 * å¼‚æ­¥ç‰ˆæœ¬ï¼šæ ¹æ®æ¨¡å‹ ID æŸ¥æ‰¾æ¨¡å‹æ˜¯å¦æ”¯æŒå¤šæ¨¡æ€
 *
 * â˜… 2026-02 ä¿®å¤ï¼šå¦‚æœç¼“å­˜æœªåŠ è½½ï¼Œå…ˆåŠ è½½ç¼“å­˜å†åˆ¤æ–­
 * â˜… ç”¨äºå‘é€æ¶ˆæ¯æ—¶ç¡®ä¿æ­£ç¡®åˆ¤æ–­æ¨¡å‹å¤šæ¨¡æ€èƒ½åŠ›
 *
 * @param modelId æ¨¡å‹é…ç½® ID
 * @returns æ˜¯å¦æ”¯æŒå¤šæ¨¡æ€ï¼ˆæœªæ‰¾åˆ°æ—¶è¿”å› falseï¼‰
 */
export async function isModelMultimodalAsync(modelId: string | undefined): Promise<boolean> {
  console.log('[PDF_DEBUG_FE] isModelMultimodalAsync called with modelId:', modelId);

  if (!modelId) {
    console.log('[PDF_DEBUG_FE] isModelMultimodalAsync: modelId is undefined, returning false');
    return false;
  }

  // å¦‚æœç¼“å­˜æœªåŠ è½½ï¼Œå…ˆåŠ è½½ç¼“å­˜
  if (!cachedModels || cachedModels.length === 0) {
    console.log('[PDF_DEBUG_FE] isModelMultimodalAsync: cachedModels is null, loading from backend...');
    try {
      const models = await ensureModelsCacheLoaded();

      // â˜… è°ƒè¯•ï¼šæ‰“å°æ‰€æœ‰æ¨¡å‹çš„å¤šæ¨¡æ€çŠ¶æ€
      console.log('[PDF_DEBUG_FE] isModelMultimodalAsync: cached models:', models.map(m => ({
        id: m.id,
        name: m.name,
        isMultimodal: m.isMultimodal,
      })));
    } catch (error: unknown) {
      console.error('[isModelMultimodalAsync] Failed to load models:', error);
      return false;
    }
  }

  const model = cachedModels?.find((m) => m.id === modelId);
  const result = model?.isMultimodal === true;

  console.log('[PDF_DEBUG_FE] isModelMultimodalAsync result:', {
    modelId,
    foundModel: model ? { id: model.id, name: model.name, isMultimodal: model.isMultimodal } : null,
    result,
  });

  return result;
}

export default useAvailableModels;
